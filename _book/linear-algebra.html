<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Math (P)refresher for Political Scientists</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Math (P)refresher for Political Scientists" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Math (P)refresher for Political Scientists" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Shiro Kuriwaki and Yon Soo Park">


<meta name="date" content="2018-06-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="functions-and-notation.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome</a></li>
<li class="chapter" data-level="2" data-path="linear-algebra.html"><a href="linear-algebra.html"><i class="fa fa-check"></i><b>2</b> Linear Algebra</a><ul>
<li class="chapter" data-level="2.1" data-path="linear-algebra.html"><a href="linear-algebra.html#working-with-vectors"><i class="fa fa-check"></i><b>2.1</b> Working with Vectors</a></li>
<li class="chapter" data-level="2.2" data-path="linear-algebra.html"><a href="linear-algebra.html#linear-independence"><i class="fa fa-check"></i><b>2.2</b> Linear Independence</a></li>
<li class="chapter" data-level="2.3" data-path="linear-algebra.html"><a href="linear-algebra.html#basics-of-matrix-algebra"><i class="fa fa-check"></i><b>2.3</b> Basics of Matrix Algebra</a></li>
<li class="chapter" data-level="2.4" data-path="linear-algebra.html"><a href="linear-algebra.html#square-matrices"><i class="fa fa-check"></i><b>2.4</b> Square Matrices</a></li>
<li class="chapter" data-level="2.5" data-path="linear-algebra.html"><a href="linear-algebra.html#linear-equations"><i class="fa fa-check"></i><b>2.5</b> Linear Equations</a></li>
<li class="chapter" data-level="2.6" data-path="linear-algebra.html"><a href="linear-algebra.html#systems-of-linear-equations"><i class="fa fa-check"></i><b>2.6</b> Systems of Linear Equations</a></li>
<li class="chapter" data-level="2.7" data-path="linear-algebra.html"><a href="linear-algebra.html#systems-of-equations-as-matrices"><i class="fa fa-check"></i><b>2.7</b> Systems of Equations as Matrices</a></li>
<li class="chapter" data-level="2.8" data-path="linear-algebra.html"><a href="linear-algebra.html#finding-solutions-to-augmented-matrices-and-systems-of-equations"><i class="fa fa-check"></i><b>2.8</b> Finding Solutions to Augmented Matrices and Systems of Equations</a></li>
<li class="chapter" data-level="2.9" data-path="linear-algebra.html"><a href="linear-algebra.html#rank-and-whether-a-system-has-one-infinite-or-no-solutions"><i class="fa fa-check"></i><b>2.9</b> Rank — and Whether a System Has One, Infinite, or No Solutions</a></li>
<li class="chapter" data-level="2.10" data-path="linear-algebra.html"><a href="linear-algebra.html#the-inverse-of-a-matrix"><i class="fa fa-check"></i><b>2.10</b> The Inverse of a Matrix</a></li>
<li class="chapter" data-level="2.11" data-path="linear-algebra.html"><a href="linear-algebra.html#linear-systems-and-inverses"><i class="fa fa-check"></i><b>2.11</b> Linear Systems and Inverses</a></li>
<li class="chapter" data-level="2.12" data-path="linear-algebra.html"><a href="linear-algebra.html#determinants"><i class="fa fa-check"></i><b>2.12</b> Determinants</a></li>
<li class="chapter" data-level="2.13" data-path="linear-algebra.html"><a href="linear-algebra.html#getting-inverse-of-a-matrix-using-its-determinant-and-matrix-of-cofactors"><i class="fa fa-check"></i><b>2.13</b> Getting Inverse of a Matrix using its Determinant and Matrix of Cofactors</a></li>
<li class="chapter" data-level="2.14" data-path="linear-algebra.html"><a href="linear-algebra.html#inverse-of-larger-matrices"><i class="fa fa-check"></i><b>2.14</b> Inverse of Larger Matrices</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="functions-and-notation.html"><a href="functions-and-notation.html"><i class="fa fa-check"></i><b>3</b> Functions and Notation</a><ul>
<li class="chapter" data-level="3.1" data-path="functions-and-notation.html"><a href="functions-and-notation.html#dimensionality"><i class="fa fa-check"></i><b>3.1</b> Dimensionality</a></li>
<li class="chapter" data-level="3.2" data-path="functions-and-notation.html"><a href="functions-and-notation.html#interval-notation-for-bf-r1"><i class="fa fa-check"></i><b>3.2</b> Interval Notation for <span class="math inline">\({\bf R}^1\)</span></a></li>
<li class="chapter" data-level="3.3" data-path="functions-and-notation.html"><a href="functions-and-notation.html#neighborhoods-intervals-disks-and-balls"><i class="fa fa-check"></i><b>3.3</b> Neighborhoods: Intervals, Disks, and Balls</a></li>
<li class="chapter" data-level="3.4" data-path="functions-and-notation.html"><a href="functions-and-notation.html#introduction-to-functions"><i class="fa fa-check"></i><b>3.4</b> Introduction to Functions</a></li>
<li class="chapter" data-level="3.5" data-path="functions-and-notation.html"><a href="functions-and-notation.html#domain-and-rangeimage"><i class="fa fa-check"></i><b>3.5</b> Domain and Range/Image</a></li>
<li class="chapter" data-level="3.6" data-path="functions-and-notation.html"><a href="functions-and-notation.html#some-general-types-of-functions"><i class="fa fa-check"></i><b>3.6</b> Some General Types of Functions</a></li>
<li class="chapter" data-level="3.7" data-path="functions-and-notation.html"><a href="functions-and-notation.html#log-ln-and-exp"><i class="fa fa-check"></i><b>3.7</b> <span class="math inline">\(\log\)</span>, <span class="math inline">\(\ln\)</span>, and <span class="math inline">\(\exp\)</span></a></li>
<li class="chapter" data-level="3.8" data-path="functions-and-notation.html"><a href="functions-and-notation.html#other-useful-functions"><i class="fa fa-check"></i><b>3.8</b> Other Useful Functions</a></li>
<li class="chapter" data-level="3.9" data-path="functions-and-notation.html"><a href="functions-and-notation.html#graphing-functions"><i class="fa fa-check"></i><b>3.9</b> Graphing Functions</a></li>
<li class="chapter" data-level="3.10" data-path="functions-and-notation.html"><a href="functions-and-notation.html#solving-for-variables-and-finding-inverses"><i class="fa fa-check"></i><b>3.10</b> Solving for Variables and Finding Inverses</a></li>
<li class="chapter" data-level="3.11" data-path="functions-and-notation.html"><a href="functions-and-notation.html#finding-the-roots-or-zeroes-of-a-function"><i class="fa fa-check"></i><b>3.11</b> Finding the Roots or Zeroes of a Function</a></li>
<li class="chapter" data-level="3.12" data-path="functions-and-notation.html"><a href="functions-and-notation.html#the-limit-of-a-function"><i class="fa fa-check"></i><b>3.12</b> The Limit of a Function</a></li>
<li class="chapter" data-level="3.13" data-path="functions-and-notation.html"><a href="functions-and-notation.html#continuity"><i class="fa fa-check"></i><b>3.13</b> Continuity</a></li>
<li class="chapter" data-level="3.14" data-path="functions-and-notation.html"><a href="functions-and-notation.html#sets"><i class="fa fa-check"></i><b>3.14</b> Sets</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="calculus-i.html"><a href="calculus-i.html"><i class="fa fa-check"></i><b>4</b> Calculus I</a><ul>
<li class="chapter" data-level="4.1" data-path="calculus-i.html"><a href="calculus-i.html#sequences"><i class="fa fa-check"></i><b>4.1</b> Sequences</a></li>
<li class="chapter" data-level="4.2" data-path="calculus-i.html"><a href="calculus-i.html#the-limit-of-a-sequence"><i class="fa fa-check"></i><b>4.2</b> The Limit of a Sequence</a></li>
<li class="chapter" data-level="4.3" data-path="calculus-i.html"><a href="calculus-i.html#series"><i class="fa fa-check"></i><b>4.3</b> Series</a></li>
<li class="chapter" data-level="4.4" data-path="calculus-i.html"><a href="calculus-i.html#derivatives"><i class="fa fa-check"></i><b>4.4</b> Derivatives</a></li>
<li class="chapter" data-level="4.5" data-path="calculus-i.html"><a href="calculus-i.html#higher-order-derivatives-or-derivatives-of-derivatives-of-derivatives"><i class="fa fa-check"></i><b>4.5</b> Higher-Order Derivatives or, Derivatives of Derivatives of Derivatives</a></li>
<li class="chapter" data-level="4.6" data-path="calculus-i.html"><a href="calculus-i.html#composite-functions-and-the-chain-rule"><i class="fa fa-check"></i><b>4.6</b> Composite Functions and the Chain Rule</a></li>
<li class="chapter" data-level="4.7" data-path="calculus-i.html"><a href="calculus-i.html#derivatives-of-eulers-number-and-natural-logs"><i class="fa fa-check"></i><b>4.7</b> Derivatives of Euler’s number and natural logs</a></li>
<li class="chapter" data-level="4.8" data-path="calculus-i.html"><a href="calculus-i.html#applications-of-the-derivative-maxima-and-minima"><i class="fa fa-check"></i><b>4.8</b> Applications of the Derivative: Maxima and Minima</a></li>
<li class="chapter" data-level="4.9" data-path="calculus-i.html"><a href="calculus-i.html#partial-derivatives"><i class="fa fa-check"></i><b>4.9</b> Partial Derivatives</a></li>
<li class="chapter" data-level="4.10" data-path="calculus-i.html"><a href="calculus-i.html#lhopitals-rule"><i class="fa fa-check"></i><b>4.10</b> L’H^opital’s Rule</a></li>
<li class="chapter" data-level="4.11" data-path="calculus-i.html"><a href="calculus-i.html#taylor-series-approximation"><i class="fa fa-check"></i><b>4.11</b> Taylor Series Approximation</a></li>
<li class="chapter" data-level="4.12" data-path="calculus-i.html"><a href="calculus-i.html#summary-derivative-calculus-in-6-steps"><i class="fa fa-check"></i><b>4.12</b> Summary: Derivative calculus in 6 steps</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="calculus-ii.html"><a href="calculus-ii.html"><i class="fa fa-check"></i><b>5</b> Calculus II</a><ul>
<li class="chapter" data-level="5.1" data-path="calculus-ii.html"><a href="calculus-ii.html#the-indefinite-integral-the-antiderivative"><i class="fa fa-check"></i><b>5.1</b> The Indefinite Integral: The Antiderivative</a></li>
<li class="chapter" data-level="5.2" data-path="calculus-ii.html"><a href="calculus-ii.html#common-rules-of-integration"><i class="fa fa-check"></i><b>5.2</b> Common Rules of Integration</a></li>
<li class="chapter" data-level="5.3" data-path="calculus-ii.html"><a href="calculus-ii.html#the-definite-integral-the-area-under-the-curve"><i class="fa fa-check"></i><b>5.3</b> The Definite Integral: The Area under the Curve</a></li>
<li class="chapter" data-level="5.4" data-path="calculus-ii.html"><a href="calculus-ii.html#integration-by-substitution"><i class="fa fa-check"></i><b>5.4</b> Integration by Substitution</a></li>
<li class="chapter" data-level="5.5" data-path="calculus-ii.html"><a href="calculus-ii.html#integration-by-parts-or-ultraviolet-voodoo"><i class="fa fa-check"></i><b>5.5</b> Integration by Parts, or Ultraviolet Voodoo</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="optimization.html"><a href="optimization.html"><i class="fa fa-check"></i><b>6</b> Optimization</a><ul>
<li class="chapter" data-level="6.1" data-path="optimization.html"><a href="optimization.html#quadratic-forms"><i class="fa fa-check"></i><b>6.1</b> Quadratic Forms</a></li>
<li class="chapter" data-level="6.2" data-path="optimization.html"><a href="optimization.html#concavity-of-quadratic-forms"><i class="fa fa-check"></i><b>6.2</b> Concavity of Quadratic Forms</a></li>
<li class="chapter" data-level="6.3" data-path="optimization.html"><a href="optimization.html#definiteness-of-quadratic-forms"><i class="fa fa-check"></i><b>6.3</b> Definiteness of Quadratic Forms</a></li>
<li class="chapter" data-level="6.4" data-path="optimization.html"><a href="optimization.html#first-order-conditions"><i class="fa fa-check"></i><b>6.4</b> First Order Conditions</a></li>
<li class="chapter" data-level="6.5" data-path="optimization.html"><a href="optimization.html#second-order-conditions"><i class="fa fa-check"></i><b>6.5</b> Second Order Conditions</a></li>
<li class="chapter" data-level="6.6" data-path="optimization.html"><a href="optimization.html#definiteness-and-concavity"><i class="fa fa-check"></i><b>6.6</b> Definiteness and Concavity</a></li>
<li class="chapter" data-level="6.7" data-path="optimization.html"><a href="optimization.html#global-maxima-and-minima"><i class="fa fa-check"></i><b>6.7</b> Global Maxima and Minima</a></li>
<li class="chapter" data-level="6.8" data-path="optimization.html"><a href="optimization.html#constrained-optimization"><i class="fa fa-check"></i><b>6.8</b> Constrained Optimization</a></li>
<li class="chapter" data-level="6.9" data-path="optimization.html"><a href="optimization.html#equality-constraints"><i class="fa fa-check"></i><b>6.9</b> Equality Constraints</a></li>
<li class="chapter" data-level="6.10" data-path="optimization.html"><a href="optimization.html#inequality-constraints"><i class="fa fa-check"></i><b>6.10</b> Inequality Constraints</a></li>
<li class="chapter" data-level="6.11" data-path="optimization.html"><a href="optimization.html#kuhn-tucker-conditions"><i class="fa fa-check"></i><b>6.11</b> Kuhn-Tucker Conditions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="7" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>7</b> Introduction</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Math (P)refresher for Political Scientists</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-algebra" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Linear Algebra</h1>
<p>Topics: <span class="math inline">\(\bullet\)</span> Working with Vectors <span class="math inline">\(\bullet\)</span> Linear Independence <span class="math inline">\(\bullet\)</span> Basics of Matrix Algebra <span class="math inline">\(\bullet\)</span> Square Matrices <span class="math inline">\(\bullet\)</span> Linear Equations <span class="math inline">\(\bullet\)</span> Systems of Linear Equations <span class="math inline">\(\bullet\)</span> Systems of Equations as Matrices <span class="math inline">\(\bullet\)</span> Solving Augmented Matrices and Systems of Equations <span class="math inline">\(\bullet\)</span> Rank <span class="math inline">\(\bullet\)</span> The Inverse of a Matrix <span class="math inline">\(\bullet\)</span> Inverse of Larger Matrices</p>
<p>Much of the material and examples for this lecture are taken from Gill (2006) , Simon &amp; Blume (1994)  and Kolman (1993) .</p>
<div id="working-with-vectors" class="section level2">
<h2><span class="header-section-number">2.1</span> Working with Vectors</h2>
<p><strong>Vector</strong>: A vector in <span class="math inline">\(n\)</span>-space is an ordered list of <span class="math inline">\(n\)</span> numbers. These numbers can be represented as either a row vector or a column vector: <span class="math display">\[ {\bf v} \begin{pmatrix} v_1 &amp; v_2 &amp; \dots &amp; v_n\end{pmatrix} , {\bf v} = \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix}\]</span></p>
<p>We can also think of a vector as defining a point in <span class="math inline">\(n\)</span>-dimensional space, usually <span class="math inline">\({\bf R}^n\)</span>; each element of the vector defines the coordinate of the point in a particular direction.</p>
<p><strong>Vector Addition and Subtraction</strong>: If two vectors, <span class="math inline">\({\bf u}\)</span> and <span class="math inline">\({\bf v}\)</span>, have the same length (i.e. have the same number of elements), they can be added (subtracted) together: <span class="math display">\[ {\bf u} + {\bf v} = \begin{pmatrix} u_1 + v_1 &amp; u_2 + v_2 &amp; \cdots &amp; u_k + v_n \end{pmatrix}\]</span> <span class="math display">\[ {\bf u} - {\bf v} = \begin{pmatrix} u_1 - v_1 &amp; u_2 - v_2 &amp; \cdots &amp; u_k - v_n \end{pmatrix}\]</span></p>
<p><strong>Scalar Multiplication</strong>: The product of a scalar <span class="math inline">\(c\)</span> (i.e. a constant) and vector <span class="math inline">\({\bf v}\)</span> is:<br />
<span class="math display">\[ c{\bf v} =  \begin{pmatrix} cv_1 &amp; cv_2 &amp; \dots &amp; cv_n \end{pmatrix} \]</span></p>
<p><strong>Vector Inner Product</strong>: The inner product (also called the dot product or scalar product) of two vectors <span class="math inline">\({\bf u}\)</span> and <span class="math inline">\({\bf v}\)</span> is again defined iff they have the same number of elements <span class="math display">\[ {\bf u} \cdot {\bf v} = u_1v_1 + u_2v_2 + \cdots + u_nv_n = \sum_{i = 1}^n u_iv_i\]</span> If <span class="math inline">\({\bf u} \cdot {\bf v} = 0\)</span>, the two vectors are orthogonal (or perpendicular).</p>
<p><strong>Vector Norm</strong>: The norm of a vector is a measure of its length. There are many different ways to calculate the norm, but the most common of is the Euclidean norm (which corresponds to our usual conception of distance in three-dimensional space): <span class="math display">\[ ||{\bf v}|| = \sqrt{{\bf v}\cdot{\bf v}} = \sqrt{ v_1v_1 + v_2v_2 + \cdots + v_nv_n}\]</span></p>
</div>
<div id="linear-independence" class="section level2">
<h2><span class="header-section-number">2.2</span> Linear Independence</h2>
<p><strong>Linear combinations</strong>: The vector <span class="math inline">\({\bf u}\)</span> is a linear combination of the vectors <span class="math inline">\({\bf v}_1, {\bf v}_2, \cdots , {\bf v}_k\)</span> if <span class="math display">\[{\bf u} = c_1{\bf v}_1 + c_2{\bf v}_2 +  \cdots + c_k{\bf v}_k\]</span></p>
<p><strong>Linear independence</strong>: A set of vectors <span class="math inline">\({\bf v}_1, {\bf v}_2, \cdots , {\bf v}_k\)</span> is linearly independent if the only solution to the equation <span class="math display">\[c_1{\bf v}_1 + c_2{\bf v}_2 +  \cdots + c_k{\bf v}_k = 0\]</span> is <span class="math inline">\(c_1 = c_2 = \cdots = c_k = 0\)</span>. If another solution exists, the set of vectors is linearly dependent.</p>
<p>A set <span class="math inline">\(S\)</span> of vectors is linearly dependent iff at least one of the vectors in <span class="math inline">\(S\)</span> can be written as a linear combination of the other vectors in <span class="math inline">\(S\)</span>.</p>
<p>Linear independence is only defined for sets of vectors with the same number of elements; any linearly independent set of vectors in <span class="math inline">\(n\)</span>-space contains at most <span class="math inline">\(n\)</span> vectors.</p>
<p>Exercises: Are the following sets of vectors linearly independent?</p>

</div>
<div id="basics-of-matrix-algebra" class="section level2">
<h2><span class="header-section-number">2.3</span> Basics of Matrix Algebra</h2>
<p><strong>Matrix</strong>: A matrix is an array of real numbers arranged in <span class="math inline">\(m\)</span> rows by <span class="math inline">\(n\)</span> columns. The dimensionality of the matrix is defined as the number of rows by the number of columns, <span class="math inline">\(m x n\)</span>.</p>
<p><span class="math display">\[{\bf A}=\begin{pmatrix}
            a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n} \\
            a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n} \\
            \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
            a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn}
        \end{pmatrix}\]</span></p>
<p>Note that you can think of vectors as special cases of matrices; a column vector of length <span class="math inline">\(k\)</span> is a <span class="math inline">\(k \times 1\)</span> matrix, while a row vector of the same length is a <span class="math inline">\(1 \times k\)</span> matrix.</p>
<p>It’s also useful to think of matrices as being made up of a collection of row or column vectors. For example, <span class="math display">\[\bf A = \begin{pmatrix} {\bf a}_1 &amp; {\bf a}_2 &amp;  \cdots &amp; {\bf a}_m \end{pmatrix}\]</span></p>
<p><strong>Matrix Addition</strong>: Let <span class="math inline">\(\bf A\)</span> and <span class="math inline">\(\bf B\)</span> be two <span class="math inline">\(m\times n\)</span> matrices. <span class="math display">\[{\bf A+B}=\begin{pmatrix}
            a_{11}+b_{11} &amp; a_{12}+b_{12} &amp; \cdots &amp; a_{1n}+b_{1n} \\
            a_{21}+b_{21} &amp; a_{22}+b_{22} &amp; \cdots &amp; a_{2n}+b_{2n} \\
            \vdots &amp; \vdots  &amp; \ddots &amp; \vdots \\
            a_{m1}+b_{m1} &amp; a_{m2}+b_{m2} &amp; \cdots &amp; a_{mn}+b_{mn}
        \end{pmatrix}\]</span></p>
<p>Note that matrices <span class="math inline">\({\bf A}\)</span> and <span class="math inline">\({\bf B}\)</span> must have the same dimensionality, in which case they are <strong>conformable for addition</strong>.</p>
<p>Example: <span class="math display">\[{\bf A}=\begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \end{pmatrix}, \qquad
            {\bf B}=\begin{pmatrix} 1 &amp; 2 &amp; 1 \\ 2 &amp; 1 &amp; 2 \end{pmatrix}\]</span> <span class="math display">\[{\bf A+B}= \phantom{\begin{pmatrix} 2 &amp; 4 &amp; 4 \\ 6 &amp; 6 &amp; 8 \end{pmatrix}}\]</span></p>
<p><strong>Scalar Multiplication</strong>: Given the scalar <span class="math inline">\(s\)</span>, the scalar multiplication of <span class="math inline">\(s {\bf A}\)</span> is <span class="math display">\[ s {\bf A}=  s \begin{pmatrix}
            a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n} \\
            a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n} \\
            \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
            a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn}
        \end{pmatrix}
        = \begin{pmatrix}
            s a_{11} &amp; s a_{12} &amp; \cdots &amp; s a_{1n} \\
            s a_{21} &amp; s a_{22} &amp; \cdots &amp; s a_{2n} \\
            \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
            s a_{m1} &amp; s a_{m2} &amp; \cdots &amp; s a_{mn}
        \end{pmatrix}\]</span></p>
<p>Example: <span class="math display">\[s=2, \qquad {\bf A}=\begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \end{pmatrix}\]</span> <span class="math display">\[s {\bf A} = \phantom{\begin{pmatrix} 2 &amp; 4 &amp; 6 \\ 8 &amp; 10 &amp; 12 \end{pmatrix}}\]</span></p>
<p><strong>Matrix Multiplication</strong>: If <span class="math inline">\({\bf A}\)</span> is an <span class="math inline">\(m\times k\)</span> matrix and <span class="math inline">\(\bf B\)</span> is a <span class="math inline">\(k\times n\)</span> matrix, then their product <span class="math inline">\(\bf C = A B\)</span> is the <span class="math inline">\(m\times n\)</span> matrix where <span class="math display">\[c_{ij}=a_{i1}b_{1j}+a_{i2}b_{2j}+\cdots+a_{ik}b_{kj}\]</span></p>
<p>Examples:</p>

<p>Note that the number of columns of the first matrix must equal the number of rows of the second matrix, in which case they are <strong>conformable for multiplication</strong>. The sizes of the matrices (including the resulting product) must be <span class="math display">\[(m\times k)(k\times n)=(m\times n)\]</span></p>
<p>Also note that if <strong>AB</strong> exists, <strong>BA</strong> exists only if <span class="math inline">\(\dim({\bf A}) = m \times n\)</span> and <span class="math inline">\(\dim({\bf B}) = n \times m\)</span>.</p>
<p>This does not mean that <strong>AB</strong> = <strong>BA</strong>. <strong>AB</strong> = <strong>BA</strong> is true only in special circumstances, like when <span class="math inline">\({\bf A}\)</span> or <span class="math inline">\({\bf B}\)</span> is an identity matrix, <span class="math inline">\({\bf A} = {\bf B}^{-1}\)</span>, or <span class="math inline">\({\bf A} = {\bf B}\)</span> and <strong>A</strong> is idempotent.</p>
<strong>Laws of Matrix Algebra</strong>:

<p>Commutative law for multiplication does not hold – the order of multiplication matters: <span class="math display">\[\bf AB\ne BA\]</span></p>
<p>Example: <span class="math display">\[{\bf A}=\begin{pmatrix} 1&amp;2\\-1&amp;3\end{pmatrix}, \qquad {\bf B}=\begin{pmatrix} 2&amp;1\\0&amp;1\end{pmatrix}\]</span> <span class="math display">\[{\bf AB}=\begin{pmatrix} 2&amp;3\\-2&amp;2\end{pmatrix}, \qquad {\bf BA}=\begin{pmatrix} 1&amp;7\\-1&amp;3\end{pmatrix}\]</span></p>
<p><strong>Transpose</strong>: The transpose of the <span class="math inline">\(m\times n\)</span> matrix <span class="math inline">\(\bf A\)</span> is the <span class="math inline">\(n\times m\)</span> matrix <span class="math inline">\({\bf A}^T\)</span> (also written <span class="math inline">\({\bf A}&#39;\)</span>) obtained by interchanging the rows and columns of <span class="math inline">\(\bf A\)</span>.</p>
Examples:

The following rules apply for transposed matrices:

<p>Example of <span class="math inline">\(({\bf AB})^T = {\bf B}^T{\bf A}^T\)</span>: <span class="math display">\[{\bf A}=\begin{pmatrix} 1&amp;3&amp;2\\2&amp;-1&amp;3\end{pmatrix}, \qquad {\bf B}=\begin{pmatrix} 0&amp;1\\2&amp;2\\3&amp;-1\end{pmatrix}\]</span> <span class="math display">\[ ({\bf AB})^T = \left[ \begin{pmatrix} 1&amp;3&amp;2\\2&amp;-1&amp;3\end{pmatrix} \begin{pmatrix} 0&amp;1\\2&amp;2\\3&amp;-1\end{pmatrix} \right]^T = \begin{pmatrix} 12&amp;7\\5&amp;-3 \end{pmatrix}\]</span> <span class="math display">\[ {\bf B}^T{\bf A}^T= \begin{pmatrix} 0&amp;2&amp;3\\1&amp;2&amp;-1 \end{pmatrix}  \begin{pmatrix} 1&amp;2\\3&amp;-1\\2&amp;3 \end{pmatrix} = \begin{pmatrix} 12&amp;7\\5&amp;-3 \end{pmatrix}\]</span></p>
</div>
<div id="square-matrices" class="section level2">
<h2><span class="header-section-number">2.4</span> Square Matrices</h2>
<p><strong>Square</strong> matrices have the same number of rows and columns; a <span class="math inline">\(k \times k\)</span> square matrix is referred to as a matrix of order <span class="math inline">\(k\)</span>.</p>
<p>The <strong>diagonal</strong> of a square matrix is the vector of matrix elements that have the same subscripts. If <strong>A</strong> is a square matrix of order <span class="math inline">\(k\)</span>, then its diagonal is <span class="math inline">\([ a_{11}, a_{22}, \dots, a_{kk}]&#39;\)</span>.</p>
<p>There are several important types of square matrices:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Identity Matrix</strong>: The <span class="math inline">\(n\times n\)</span> identity matrix <span class="math inline">\({\bf I}_n\)</span> is the matrix whose diagonal elements are 1 and all off-diagonal elements are 0. Examples: <span class="math display">\[ {\bf I}_2=\begin{pmatrix} 1&amp;0\\0&amp;1 \end{pmatrix}, \qquad {\bf I}_3=\begin{pmatrix} 1&amp;0&amp;0\\ 0&amp;1&amp;0\\ 
        0&amp;0&amp;1 \end{pmatrix}\]</span></p></li>
<li><p><strong>Symmetric Matrix</strong>: A matrix <strong>A</strong> is symmetric if <span class="math inline">\({\bf A} = {\bf A}&#39;\)</span>; this implies that <span class="math inline">\(a_{ij} = a_{ji}\)</span> for all <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>. Examples: <span class="math display">\[ {\bf A} = \begin{pmatrix} 1&amp;2\\2&amp;1 \end{pmatrix} = {\bf A}&#39;, \qquad {\bf B} =\begin{pmatrix} 4&amp;2&amp;-1\\ 2&amp;1&amp;3\\
        -1&amp;3&amp;1 \end{pmatrix} = {\bf B}&#39;\]</span></p></li>
<li><p><strong>Diagonal Matrix</strong>: A matrix <strong>A</strong> is diagonal if all of its non-diagonal entries are zero; formally, if <span class="math inline">\(a_{ij} = 0\)</span> for all <span class="math inline">\(i \neq j\)</span> Examples: <span class="math display">\[ {\bf A} = \begin{pmatrix} 1&amp;0\\0&amp;2 \end{pmatrix}, \qquad {\bf B} =\begin{pmatrix} 4&amp;0&amp;0\\ 0&amp;1&amp;0\\
        0&amp;0&amp;1 \end{pmatrix}\]</span></p></li>
<li><p><strong>Triangular Matrix</strong>: A matrix is triangular one of two cases. If all entries below the diagonal are zero (<span class="math inline">\(a_{ij} = 0\)</span> for all <span class="math inline">\(i &gt; j\)</span>), it is <strong>upper triangular</strong>. Conversely, if all entries above the diagonal are zero (<span class="math inline">\(a_{ij} = 0\)</span> for all <span class="math inline">\(i &lt; j\)</span>), it is <strong>lower triangular</strong>.</p></li>
</ol>
<p>Examples: <span class="math display">\[ {\bf A}_{LT}= \begin{pmatrix} 1&amp;0 &amp; 0\\4&amp;2&amp;0\\-3 &amp; 2 &amp; 5 \end{pmatrix}, \qquad {\bf A}_{UT}=\begin{pmatrix} 1&amp;7&amp;-4\\ 0&amp;3&amp;9\\
0&amp;0&amp;-3 \end{pmatrix}\]</span></p>
</div>
<div id="linear-equations" class="section level2">
<h2><span class="header-section-number">2.5</span> Linear Equations</h2>
<p><strong>Linear Equation</strong>: <span class="math inline">\(a_1 x_1 + a_2 x_2 + \cdots + a_n x_n = b\)</span></p>
<p><span class="math inline">\(a_i\)</span> are parameters or coefficients. <span class="math inline">\(x_i\)</span> are variables or unknowns.</p>
Linear because only one variable per term and degree is at most 1.

</div>
<div id="systems-of-linear-equations" class="section level2">
<h2><span class="header-section-number">2.6</span> Systems of Linear Equations</h2>
<p>We are often interested in solving linear systems like\</p>
<p><span class="math display">\[\begin{matrix}
            x  &amp; - &amp; 3y &amp; = &amp; -3\\
            2x &amp; + &amp;  y &amp; = &amp;  8
            \end{matrix}\]</span></p>

<p>More generally, we might have a system of <span class="math inline">\(m\)</span> equations in <span class="math inline">\(n\)</span> unknowns</p>
<p><span class="math display">\[\begin{matrix}
            a_{11}x_1  &amp; + &amp; a_{12}x_2 &amp; + &amp; \cdots &amp; + &amp; a_{1n}x_n &amp; = &amp; b_1\\
            a_{21}x_1  &amp; + &amp; a_{22}x_2 &amp; + &amp; \cdots &amp; + &amp; a_{2n}x_n &amp; = &amp; b_2\\
            \vdots     &amp;   &amp;     &amp;   &amp; \vdots &amp;   &amp;     &amp; \vdots &amp; \\
            a_{m1}x_1  &amp; + &amp; a_{m2}x_2 &amp; + &amp; \cdots &amp; + &amp; a_{mn}x_n &amp; = &amp; b_m
            \end{matrix}\]</span></p>
A <strong>solution</strong> to a linear system of <span class="math inline">\(m\)</span> equations in <span class="math inline">\(n\)</span> unknowns is a set of <span class="math inline">\(n\)</span> numbers <span class="math inline">\(x_1, x_2, \cdots, x_n\)</span> that satisfy each of the <span class="math inline">\(m\)</span> equations.

<p>Example: <span class="math inline">\(x=3\)</span> and <span class="math inline">\(y=2\)</span> is the solution to the above <span class="math inline">\(2\times 2\)</span> linear system. Notice from the graph that the two lines intersect at <span class="math inline">\((3,2)\)</span>.</p>
<p>Does a linear system have one, no, or multiple solutions? For a system of 2 equations in 2 unknowns (i.e., two lines):</p>

<p>Methods to solve linear systems:</p>
<ol style="list-style-type: decimal">
<li>Substitution</li>
<li>Elimination of variables</li>
<li>Matrix methods</li>
</ol>
</div>
<div id="systems-of-equations-as-matrices" class="section level2">
<h2><span class="header-section-number">2.7</span> Systems of Equations as Matrices</h2>
<p>Matrices provide an easy and efficient way to represent linear systems such as <span class="math display">\[\begin{matrix}
        a_{11}x_1  &amp; + &amp; a_{12}x_2 &amp; + &amp; \cdots &amp; + &amp; a_{1n}x_n &amp; = &amp; b_1\\
        a_{21}x_1  &amp; + &amp; a_{22}x_2 &amp; + &amp; \cdots &amp; + &amp; a_{2n}x_n &amp; = &amp; b_2\\
        \vdots     &amp;   &amp;     &amp;   &amp; \vdots &amp;   &amp;     &amp; \vdots &amp; \\
        a_{m1}x_1  &amp; + &amp; a_{m2}x_2 &amp; + &amp; \cdots &amp; + &amp; a_{mn}x_n &amp; = &amp; b_m
        \end{matrix}\]</span></p>
<p>as <span class="math display">\[{\bf A x = b}\]</span> where</p>

<p><strong>Augmented Matrix</strong>: When we append <span class="math inline">\(\bf b\)</span> to the coefficient matrix <span class="math inline">\(\bf A\)</span>, we get the augmented matrix <span class="math inline">\(\widehat{\bf A}=[\bf A | b]\)</span> <span class="math display">\[\begin{pmatrix}
            a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n} &amp; | &amp; b_1\\
            a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n} &amp; | &amp; b_2\\
            \vdots &amp;  &amp; \ddots &amp; \vdots &amp; | &amp; \vdots\\
            a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn} &amp; | &amp; b_m
            \end{pmatrix}\]</span></p>
</div>
<div id="finding-solutions-to-augmented-matrices-and-systems-of-equations" class="section level2">
<h2><span class="header-section-number">2.8</span> Finding Solutions to Augmented Matrices and Systems of Equations</h2>
<p><strong>Row Echelon Form</strong>: Our goal is to translate our augmented matrix or system of equations into row echelon form. This will provide us with the values of the vector <strong>x</strong> which solve the system. We use the row operations to change coefficients in lower triangle of the augmented matrix to 0. An augmented matrix of the form</p>
<p><span class="math display">\[\begin{pmatrix}
            \fbox{$a&#39;_{11}$}&amp; a&#39;_{12} &amp; a&#39;_{13}&amp; \cdots &amp; a&#39;_{1n} &amp; | &amp; b&#39;_1\\
            0 &amp; \fbox{$a&#39;_{22}$} &amp; a&#39;_{23}&amp; \cdots &amp; a&#39;_{2n} &amp; | &amp; b&#39;_2\\
            0 &amp; 0 &amp; \fbox{$a&#39;_{33}$}&amp; \cdots &amp; a&#39;_{3n} &amp; | &amp; b&#39;_3\\
            0 &amp; 0 &amp;0 &amp; \ddots &amp; \vdots  &amp; | &amp; \vdots \\
            0 &amp; 0 &amp;0 &amp;0 &amp; \fbox{$a&#39;_{mn}$} &amp; | &amp; b&#39;_m
            \end{pmatrix}\]</span></p>
<p>is said to be in row echelon form — each row has more leading zeros than the row preceding it.</p>
<p><strong>Reduced Row Echelon Form</strong>: We can go one step further and put the matrix into reduced row echelon form. Reduced row echelon form makes the value of <strong>x</strong> which solves the system very obvious. For a system of <span class="math inline">\(m\)</span> equations in <span class="math inline">\(m\)</span> unknowns, with no all-zero rows, the reduced row echelon form would be</p>
<p><span class="math display">\[\begin{pmatrix}
            \fbox{$1$}  &amp;  0 &amp;   0 &amp;    0  &amp;   0 &amp; | &amp; b^*_1\\
            0  &amp;  \fbox{$1$} &amp;   0 &amp;    0  &amp;   0 &amp; | &amp; b^*_2\\
            0  &amp;  0 &amp;   \fbox{$1$} &amp;    0  &amp;   0 &amp; | &amp; b^*_3\\
            0  &amp;  0 &amp;   0 &amp;\ddots &amp;   0 &amp; | &amp;\vdots\\
            0  &amp;  0 &amp;   0 &amp;    0  &amp;   \fbox{$1$} &amp; | &amp; b^*_m
            \end{pmatrix}\]</span></p>
<p><strong>Gaussian and Gauss-Jordan elimination</strong>: We can conduct elementary row operations to get our augmented matrix into row echelon or reduced row echelon form. The methods of transforming a matrix or system into row echelon and reduced row echelon form are referred to as Gaussian elimination and Gauss-Jordan elimination, respectively.</p>
<p><strong>Elementary Row Operations</strong>: To do Gaussian and Gauss-Jordan elimination, we use three basic operations to transform the augmented matrix into another augmented matrix that represents an equivalent linear system – equivalent in the sense that the same values of <span class="math inline">\(x_j\)</span> solve both the original and transformed matrix/system:</p>

<p><strong>Interchanging Rows</strong>: Suppose we have the augmented matrix <span class="math display">\[{\widehat{\bf A}}=\begin{pmatrix} a_{11} &amp; a_{12} &amp; | &amp; b_1\\
            a_{21} &amp; a_{22} &amp; | &amp; b_2 
            \end{pmatrix}\]</span> If we interchange the two rows, we get the augmented matrix <span class="math display">\[\begin{pmatrix}
            a_{21} &amp; a_{22} &amp; | &amp; b_2\\
            a_{11} &amp; a_{12} &amp; | &amp; b_1
            \end{pmatrix}\]</span> which represents a linear system equivalent to that represented by matrix <span class="math inline">\(\widehat{\bf A}\)</span>.</p>
<p><strong>Multiplying by a Constant</strong>: If we multiply the second row of matrix <span class="math inline">\(\widehat{\bf A}\)</span> by a constant <span class="math inline">\(c\)</span>, we get the augmented matrix <span class="math display">\[\begin{pmatrix}
            a_{11} &amp; a_{12} &amp; | &amp; b_1\\
            c a_{21} &amp; c a_{22} &amp; | &amp; c b_2
            \end{pmatrix}\]</span> which represents a linear system equivalent to that represented by matrix <span class="math inline">\(\widehat{\bf A}\)</span>.</p>
<p><strong>Adding (subtracting) Rows</strong>: If we add (subtract) the first row of matrix <span class="math inline">\(\widehat{\bf A}\)</span> to the second, we obtain the augmented matrix <span class="math display">\[\begin{pmatrix}
            a_{11} &amp; a_{12} &amp; | &amp; b_1\\
            a_{11}+a_{21} &amp; a_{12}+a_{22} &amp; | &amp; b_1+b_2
            \end{pmatrix}\]</span> which represents a linear system equivalent to that represented by matrix <span class="math inline">\(\widehat{\bf A}\)</span>.</p>
<p>Exercises: Using Gaussian or Gauss-Jordan elimination, solve the following linear systems by putting them into row echelon or reduced row echelon form:</p>

</div>
<div id="rank-and-whether-a-system-has-one-infinite-or-no-solutions" class="section level2">
<h2><span class="header-section-number">2.9</span> Rank — and Whether a System Has One, Infinite, or No Solutions</h2>
<p>We previously noted that a <span class="math inline">\(2\times 2\)</span> system had one, infinite, or no solutions if the two lines intersected, were the same, or were parallel, respectively. More generally, to determine how many solutions exist, we can use information about (1) the number of equations <span class="math inline">\(m\)</span>, (2) the number of unknowns <span class="math inline">\(n\)</span>, and (3) the <strong>rank</strong> of the matrix representing the linear system.</p>
<p><strong>Rank</strong>: The row rank or column rank of a matrix is the number of nonzero rows or columns in its row echelon form. The rank also corresponds to the maximum number of linearly independent row or column vectors in the matrix. For any matrix <strong>A</strong>, the row rank always equals column rank, and we refer to this number as the rank of <strong>A</strong>.</p>
Examples:

<p>Let <span class="math inline">\(\bf A\)</span> be the coefficient matrix and <span class="math inline">\(\widehat{\bf A}=[ {\bf A} | {\bf b}]\)</span> be the augmented matrix. Then</p>

<strong>Existence of Solutions</strong>:

<p>Find the rank and number of solutions for the systems of equations below.:</p>

</div>
<div id="the-inverse-of-a-matrix" class="section level2">
<h2><span class="header-section-number">2.10</span> The Inverse of a Matrix</h2>
<p><strong>Inverse Matrix</strong>: An <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\({\bf A}\)</span> is <strong>nonsingular</strong> or <strong>invertible</strong> if there exists an <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\({\bf A}^{-1}\)</span> such that <span class="math display">\[{\bf A} {\bf A}^{-1} = {\bf A}^{-1} {\bf A} = {\bf I}_n\]</span> where <span class="math inline">\({\bf A}^{-1}\)</span> is the inverse of <span class="math inline">\({\bf A}\)</span>. If there is no such <span class="math inline">\({\bf A}^{-1}\)</span>, then <span class="math inline">\({\bf A}\)</span> is singular or noninvertible.</p>
<p>Example: Let <span class="math display">\[{\bf A} = \begin{pmatrix} 2&amp;3\\2&amp;2 \end{pmatrix}, \qquad {\bf B}=\begin{pmatrix} -1&amp;\frac{3}{2}\\ 1&amp;-1
        \end{pmatrix}\]</span> Since <span class="math display">\[{\bf A} {\bf B} = {\bf B} {\bf A} = {\bf I}_n\]</span> we conclude that <span class="math inline">\({\bf B}\)</span> is the inverse, <span class="math inline">\({\bf A}^{-1}\)</span>, of <span class="math inline">\({\bf A}\)</span> and that <span class="math inline">\({\bf A}\)</span> is nonsingular.</p>
<p><strong>Properties of the Inverse</strong>:</p>

<p>: We know that if <span class="math inline">\({\bf B}\)</span> is the inverse of <span class="math inline">\({\bf A}\)</span>, then <span class="math display">\[{\bf A} {\bf B} = {\bf B} {\bf A} = {\bf I}_n\]</span> Looking only at the first and last parts of this <span class="math display">\[{\bf A} {\bf B} = {\bf I}_n\]</span> Solving for <span class="math inline">\({\bf B}\)</span> is equivalent to solving for <span class="math inline">\(n\)</span> linear systems, where each column of <span class="math inline">\({\bf B}\)</span> is solved for the corresponding column in <span class="math inline">\({\bf I}_n\)</span>. We can solve the systems simultaneously by augmenting <span class="math inline">\({\bf A}\)</span> with <span class="math inline">\({\bf I}_n\)</span> and performing Gauss-Jordan elimination on <span class="math inline">\({\bf A}\)</span>. If Gauss-Jordan elimination on <span class="math inline">\([{\bf A} | {\bf I}_n]\)</span> results in <span class="math inline">\([{\bf I}_n | {\bf B} ]\)</span>, then <span class="math inline">\({\bf B}\)</span> is the inverse of <span class="math inline">\({\bf A}\)</span>. Otherwise, <span class="math inline">\({\bf A}\)</span> is singular.\ [12pt] To summarize: To calculate the inverse of <span class="math inline">\({\bf A}\)</span></p>

<p>Exercise:</p>
<p>Find the inverse of <span class="math inline">\({\bf A}=\begin{pmatrix} 1&amp;1&amp;1\\0&amp;2&amp;3\\5&amp;5&amp;1 \end{pmatrix}\)</span></p>








</div>
<div id="linear-systems-and-inverses" class="section level2">
<h2><span class="header-section-number">2.11</span> Linear Systems and Inverses</h2>
<p>Let’s return to the matrix representation of a linear system</p>
<p><span class="math display">\[\bf {\bf A} x = b\]</span></p>
<p>If <span class="math inline">\({\bf A}\)</span> is an <span class="math inline">\(n\times n\)</span> matrix,then <span class="math inline">\(\bf {\bf A} x=b\)</span> is a system of <span class="math inline">\(n\)</span> equations in <span class="math inline">\(n\)</span> unknowns. Suppose ${} $ is nonsingular <span class="math inline">\(\quad \Longrightarrow \quad\)</span> <span class="math inline">\({\bf A}^{-1}\)</span> exists. To solve this system, we can premultiply each side by <span class="math inline">\({\bf A}^{-1}\)</span> and reduce it as follows:</p>
<span class="math display">\[\begin{eqnarray} 
            {\bf A}^{-1} ({\bf A} \bf x)&amp;=&amp;{\bf A}^{-1} \bf b \nonumber\\
            ({\bf A}^{-1} {\bf A})\bf x &amp;=&amp;{\bf A}^{-1} \bf b \nonumber\\
            {\bf I}_n \bf x     &amp;=&amp;{\bf A}^{-1} \bf b \nonumber\\
            \bf x&amp;=&amp;{\bf A}^{-1} \bf b \nonumber
\end{eqnarray}\]</span>
<p>Hence, given <span class="math inline">\(\bm{A}\)</span> and <span class="math inline">\(\bm{b}\)</span> and given that <span class="math inline">\(\bm{A}\)</span> is nonsingular, then <span class="math inline">\(\bm{x} = \bm{A}^{-1} b\)</span> is a unique solution to this system.</p>
<p>Notice also that the requirements for <span class="math inline">\({\bf A}\)</span> to be nonsingular correspond to the requirements for a linear system to have a unique solution: <span class="math inline">\(\mbox{rank\,}{\bf A}=\mbox{rows\,}{\bf A}=\mbox{cols\,}{\bf A}\)</span>.</p>
</div>
<div id="determinants" class="section level2">
<h2><span class="header-section-number">2.12</span> Determinants</h2>
<p><strong>Singularity</strong>: Determinants can be used to  whether a square matrix is nonsingular.</p>
<p>A square matrix is nonsingular iff its determinant is not zero.</p>
<p>Determinant of a <span class="math inline">\(1 \times 1\)</span> matrix, <strong>A</strong>, equals <span class="math inline">\(a_{11}\)</span></p>
<p>Determinant of a <span class="math inline">\(2 \times 2\)</span> matrix, <strong>A</strong>, <span class="math inline">\(\begin{vmatrix} a_{11}&amp;a_{12}\\  a_{21}&amp;a_{22} \end{vmatrix}\)</span>:</p>
<span class="math display">\[\begin{eqnarray*}
\det({\bf A}) &amp;=&amp; |{\bf A}|\\
            &amp;=&amp; a_{11}|a_{22}| - a_{12}|a_{21}|\\
            &amp;=&amp; a_{11}a_{22} - a_{12}a_{21}
\end{eqnarray*}\]</span>
<p>We can extend the second to last equation above to get the definition of the determinant of a <span class="math inline">\(3 \times 3\)</span> matrix:</p>
<span class="math display">\[\begin{eqnarray*}
            \begin{vmatrix} a_{11}&amp;a_{12}&amp;a_{13}\\  a_{21} &amp; a_{22}&amp;a_{23}\\ a_{31}&amp;a_{32}&amp;a_{33} \end{vmatrix} 
                &amp;=&amp; 
                a_{11} \begin{vmatrix} a_{22}&amp;a_{23}\\ a_{32}&amp;a_{33} \end{vmatrix}
                - a_{12} \begin{vmatrix} a_{21}&amp;a_{23}\\ a_{31}&amp;a_{33} \end{vmatrix}
                + a_{13} \begin{vmatrix} a_{21}&amp;a_{22}\\ a_{31}&amp;a_{32} 
                \end{vmatrix}\\
                &amp;=&amp; a_{11}(a_{22}a_{33} - a_{23}a_{32}) - a_{12}(a_{21}a_{33} - a_{23}a_{31}) + a_{13}(a_{21}a_{32} - a_{22}a_{31})
\end{eqnarray*}\]</span>
<p>Let’s extend this now to any <span class="math inline">\(n\times n\)</span> matrix. Let’s define <span class="math inline">\({\bf A}_{ij}\)</span> as the <span class="math inline">\((n-1)\times (n-1)\)</span> submatrix of <span class="math inline">\({\bf A}\)</span> obtained by deleting row <span class="math inline">\(i\)</span> and column <span class="math inline">\(j\)</span>. Let the <span class="math inline">\((i,j)\)</span>th <strong>minor</strong> of <span class="math inline">\({\bf A}\)</span> be the determinant of <span class="math inline">\({\bf A}_{ij}\)</span>: <span class="math display">\[M_{ij}=|{\bf A}_{ij}|\]</span> Then for any <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\({\bf A}\)</span> <span class="math display">\[|{\bf A}|= a_{11}M_{11} - a_{12}M_{12} + \cdots + (-1)^{n+1} a_{1n} M_{1n}\]</span></p>
Example: Does the following matrix have an inverse? <span class="math display">\[{\bf A}=\begin{pmatrix} 1&amp;1&amp;1\\0&amp;2&amp;3\\5&amp;5&amp;1 \end{pmatrix}\]</span> 1. Calculate its determinant.
<span class="math display">\[\begin{eqnarray}
                &amp;=&amp; 1(2-15) - 1(0-15) + 1(0-10) \nonumber\\
                &amp;=&amp; -13+15-10 \nonumber\\
                &amp;=&amp; -8\nonumber
\end{eqnarray}\]</span>
<ol start="2" style="list-style-type: decimal">
<li>Since <span class="math inline">\(|{\bf A}|\ne 0\)</span>, we conclude that <span class="math inline">\({\bf A}\)</span> has an inverse.</li>
</ol>
<p><strong>Determinant of Triangular or Diagonal Matrices</strong>: For any upper-triangular, lower-triangular, or diagonal matrix, the determinant is just the product of the diagonal terms.</p>
<p>Example: Suppose we have the following square matrix in row echelon form (i.e., upper triangular) <span class="math display">\[{\bf R} =\begin{pmatrix} r_{11}&amp;r_{12}&amp;r_{13}\\
            0&amp;r_{22}&amp;r_{23}\\
            0&amp;     0&amp;r_{33} \end{pmatrix}\]</span></p>
<p>Then <span class="math display">\[|{\bf R}| = r_{11} \begin{vmatrix} r_{22}&amp;r_{23}\\ 0&amp;r_{33} \end{vmatrix} = r_{11}r_{22}r_{33}\]</span></p>
<p><strong>Properties of Determinants</strong>:</p>

</div>
<div id="getting-inverse-of-a-matrix-using-its-determinant-and-matrix-of-cofactors" class="section level2">
<h2><span class="header-section-number">2.13</span> Getting Inverse of a Matrix using its Determinant and Matrix of Cofactors</h2>
<p>Thus far, we have a number of algorithms to</p>
<ol style="list-style-type: decimal">
<li>Find the solution of a linear system,</li>
<li>Find the inverse of a matrix</li>
</ol>
<p>but these remain just that — algorithms. At this point, we have no way of telling how the solutions <span class="math inline">\(x_j\)</span> change as the parameters <span class="math inline">\(a_{ij}\)</span> and <span class="math inline">\(b_i\)</span> change, except by changing the values and “rerunning” the algorithms.</p>
<p>With determinants, we can 1. Provide an explicit formula for the inverse, and 2. Provide an explicit formula for the solution of an <span class="math inline">\(n\times n\)</span> linear system.</p>
<p>Hence, we can examine how changes in the parameters and <span class="math inline">\(b_i\)</span> affect the solutions <span class="math inline">\(x_j\)</span>.</p>
<p><strong>Determinant Formula for the Inverse of a <span class="math inline">\(2 \times 2\)</span></strong>: The determinant of a <span class="math inline">\(2 \times 2\)</span> matrix <strong>A</strong> <span class="math inline">\(\begin{pmatrix} a &amp; b\\ c &amp; d\\ \end{pmatrix}\)</span> is defined as: <span class="math display">\[\frac{1}{\det({\bf A})} \begin{pmatrix}
            d &amp; -b\\
            -c &amp; a\\
        \end{pmatrix}\]</span></p>
</div>
<div id="inverse-of-larger-matrices" class="section level2">
<h2><span class="header-section-number">2.14</span> Inverse of Larger Matrices</h2>
<p><strong>Cofactors and Adjoint Matrices</strong>:</p>
<p>First define the <span class="math inline">\((i,j)\)</span>th <strong>cofactor</strong> <span class="math inline">\(C_{ij}\)</span> of <span class="math inline">\({\bf A}\)</span> as <span class="math inline">\((-1)^{i+j}M_{ij}\)</span>. Recall that <span class="math inline">\(M_{ij}\)</span> is the minor of <strong>A</strong>, defined as the determinant of the matrix that results from removing row <span class="math inline">\(i\)</span> and column <span class="math inline">\(j\)</span> from <strong>A</strong>.</p>
<p>Then define the <strong>adjoint</strong> of <span class="math inline">\({\bf A}\)</span> as the <span class="math inline">\(n\times n\)</span> matrix whose <span class="math inline">\((i,j)\)</span>th entry is <span class="math inline">\(C_{ji}\)</span> (notice the switch in indices!). In other words, adj(<span class="math inline">\({\bf A}\)</span>) is the transpose of the cofactor matrix of <span class="math inline">\({\bf A}\)</span>.</p>
<p>Then the inverse of <span class="math inline">\({\bf A}\)</span> is defined as the reciprocal of the determinant of <strong>A</strong> times its adjoint, given by the formula <span class="math display">\[{\bf A}^{-1}=\frac{1}{|{\bf A}|}\mbox{adj\,}{\bf A}= 
        \begin{pmatrix}
            \frac{C_{11}}{|{\bf A}|}&amp;\frac{C_{21}}{|{\bf A}|}&amp;\cdots&amp;\frac{C_{n1}}{|{\bf A}|}\\[6pt]
            \frac{C_{12}}{|{\bf A}|}&amp;\frac{C_{22}}{|{\bf A}|}&amp;\cdots&amp;\frac{C_{n2}}{|{\bf A}|}\\[6pt]
            \vdots     &amp;\vdots     &amp;\ddots&amp;\vdots \\[6pt]
            \frac{C_{1n}}{|{\bf A}|}&amp;\frac{C_{2n}}{|{\bf A}|}&amp;\cdots&amp;\frac{C_{nn}}{|{\bf A}|}
        \end{pmatrix}\]</span></p>
<p>Exercises:</p>
<p>Let <span class="math inline">\({\bf A}=\begin{pmatrix} 5&amp;1&amp;3\\0&amp;2&amp;3\\5&amp;5&amp;1 \end{pmatrix}\)</span></p>
<ol style="list-style-type: decimal">
<li>Find the determinant of <strong>A</strong>.
<span class="math display">\[\begin{eqnarray*}
            \det{\bf A} &amp;=&amp; \phantom{5\cdot(2\cdot 1 - 3\cdot 5) - 1\cdot(0\cdot 1 - 3\cdot 5) + 3\cdot(2\cdot 5 - 0\cdot 5)}\\
            &amp;=&amp; \phantom{5\cdot(-13) - (-15) + 3\cdot(-10)}\\
            &amp;=&amp; \phantom{-65 + 15 - 30}\\
            &amp;=&amp; \phantom{-80}
        \end{eqnarray*}\]</span></li>
<li>Find the adjoint matrix of <strong>A</strong>.</li>
</ol>
<p>adj({}) = </p>
<ol start="3" style="list-style-type: decimal">
<li>Find the inverse of {}.</li>
</ol>
<p><span class="math inline">\({\bf A}^{-1}\)</span> = </p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="functions-and-notation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["prefresher.pdf", "prefresher.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
