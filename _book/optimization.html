<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Math (P)refresher for Political Scientists</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Math (P)refresher for Political Scientists" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Math (P)refresher for Political Scientists" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Shiro Kuriwaki and Yon Soo Park">


<meta name="date" content="2018-06-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="calculus-ii.html">
<link rel="next" href="references.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome</a></li>
<li class="chapter" data-level="2" data-path="linear-algebra.html"><a href="linear-algebra.html"><i class="fa fa-check"></i><b>2</b> Linear Algebra</a><ul>
<li class="chapter" data-level="2.1" data-path="linear-algebra.html"><a href="linear-algebra.html#working-with-vectors"><i class="fa fa-check"></i><b>2.1</b> Working with Vectors</a></li>
<li class="chapter" data-level="2.2" data-path="linear-algebra.html"><a href="linear-algebra.html#linear-independence"><i class="fa fa-check"></i><b>2.2</b> Linear Independence</a></li>
<li class="chapter" data-level="2.3" data-path="linear-algebra.html"><a href="linear-algebra.html#basics-of-matrix-algebra"><i class="fa fa-check"></i><b>2.3</b> Basics of Matrix Algebra</a></li>
<li class="chapter" data-level="2.4" data-path="linear-algebra.html"><a href="linear-algebra.html#square-matrices"><i class="fa fa-check"></i><b>2.4</b> Square Matrices</a></li>
<li class="chapter" data-level="2.5" data-path="linear-algebra.html"><a href="linear-algebra.html#linear-equations"><i class="fa fa-check"></i><b>2.5</b> Linear Equations</a></li>
<li class="chapter" data-level="2.6" data-path="linear-algebra.html"><a href="linear-algebra.html#systems-of-linear-equations"><i class="fa fa-check"></i><b>2.6</b> Systems of Linear Equations</a></li>
<li class="chapter" data-level="2.7" data-path="linear-algebra.html"><a href="linear-algebra.html#systems-of-equations-as-matrices"><i class="fa fa-check"></i><b>2.7</b> Systems of Equations as Matrices</a></li>
<li class="chapter" data-level="2.8" data-path="linear-algebra.html"><a href="linear-algebra.html#finding-solutions-to-augmented-matrices-and-systems-of-equations"><i class="fa fa-check"></i><b>2.8</b> Finding Solutions to Augmented Matrices and Systems of Equations</a></li>
<li class="chapter" data-level="2.9" data-path="linear-algebra.html"><a href="linear-algebra.html#rank-and-whether-a-system-has-one-infinite-or-no-solutions"><i class="fa fa-check"></i><b>2.9</b> Rank — and Whether a System Has One, Infinite, or No Solutions</a></li>
<li class="chapter" data-level="2.10" data-path="linear-algebra.html"><a href="linear-algebra.html#the-inverse-of-a-matrix"><i class="fa fa-check"></i><b>2.10</b> The Inverse of a Matrix</a></li>
<li class="chapter" data-level="2.11" data-path="linear-algebra.html"><a href="linear-algebra.html#linear-systems-and-inverses"><i class="fa fa-check"></i><b>2.11</b> Linear Systems and Inverses</a></li>
<li class="chapter" data-level="2.12" data-path="linear-algebra.html"><a href="linear-algebra.html#determinants"><i class="fa fa-check"></i><b>2.12</b> Determinants</a></li>
<li class="chapter" data-level="2.13" data-path="linear-algebra.html"><a href="linear-algebra.html#getting-inverse-of-a-matrix-using-its-determinant-and-matrix-of-cofactors"><i class="fa fa-check"></i><b>2.13</b> Getting Inverse of a Matrix using its Determinant and Matrix of Cofactors</a></li>
<li class="chapter" data-level="2.14" data-path="linear-algebra.html"><a href="linear-algebra.html#inverse-of-larger-matrices"><i class="fa fa-check"></i><b>2.14</b> Inverse of Larger Matrices</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="functions-and-notation.html"><a href="functions-and-notation.html"><i class="fa fa-check"></i><b>3</b> Functions and Notation</a><ul>
<li class="chapter" data-level="3.1" data-path="functions-and-notation.html"><a href="functions-and-notation.html#dimensionality"><i class="fa fa-check"></i><b>3.1</b> Dimensionality</a></li>
<li class="chapter" data-level="3.2" data-path="functions-and-notation.html"><a href="functions-and-notation.html#interval-notation-for-bf-r1"><i class="fa fa-check"></i><b>3.2</b> Interval Notation for <span class="math inline">\({\bf R}^1\)</span></a></li>
<li class="chapter" data-level="3.3" data-path="functions-and-notation.html"><a href="functions-and-notation.html#neighborhoods-intervals-disks-and-balls"><i class="fa fa-check"></i><b>3.3</b> Neighborhoods: Intervals, Disks, and Balls</a></li>
<li class="chapter" data-level="3.4" data-path="functions-and-notation.html"><a href="functions-and-notation.html#introduction-to-functions"><i class="fa fa-check"></i><b>3.4</b> Introduction to Functions</a></li>
<li class="chapter" data-level="3.5" data-path="functions-and-notation.html"><a href="functions-and-notation.html#domain-and-rangeimage"><i class="fa fa-check"></i><b>3.5</b> Domain and Range/Image</a></li>
<li class="chapter" data-level="3.6" data-path="functions-and-notation.html"><a href="functions-and-notation.html#some-general-types-of-functions"><i class="fa fa-check"></i><b>3.6</b> Some General Types of Functions</a></li>
<li class="chapter" data-level="3.7" data-path="functions-and-notation.html"><a href="functions-and-notation.html#log-ln-and-exp"><i class="fa fa-check"></i><b>3.7</b> <span class="math inline">\(\log\)</span>, <span class="math inline">\(\ln\)</span>, and <span class="math inline">\(\exp\)</span></a></li>
<li class="chapter" data-level="3.8" data-path="functions-and-notation.html"><a href="functions-and-notation.html#other-useful-functions"><i class="fa fa-check"></i><b>3.8</b> Other Useful Functions</a></li>
<li class="chapter" data-level="3.9" data-path="functions-and-notation.html"><a href="functions-and-notation.html#graphing-functions"><i class="fa fa-check"></i><b>3.9</b> Graphing Functions</a></li>
<li class="chapter" data-level="3.10" data-path="functions-and-notation.html"><a href="functions-and-notation.html#solving-for-variables-and-finding-inverses"><i class="fa fa-check"></i><b>3.10</b> Solving for Variables and Finding Inverses</a></li>
<li class="chapter" data-level="3.11" data-path="functions-and-notation.html"><a href="functions-and-notation.html#finding-the-roots-or-zeroes-of-a-function"><i class="fa fa-check"></i><b>3.11</b> Finding the Roots or Zeroes of a Function</a></li>
<li class="chapter" data-level="3.12" data-path="functions-and-notation.html"><a href="functions-and-notation.html#the-limit-of-a-function"><i class="fa fa-check"></i><b>3.12</b> The Limit of a Function</a></li>
<li class="chapter" data-level="3.13" data-path="functions-and-notation.html"><a href="functions-and-notation.html#continuity"><i class="fa fa-check"></i><b>3.13</b> Continuity</a></li>
<li class="chapter" data-level="3.14" data-path="functions-and-notation.html"><a href="functions-and-notation.html#sets"><i class="fa fa-check"></i><b>3.14</b> Sets</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="calculus-i.html"><a href="calculus-i.html"><i class="fa fa-check"></i><b>4</b> Calculus I</a><ul>
<li class="chapter" data-level="4.1" data-path="calculus-i.html"><a href="calculus-i.html#sequences"><i class="fa fa-check"></i><b>4.1</b> Sequences</a></li>
<li class="chapter" data-level="4.2" data-path="calculus-i.html"><a href="calculus-i.html#the-limit-of-a-sequence"><i class="fa fa-check"></i><b>4.2</b> The Limit of a Sequence</a></li>
<li class="chapter" data-level="4.3" data-path="calculus-i.html"><a href="calculus-i.html#series"><i class="fa fa-check"></i><b>4.3</b> Series</a></li>
<li class="chapter" data-level="4.4" data-path="calculus-i.html"><a href="calculus-i.html#derivatives"><i class="fa fa-check"></i><b>4.4</b> Derivatives</a></li>
<li class="chapter" data-level="4.5" data-path="calculus-i.html"><a href="calculus-i.html#higher-order-derivatives-or-derivatives-of-derivatives-of-derivatives"><i class="fa fa-check"></i><b>4.5</b> Higher-Order Derivatives or, Derivatives of Derivatives of Derivatives</a></li>
<li class="chapter" data-level="4.6" data-path="calculus-i.html"><a href="calculus-i.html#composite-functions-and-the-chain-rule"><i class="fa fa-check"></i><b>4.6</b> Composite Functions and the Chain Rule</a></li>
<li class="chapter" data-level="4.7" data-path="calculus-i.html"><a href="calculus-i.html#derivatives-of-eulers-number-and-natural-logs"><i class="fa fa-check"></i><b>4.7</b> Derivatives of Euler’s number and natural logs</a></li>
<li class="chapter" data-level="4.8" data-path="calculus-i.html"><a href="calculus-i.html#applications-of-the-derivative-maxima-and-minima"><i class="fa fa-check"></i><b>4.8</b> Applications of the Derivative: Maxima and Minima</a></li>
<li class="chapter" data-level="4.9" data-path="calculus-i.html"><a href="calculus-i.html#partial-derivatives"><i class="fa fa-check"></i><b>4.9</b> Partial Derivatives</a></li>
<li class="chapter" data-level="4.10" data-path="calculus-i.html"><a href="calculus-i.html#lhopitals-rule"><i class="fa fa-check"></i><b>4.10</b> L’H^opital’s Rule</a></li>
<li class="chapter" data-level="4.11" data-path="calculus-i.html"><a href="calculus-i.html#taylor-series-approximation"><i class="fa fa-check"></i><b>4.11</b> Taylor Series Approximation</a></li>
<li class="chapter" data-level="4.12" data-path="calculus-i.html"><a href="calculus-i.html#summary-derivative-calculus-in-6-steps"><i class="fa fa-check"></i><b>4.12</b> Summary: Derivative calculus in 6 steps</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="calculus-ii.html"><a href="calculus-ii.html"><i class="fa fa-check"></i><b>5</b> Calculus II</a><ul>
<li class="chapter" data-level="5.1" data-path="calculus-ii.html"><a href="calculus-ii.html#the-indefinite-integral-the-antiderivative"><i class="fa fa-check"></i><b>5.1</b> The Indefinite Integral: The Antiderivative</a></li>
<li class="chapter" data-level="5.2" data-path="calculus-ii.html"><a href="calculus-ii.html#common-rules-of-integration"><i class="fa fa-check"></i><b>5.2</b> Common Rules of Integration</a></li>
<li class="chapter" data-level="5.3" data-path="calculus-ii.html"><a href="calculus-ii.html#the-definite-integral-the-area-under-the-curve"><i class="fa fa-check"></i><b>5.3</b> The Definite Integral: The Area under the Curve</a></li>
<li class="chapter" data-level="5.4" data-path="calculus-ii.html"><a href="calculus-ii.html#integration-by-substitution"><i class="fa fa-check"></i><b>5.4</b> Integration by Substitution</a></li>
<li class="chapter" data-level="5.5" data-path="calculus-ii.html"><a href="calculus-ii.html#integration-by-parts-or-ultraviolet-voodoo"><i class="fa fa-check"></i><b>5.5</b> Integration by Parts, or Ultraviolet Voodoo</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="optimization.html"><a href="optimization.html"><i class="fa fa-check"></i><b>6</b> Optimization</a><ul>
<li class="chapter" data-level="6.1" data-path="optimization.html"><a href="optimization.html#quadratic-forms"><i class="fa fa-check"></i><b>6.1</b> Quadratic Forms</a></li>
<li class="chapter" data-level="6.2" data-path="optimization.html"><a href="optimization.html#concavity-of-quadratic-forms"><i class="fa fa-check"></i><b>6.2</b> Concavity of Quadratic Forms</a></li>
<li class="chapter" data-level="6.3" data-path="optimization.html"><a href="optimization.html#definiteness-of-quadratic-forms"><i class="fa fa-check"></i><b>6.3</b> Definiteness of Quadratic Forms</a></li>
<li class="chapter" data-level="6.4" data-path="optimization.html"><a href="optimization.html#first-order-conditions"><i class="fa fa-check"></i><b>6.4</b> First Order Conditions</a></li>
<li class="chapter" data-level="6.5" data-path="optimization.html"><a href="optimization.html#second-order-conditions"><i class="fa fa-check"></i><b>6.5</b> Second Order Conditions</a></li>
<li class="chapter" data-level="6.6" data-path="optimization.html"><a href="optimization.html#definiteness-and-concavity"><i class="fa fa-check"></i><b>6.6</b> Definiteness and Concavity</a></li>
<li class="chapter" data-level="6.7" data-path="optimization.html"><a href="optimization.html#global-maxima-and-minima"><i class="fa fa-check"></i><b>6.7</b> Global Maxima and Minima</a></li>
<li class="chapter" data-level="6.8" data-path="optimization.html"><a href="optimization.html#constrained-optimization"><i class="fa fa-check"></i><b>6.8</b> Constrained Optimization</a></li>
<li class="chapter" data-level="6.9" data-path="optimization.html"><a href="optimization.html#equality-constraints"><i class="fa fa-check"></i><b>6.9</b> Equality Constraints</a></li>
<li class="chapter" data-level="6.10" data-path="optimization.html"><a href="optimization.html#inequality-constraints"><i class="fa fa-check"></i><b>6.10</b> Inequality Constraints</a></li>
<li class="chapter" data-level="6.11" data-path="optimization.html"><a href="optimization.html#kuhn-tucker-conditions"><i class="fa fa-check"></i><b>6.11</b> Kuhn-Tucker Conditions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="7" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>7</b> Introduction</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Math (P)refresher for Political Scientists</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="optimization" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Optimization</h1>
<p>Topics:</p>
<p><span class="math inline">\(\bullet\)</span> Quadratic Forms <span class="math inline">\(\bullet\)</span> Definiteness of Quadratic Forms <span class="math inline">\(\bullet\)</span> Maxima and Minima in <span class="math inline">\({\bf R}^n\)</span> <span class="math inline">\(\bullet\)</span> First Order Conditions <span class="math inline">\(\bullet\)</span> Second Order Conditions <span class="math inline">\(\bullet\)</span> Global Maxima and Minima <span class="math inline">\(\bullet\)</span> Constrained Optimization <span class="math inline">\(\bullet\)</span> Equality Constraints <span class="math inline">\(\bullet\)</span> Inequality Constraints <span class="math inline">\(\bullet\)</span> Kuhn-Tucker Conditions</p>
<p>Much of the material and examples for this lecture are taken from Simon &amp; Blume (1994)  and Ecker &amp; Kupferschmid (1988) </p>
<div id="quadratic-forms" class="section level2">
<h2><span class="header-section-number">6.1</span> Quadratic Forms</h2>
<p>Quadratic forms important because 1. Approximates local curvature around a point — e.g., used to identify max vs min vs saddle point. 2. Simple, so easy to deal with. 3. Have a matrix representation.</p>
<p><strong>Quadratic Form</strong>: A polynomial where each term is a monomial of degree 2 in any number of variables:</p>
<span class="math display">\[\begin{align*}
\text{One variable: }&amp; Q(x_1) = a_{11}x_1^2\\
\text{Two variables: }&amp; Q(x_1,x_2) = a_{11}x_1^2 + a_{12}x_1x_2 + a_{22}x_2^2\\
\text{N variables: }&amp; Q(x_1,\cdots,x_n)=\sum\limits_{i\le j} a_{ij}x_i x_j
\end{align*}\]</span>
<p>which can be written in matrix terms:</p>
<span class="math display">\[\begin{align*}
\text{One variable: }&amp; Q({\bf x}) = x_1^T a_{11} x_1\\
\text{N variables: }&amp; Q({\bf x})=\begin{pmatrix} x1&amp;x2&amp;\cdots&amp;x_n\end{pmatrix}
\begin{pmatrix}
a_{11}&amp;\frac{1}{2}a_{12}&amp;\cdots&amp;\frac{1}{2}a_{1n}\\
\frac{1}{2}a_{12}&amp;a_{22}&amp;\cdots&amp;\frac{1}{2}a_{2n}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
\frac{1}{2}a_{1n}&amp;\frac{1}{2}a_{2n}&amp;\cdots&amp;a_{nn}
\end{pmatrix}
\begin{pmatrix} x_1\\x_2\\\vdots\\x_n\end{pmatrix}\\
&amp;={\bf x}^T{\bf A}{\bf x}
\end{align*}\]</span>
Examples:

</div>
<div id="concavity-of-quadratic-forms" class="section level2">
<h2><span class="header-section-number">6.2</span> Concavity of Quadratic Forms</h2>
<p>Concavity helps identify the curvature of a function, <span class="math inline">\(f( x)\)</span>, in 2 dimensional space.</p>










<p>: The second derivative can be used to understand concavity.</p>
<p>If <span class="math display">\[\begin{array}{lll}
f&#39;&#39;(x) &lt; 0 &amp; \Rightarrow &amp; \text{Concave}\\
f&#39;&#39;(x) &gt; 0 &amp; \Rightarrow &amp; \text{Convex}
\end{array}\]</span></p>
</div>
<div id="definiteness-of-quadratic-forms" class="section level2">
<h2><span class="header-section-number">6.3</span> Definiteness of Quadratic Forms</h2>
<p>Definiteness helps identify the curvature of a function, <span class="math inline">\(Q({\bf x})\)</span>, in n dimensional space.</p>
<p><strong>Definiteness</strong>: By definition, a quadratic form always takes on the value of zero when <span class="math inline">\(x = 0\)</span>, <span class="math inline">\(Q({\bf x})=0\)</span> at <span class="math inline">\({\bf x}=0\)</span>. The definiteness of the matrix <span class="math inline">\({\bf A}\)</span> is determined by whether the quadratic form <span class="math inline">\(Q({\bf x})={\bf x}^T{\bf A}{\bf x}\)</span> is greater than zero, less than zero, or sometimes both over all <span class="math inline">\({\bf x}\ne 0\)</span>.</p>

<p>Examples:</p>

</div>
<div id="first-order-conditions" class="section level2">
<h2><span class="header-section-number">6.4</span> First Order Conditions</h2>
<p>When we examined functions of one variable <span class="math inline">\(x\)</span>, we found critical points by taking the first derivative, setting it to zero, and solving for <span class="math inline">\(x\)</span>. For functions of <span class="math inline">\(n\)</span> variables, the critical points are found in much the same way, except now we set the partial derivatives equal to zero.</p>
<p><strong>Gradient</strong> (<span class="math inline">\(\nabla \fx\)</span>): Given a function <span class="math inline">\(f({\bf x})\)</span> in <span class="math inline">\(n\)</span> variables, the gradient <span class="math inline">\(\nabla \fx\)</span> is a column vector, where the <span class="math inline">\(i\)</span>th element is the partial derivative of <span class="math inline">\(f({\bf x})\)</span> with respect to <span class="math inline">\(x_i\)</span>:</p>
<p><span class="math display">\[\nabla \fx = \begin{pmatrix}
\frac{\partial \fx}{\partial x_1}\\[9pt] \frac{\partial \fx}{\partial x_2}\\
  \vdots \\[3pt] \frac{\partial \fx}{\partial x_n} \end{pmatrix}\]</span></p>
<p><strong>Critical Point</strong>: <span class="math inline">\({\bf x}^*\)</span> is a critical point iff <span class="math inline">\(\nabla f({\bf x}^*)=0\)</span>. If the partial derivative of f(x) with respect to <span class="math inline">\(x^*\)</span> is 0, then <span class="math inline">\({\bf x}^*\)</span> is a critical point. To solve for <span class="math inline">\({\bf x}^*\)</span>, find the gradient, set each element equal to 0, and solve the system of equations. <span class="math display">\[{\bf x}^* = \begin{pmatrix} x_1^*\\x_2^*\\ \vdots \\ x_n^*\end{pmatrix}\]</span></p>
Example: Given a function <span class="math inline">\(\fx=(x_1-1)^2+x_2^2+1\)</span>, find the:

<p>\end{itemize}</p>
</div>
<div id="second-order-conditions" class="section level2">
<h2><span class="header-section-number">6.5</span> Second Order Conditions</h2>
<p>When we found a critical point for a function of one variable, we used the second derivative as an indicator of the curvature at the point in order to determine whether the point was a min, max, or saddle (second derivative test of concavity). For functions of <span class="math inline">\(n\)</span> variables, we use  as an indicator of curvature.</p>
<p><strong>Hessian</strong> (<span class="math inline">\({\bf H(x)}\)</span>): Given a function <span class="math inline">\(f({\bf x})\)</span> in <span class="math inline">\(n\)</span> variables, the hessian <span class="math inline">\({\bf H(x)}\)</span> is an <span class="math inline">\(n\times n\)</span> matrix, where the <span class="math inline">\((i,j)\)</span>th element is the second order partial derivative of <span class="math inline">\(f({\bf x})\)</span> with respect to <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span>:</p>
<p><span class="math display">\[{\bf H(x)}=\begin{pmatrix}
\frac{\partial^2 \fx}{\partial x_1^2}&amp;\frac{\partial^2\fx}{\partial x_1 \partial x_2}&amp;
\cdots &amp; \frac{\partial^2 \fx}{\partial x_1 \partial x_n}\\[9pt]
\frac{\partial^2 \fx}{\partial x_2 \partial x_1}&amp;\frac{\partial^2\fx}{\partial x_2^2}&amp;
\cdots &amp; \frac{\partial^2 \fx}{\partial x_2 \partial x_n}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\[3pt]
\frac{\partial^2 \fx}{\partial x_n \partial x_1}&amp;\frac{\partial^2\fx}{\partial x_n \partial x_2}&amp;
\cdots &amp; \frac{\partial^2 \fx}{\partial x_n^2}\end{pmatrix}\]</span></p>
<p>Note that the hessian will be a symmetric matrix because <span class="math inline">\(\frac{\partial \fx}{\partial x_1\partial x_2} = \frac{\partial \fx}{\partial x_2\partial x_1}\)</span>.</p>
<p>Also note that given that <span class="math inline">\(\fx\)</span> is of quadratic form, each element of the hessian will be a constant.</p>

<p><strong>Second Order Conditions</strong>:\[6pt] Given a function <span class="math inline">\(\fx\)</span> and a point <span class="math inline">\({\bf x}^*\)</span> such that <span class="math inline">\(\nabla f({\bf x}^*)=0\)</span>,</p>


Example: We found that the only critical point of <span class="math inline">\(\fx=(x_1-1)^2+x_2^2+1\)</span> is at <span class="math inline">\({\bf x}^*=(1,0)\)</span>. Is it a min, max, or saddle point?

</div>
<div id="definiteness-and-concavity" class="section level2">
<h2><span class="header-section-number">6.6</span> Definiteness and Concavity</h2>
<p>Although definiteness helps us to understand the curvature of an n-dimensional function, it does not necessarily tell us whether the function is globally concave or convex.</p>
<p>We need to know whether a function is globally concave or convex to determine whether a critical point is a global min or max.</p>
<p><strong>Testing for Global Concavity</strong>: We can use the definiteness of the Hessian to determine whether a function is globally concave or convex:</p>

<p>Notice that the definiteness conditions must be satisfied over the entire domain.</p>
</div>
<div id="global-maxima-and-minima" class="section level2">
<h2><span class="header-section-number">6.7</span> Global Maxima and Minima</h2>
<p><strong>Global Max/Min Conditions</strong>: Given a function <span class="math inline">\(\fx\)</span> and a point <span class="math inline">\({\bf x}^*\)</span> such that <span class="math inline">\(\nabla f({\bf x}^*)=0\)</span>,</p>

<p>Note that showing that <span class="math inline">\(\bf H(x^*)\)</span> is negative semidefinite is not enough to guarantee <span class="math inline">\({\bf x}^*\)</span> is a local max. However, showing that <span class="math inline">\(\bf H(x)\)</span> is negative semidefinite for all <span class="math inline">\({\bf x}\)</span> guarantees that <span class="math inline">\(x^*\)</span> is a global max. (The same goes for positive semidefinite and minima.)\</p>
<p>Example: Take <span class="math inline">\(f_1(x)=x^4\)</span> and <span class="math inline">\(f_2(x)=-x^4\)</span>. Both have <span class="math inline">\(x=0\)</span> as a critical point. Unfortunately, <span class="math inline">\(f&#39;&#39;_1(0)=0\)</span> and <span class="math inline">\(f&#39;&#39;_2(0)=0\)</span>, so we can’t tell whether <span class="math inline">\(x=0\)</span> is a min or max for either. However, <span class="math inline">\(f&#39;&#39;_1(x)=12x^2\)</span> and <span class="math inline">\(f&#39;&#39;_2(x)=-12x^2\)</span>. For all <span class="math inline">\(x\)</span>, <span class="math inline">\(f&#39;&#39;_1(x)\ge 0\)</span> and <span class="math inline">\(f&#39;&#39;_2(x)\le 0\)</span> — i.e., <span class="math inline">\(f_1(x)\)</span> is globally convex and <span class="math inline">\(f_2(x)\)</span> is globally concave. So <span class="math inline">\(x=0\)</span> is a global min of <span class="math inline">\(f_1(x)\)</span> and a global max of <span class="math inline">\(f_2(x)\)</span>.</p>
<p>Example</p>
Given <span class="math inline">\(f({\bf x})=x_1^3-x_2^3+9x_1x_2\)</span>, find any maxima or minima.

</div>
<div id="constrained-optimization" class="section level2">
<h2><span class="header-section-number">6.8</span> Constrained Optimization</h2>
<p>We have already looked at optimizing a function in one or more dimensions over the whole domain of the function. Often, however, we want to find the maximum or minimum of a function over some restricted part of its domain.\ ex: Maximizing utility subject to a budget constraint</p>

<strong>Types of Constraints</strong>: For a function <span class="math inline">\(f(x_1, \dots, x_n)\)</span>, there are two types of constraints that can be imposed:

<p>In any constrained optimization problem, the constrained maximum will always be less than or equal to the unconstrained maximum. If the constrained maximum is less than the unconstrained maximum, then the constraint is binding. Essentially, this means that you can treat your constraint as an equality constraint rather than an inequality constraint.</p>
<p>For example, the budget constraint binds when you spend your entire budget. This generally happens because we believe that utility is strictly increasing in consumption, i.e. you always want more so you spend everything you have.</p>
<p>Any number of constraints can be placed on an optimization problem. When working with multiple constraints, always make sure that the set of constraints are not pathological; it must be possible for all of the constraints to be satisfied simultaneously.</p>
<p> <span class="math display">\[\max_{x_1,x_2} f(x_1,x_2) \text{ s.t. } c(x_1,x_2)\]</span> <span class="math display">\[\min_{x_1,x_2} f(x_1,x_2) \text{ s.t. } c(x_1,x_2)\]</span> This tells us to maximize/minimize our function, <span class="math inline">\(f(x_1,x_2)\)</span>, with respect to the choice variables, <span class="math inline">\(x_1,x_2\)</span>, subject to the constraint.</p>
<p>Example: <span class="math display">\[\max_{x_1,x_2} f(x_1, x_2) = -(x_1^2 + 2x_2^2) \text{ s.t. }x_1 + x_2 = 4\]</span> It is easy to see that the  maximum occurs at <span class="math inline">\((x_1, x_2) = (0,0)\)</span>, but that does not satisfy the constraint. How should we proceed?</p>
</div>
<div id="equality-constraints" class="section level2">
<h2><span class="header-section-number">6.9</span> Equality Constraints</h2>
<p>Equality constraints are the easiest to deal with because we know that the maximum or minimum has to lie on the (intersection of the) constraint(s).</p>
<p>The trick is to change the problem from a constrained optimization problem in <span class="math inline">\(n\)</span> variables to an unconstrained optimization problem in <span class="math inline">\(n + k\)</span> variables, adding  variable for  equality constraint. We do this using a lagrangian multiplier.</p>
<p><strong>Lagrangian function</strong>: The Lagrangian function allows us to combine the function we want to optimize and the constraint function into a single function. Once we have this single function, we can proceed as if this were an  optimization problem.\</p>
<p>For each constraint, we must include a  (<span class="math inline">\(\lambda_i\)</span>) as an additional variable in the analysis. These terms are the link between the constraint and the Lagrangian function.\</p>
<p>Given a  set-up: <span class="math display">\[\max_{x_1,x_2}/\min_{x_1,x_2} f(x_1,x_2) \text{ s.t. } c(x_1,x_2) = a\]</span></p>
<p>We define the Lagrangian function <span class="math inline">\(L(x_1,x_2,\lambda_1)\)</span> as follows: <span class="math display">\[L(x_1,x_2,\lambda_1) = f(x_1,x_2) - \lambda_1 (c(x_1,x_2) - a)\]</span></p>
<p>More generally, in : <span class="math display">\[ L(x_1, \dots, x_n, \lambda_1, \dots, \lambda_k) = f(x_1, \dots, x_n) - \sum_{i=1}^k\lambda_i(c_i(x_1,\dots, x_n) - r_i)\]</span></p>
<p>\ Note that above we subtract the lagrangian term  we subtract the constraint constant from the constraint function. Occasionally, you may see the following alternative form of the Lagrangian, which is : <span class="math display">\[ L(x_1, \dots, x_n, \lambda_1, \dots, \lambda_k) = f(x_1, \dots, x_n) + \sum_{i=1}^k\lambda_i(r_i - c_i(x_1,\dots, x_n))\]</span> Here we add the lagrangian term  we subtract the constraing function from the constraint constant.</p>
<p>: To find the critical points, we take the partial derivatives of lagrangian function, <span class="math inline">\(L(x_1, \dots, x_n, \lambda_1, \dots, \lambda_k)\)</span>, with respect to each of its variables (all choice variables <span class="math inline">\({\bf x}\)</span>  all lagrangian multipliers <span class="math inline">\({\bf \lambda}\)</span>). At a critical point,  of these partial derivatives must be equal to zero, so we obtain a system of :</p>
<span class="math display">\[\begin{eqnarray*}
\frac{\partial L}{\partial x_1} = \frac{\partial f}{\partial x_1} - \sum_{i = 1}^k\lambda_i\frac{\partial c_i}{\partial x_1} &amp; = &amp; 0\\
 \vdots &amp; = &amp; \vdots \nonumber \\ 
\frac{\partial L}{\partial x_n}  = \frac{\partial f}{\partial x_n} - \sum_{i = 1}^k\lambda_i\frac{\partial c_i}{\partial x_n} &amp; =  &amp; 0\\
\frac{\partial L}{\partial \lambda_1} = c_1(x_i, \dots, x_n) - r_1&amp; = &amp; 0\\
 \vdots &amp; = &amp; \vdots \nonumber \\
\frac{\partial L}{\partial \lambda_k} = c_k(x_i, \dots, x_n) - r_k &amp; = &amp; 0
\end{eqnarray*}\]</span>
<p>We can then solve this system of equations, because there are <span class="math inline">\(n+k\)</span> equations and <span class="math inline">\(n+k\)</span> unknowns, to calculate the critical point <span class="math inline">\((x_1^*,\dots,x_n^*,\lambda_1^*,\dots,\lambda_k^*)\)</span>.</p>
<p> There may be more than one critical point, i.e. we need to verify that the critical point we find is a maximum/minimum. Similar to unconstrained optimization, we can do this by checking the second-order conditions.</p>
<p>Example:<br />
<span class="math display">\[\max_{x_1,x_2} f(x) = -(x_1^2 + 2x_2^2) \text{ s.t. } x_1 + x_2 = 4\]</span></p>

<p>Notice that when we take the partial derivative of L with respect to the lagranigian multiplier and set it equal to 0, we return exactly our constraint! This is why signs matter.</p>
</div>
<div id="inequality-constraints" class="section level2">
<h2><span class="header-section-number">6.10</span> Inequality Constraints</h2>
<p>Inequality constraints define the boundary of a region over which we seek to optimize the function. This makes inequality constraints more challenging because we do not know if the maximum/minimum lies along one of the constraints (the constraint binds) or in the interior of the region.</p>
<p>We must introduce more variables in order to turn the problem into an unconstrained optimization.</p>
<p><strong>Slack:</strong> For  inequality constraint <span class="math inline">\(c_i(x_1, \dots, x_n) \leq a_i\)</span>, we define a slack variable <span class="math inline">\(s_i^2\)</span> for which the expression <span class="math inline">\(c_i(x_1, \dots, x_n) \leq a_i - s_i^2\)</span> would hold with equality. These slack variables capture how close the constraint comes to binding. We use <span class="math inline">\(s^2\)</span> rather than <span class="math inline">\(s\)</span> to ensure that the slack is positive.</p>
<p>Slack is just a way to transform our constraints.</p>
<p>Given a  set-up and these edited constraints: <span class="math display">\[\max_{x_1,x_2}/\min_{x_1,x_2} f(x_1,x_2) \text{ s.t. } c(x_1,x_2) \le a_1\]</span></p>
<p>Adding in Slack: <span class="math display">\[\max_{x_1,x_2}/\min_{x_1,x_2} f(x_1,x_2) \text{ s.t. } c(x_1,x_2) \le a_1 - s_1^2\]</span></p>
<p>We define the Lagrangian function <span class="math inline">\(L(x_1,x_2,\lambda_1,s_1)\)</span> as follows: <span class="math display">\[L(x_1,x_2,\lambda_1,s_1) = f(x_1,x_2) - \lambda_1 ( c(x_1,x_2) + s_1^2 - a_1)\]</span></p>
<p>More generally, in : <span class="math display">\[ L(x_1, \dots, x_n, \lambda_1, \dots, \lambda_k, s_1, \dots, s_k) = f(x_1, \dots, x_n) - \sum_{i = 1}^k \lambda_i(c_i(x_1,\dots, x_n) + s_i^2 - a_i)\]</span></p>
<p>: To find the critical points, we take the partial derivatives of the lagrangian function, <span class="math inline">\(L(x_1,\dots,x_n,\lambda_1,\dots,\lambda_k,s_1,\dots,s_k)\)</span>, with respect to each of its variables (all choice variables <span class="math inline">\(x\)</span>, all lagrangian multipliers <span class="math inline">\(\lambda\)</span>, and all slack variables <span class="math inline">\(s\)</span>). At a critical point,  of these partial derivatives must be equal to zero, so we obtain a system of :</p>
<span class="math display">\[\begin{eqnarray*}
\frac{\partial L}{\partial x_1} = \frac{\partial f}{\partial x_1} - \sum_{i = 1}^k\lambda_i\frac{\partial c_i}{\partial x_1} &amp; = &amp; 0\\
 \vdots &amp; = &amp; \vdots \nonumber \\
\frac{\partial L}{\partial x_n}  = \frac{\partial f}{\partial x_n} - \sum_{i = 1}^k\lambda_i\frac{\partial c_i}{\partial x_n} &amp; =  &amp; 0\\
\frac{\partial L}{\partial \lambda_1} = c_1(x_i, \dots, x_n) + s_1^2 - b_1&amp; = &amp; 0\\
 \vdots &amp; = &amp; \vdots \nonumber \\
\frac{\partial L}{\partial \lambda_k} = c_k(x_i, \dots, x_n) + s_k^2 - b_k &amp; = &amp; 0\\
\frac{\partial L}{\partial s_1} = 2s_1\lambda_1 &amp; = &amp; 0\\
 \vdots &amp; = &amp; \vdots \nonumber \\
\frac{\partial L}{\partial s_k} = 2s_k\lambda_k &amp; = &amp; 0
\end{eqnarray*}\]</span>
<p>: The last set of first order conditions of the form <span class="math inline">\(2s_i\lambda_i = 0\)</span> (the partials taken with respect to the slack variables) are known as complementary slackness conditions. These conditions can be satisfied one of three ways:</p>

Example: Find the critical points for the following constrained optimization: <span class="math display">\[\max_{x_1,x_2} f(x) = -(x_1^2 + 2x_2^2) \text{ s.t. } x_1 + x_2 \le 4\]</span>

<p>Example: Find the critical points for the following constrained optimization: <span class="math display">\[\max_{x_1,x_2} f(x) = -(x_1^2 + 2x_2^2) \text{ s.t. } 
\begin{array}{l}
x_1 + x_2 \le 4\\
x_1 \ge 0\\
x_2 \ge 0
\end{array}\]</span></p>

</div>
<div id="kuhn-tucker-conditions" class="section level2">
<h2><span class="header-section-number">6.11</span> Kuhn-Tucker Conditions</h2>
<p>As you can see, this can be a pain. When dealing explicitly with , this process is simplified by using the Kuhn-Tucker method.</p>
<p>: Because the problem of maximizing a function subject to inequality and non-negativity constraints arises frequently in economics, the Kuhn-Tucker approach provides a method that often makes it easier to both calculate the critical points and identify points that are (local) maxima.\</p>
<p>Given a : <span class="math display">\[\max_{x_1,x_2}/\min_{x_1,x_2} f(x_1,x_2) \text{ s.t. }
\begin{array}{l}
c(x_1,x_2) \le a_1\\
x_1 \ge 0 \\
gx_2 \ge 0
\end{array}\]</span></p>
<p>We define the Lagrangian function <span class="math inline">\(L(x_1,x_2,\lambda_1)\)</span> the same as if we did not have the non-negativity constraints: <span class="math display">\[L(x_1,x_2,\lambda_2) = f(x_1,x_2) - \lambda_1(c(x_1,x_2) - a_1)\]</span></p>
<p>More generally, in : <span class="math display">\[ L(x_1, \dots, x_n, \lambda_1, \dots, \lambda_k) = f(x_1, \dots, x_n) - \sum_{i=1}^k\lambda_i(c_i(x_1,\dots, x_n) - a_i)\]</span></p>
<p>: To find the critical points, we first calculate the  by taking the partial derivatives of the lagrangian function, <span class="math inline">\(L(x_1,\dots,x_n,\lambda_1,\dots,\lambda_k)\)</span>, with respect to each of its variables (all choice variable s<span class="math inline">\(x\)</span> and all lagrangian multipliers <span class="math inline">\(\lambda\)</span>)  we calculate the  by multiplying each partial derivative by its respective variable  include  for all variables (choice variables <span class="math inline">\(x\)</span> and lagrangian multipliers <span class="math inline">\(\lambda\)</span>).\</p>

<span class="math display">\[\begin{eqnarray*}
\frac{\partial L}{\partial x_1} \leq 0, &amp; \dots, &amp; \frac{\partial L}{\partial x_n} \leq 0\\
\frac{\partial L}{\partial \lambda_1} \geq 0, &amp; \dots, &amp; \frac{\partial L}{\partial \lambda_m} \geq 0
\end{eqnarray*}\]</span>

<span class="math display">\[\begin{eqnarray*}
x_1\frac{\partial L}{\partial x_1} = 0, &amp; \dots, &amp; x_n\frac{\partial L}{\partial x_n} = 0\\
\lambda_1\frac{\partial L}{\partial \lambda_1} = 0, &amp; \dots, &amp; \lambda_m \frac{\partial L}{\partial \lambda_m} = 0
\end{eqnarray*}\]</span>

<span class="math display">\[\begin{eqnarray*}
x_1 \geq 0 &amp; \dots &amp; x_n \geq 0\\
\lambda_1 \geq 0 &amp; \dots &amp; \lambda_m \geq 0
\end{eqnarray*}\]</span>
<p>Note that some of these conditions are set equal to 0, while others are set as inequalities!\</p>
<p>Note also that to minimize the function <span class="math inline">\(f(x_1, \dots, x_n)\)</span>, the simplest thing to do is maximize the function <span class="math inline">\(-f(x_1, \dots, x_n)\)</span>; all of the conditions remain the same after reformulating as a maximization problem.\</p>
<p>There are additional assumptions (notably, f(x) is quasi-concave and the constraints are convex) that are sufficient to ensure that a point satisfying the Kuhn-Tucker conditions is a global max; if these assumptions do not hold, you may have to check more than one point.</p>
<p>: Given the above conditions, to find the critical points we solve the above system of equations. To do so, we must check  border and interior solutions to see if they satisfy the above conditions.</p>
In a two-dimensional set-up, this means we must check the following cases:

<p>Example: <span class="math display">\[\max_{x_1,x_2} f(x) = -(x_1^2 + 2x_2^2) \text{ s.t. } 
\begin{array}{l}
x_1 + x_2 \le 4\\
x_1 \ge 0\\
x_2 \ge 0
\end{array}\]</span></p>

<p>Example:</p>
<p><span class="math display">\[\max_{x_1,x_2} f(x) = \frac{1}{3}\log (x_1 + 1) + \frac{2}{3}\log (x_2 + 1) \text{ s.t. }  
\begin{array}{l}
x_1 + 2x_2 \leq 4\\
     x_1 \geq 0\\
    x_2 \geq 0
\end{array}\]</span></p>


</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="calculus-ii.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["prefresher.pdf", "prefresher.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
