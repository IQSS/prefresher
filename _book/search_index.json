[
["index.html", "Math Prefresher for Political Scientists About this Booklet", " Math Prefresher for Political Scientists 2018-07-06 About this Booklet The Prefresher is held each in the Gov department. See our website https://projects.iq.harvard.edu/prefresher. The 2018 Prefresher Instructors are Shiro Kuriwaki and Yon Soo Park, and the faculty sponsor is Gary King. The documents in this booklet are the product of generations of Math (P)refresher Instructors: Curt Signorino 1996-1997; Ken Scheve 1997-1998; Eric Dickson 1998-2000; Orit Kedar 1999; James Fowler 2000-2001; Kosuke Imai 2001-2002; Jacob Kline 2002; Dan Epstein 2003; Ben Ansell 2003-2004; Ryan Moore 2004-2005; Mike Kellermann 2005-2006; Ellie Powell 2006-2007; Jen Katkin 2007-2008; Patrick Lam 2008-2009; Viridiana Rios 2009-2010; Jennifer Pan 2010-2011; Konstantin Kashin 2011-2012; Sol'{e} Prillaman 2013; Stephen Pettigrew 2013-2014; Anton Strezhnev 2014-2015; Mayya Komisarchik 2015-2016; Connor Jerzak 2016-2017; Shiro Kuriwaki 2017-2018; Yon Soo Park 2018- "],
["pre-prefresher-exercises.html", "Chapter 1 Pre-PreFresher Exercises 1.1 Linear Algebra 1.2 Operations 1.3 Limits 1.4 Calculus 1.5 Probability", " Chapter 1 Pre-PreFresher Exercises 1.1 Linear Algebra 1.2 Operations Simplify the following \\(\\sum^3_{i = 1} i\\) \\(\\sum^5_{k = 1}(3k + 7)\\) \\(\\sum^3_{i= 1} 3k + i + 7\\) Simplify the following \\(4^2\\) \\(4^2 2^3\\) \\(\\log_{10}100\\) \\(\\log_{2}4\\) \\(\\log e\\), where \\(\\log\\) is the natural log (alsowritten as \\(\\ln\\)) – a log with base \\(e\\), and \\(e\\) is Euler’s constant \\(e^a e^b e^c\\), where \\(a, b, c\\) are each constants \\(\\log 0\\) \\(e^0\\) \\(e^1\\) \\(\\log e^2\\) 1.3 Limits Find the limit of the following. \\(\\lim_{x \\to 2} (x - 1)\\) \\(\\lim_{x \\to 2} \\frac{(x - 2) (x - 1)}{(x - 2)}\\) \\(\\lim_{x \\to 2}\\frac{x^2 - 3x + 2}{x- 2}\\) 1.4 Calculus For each of the following functions \\(f(x)\\), find the derivative \\(f&#39;(x)\\) or \\(\\frac{d}{dx}f(x)\\) \\(f(x)=c\\) \\(f(x)=x\\) \\(f(x)=x^2\\) \\(f(x)=x^3\\) \\(f(x)=3x^2+2x^{1/3}\\) \\(f(x)=(x^3)(2x^4)\\) 1.5 Probability "],
["linear-algebra-2.html", "Chapter 2 Linear Algebra 2 2.1 Working with Vectors 2.2 Linear Independence 2.3 Basics of Matrix Algebra 2.4 Square Matrices 2.5 Linear Equations 2.6 Systems of Linear Equations 2.7 Systems of Equations as Matrices 2.8 Finding Solutions to Augmented Matrices and Systems of Equations 2.9 Rank — and Whether a System Has One, Infinite, or No Solutions 2.10 The Inverse of a Matrix 2.11 Linear Systems and Inverses 2.12 Determinants 2.13 Getting Inverse of a Matrix using its Determinant and Matrix of Cofactors", " Chapter 2 Linear Algebra 2 Topics: \\(\\bullet\\) Working with Vectors \\(\\bullet\\) Linear Independence \\(\\bullet\\) Basics of Matrix Algebra \\(\\bullet\\) Square Matrices \\(\\bullet\\) Linear Equations \\(\\bullet\\) Systems of Linear Equations \\(\\bullet\\) Systems of Equations as Matrices \\(\\bullet\\) Solving Augmented Matrices and Systems of Equations \\(\\bullet\\) Rank \\(\\bullet\\) The Inverse of a Matrix \\(\\bullet\\) Inverse of Larger Matrices Much of the material and examples for this lecture are taken from Gill (2006) , Simon &amp; Blume (1994) and Kolman (1993) . 2.1 Working with Vectors Vector: A vector in \\(n\\)-space is an ordered list of \\(n\\) numbers. These numbers can be represented as either a row vector or a column vector: \\[ {\\bf v} \\begin{pmatrix} v_1 &amp; v_2 &amp; \\dots &amp; v_n\\end{pmatrix} , {\\bf v} = \\begin{pmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{pmatrix}\\] We can also think of a vector as defining a point in \\(n\\)-dimensional space, usually \\({\\bf R}^n\\); each element of the vector defines the coordinate of the point in a particular direction. Vector Addition and Subtraction: If two vectors, \\({\\bf u}\\) and \\({\\bf v}\\), have the same length (i.e. have the same number of elements), they can be added (subtracted) together: \\[ {\\bf u} + {\\bf v} = \\begin{pmatrix} u_1 + v_1 &amp; u_2 + v_2 &amp; \\cdots &amp; u_k + v_n \\end{pmatrix}\\] \\[ {\\bf u} - {\\bf v} = \\begin{pmatrix} u_1 - v_1 &amp; u_2 - v_2 &amp; \\cdots &amp; u_k - v_n \\end{pmatrix}\\] Scalar Multiplication: The product of a scalar \\(c\\) (i.e. a constant) and vector \\({\\bf v}\\) is: \\[ c{\\bf v} = \\begin{pmatrix} cv_1 &amp; cv_2 &amp; \\dots &amp; cv_n \\end{pmatrix} \\] Vector Inner Product: The inner product (also called the dot product or scalar product) of two vectors \\({\\bf u}\\) and \\({\\bf v}\\) is again defined iff they have the same number of elements \\[ {\\bf u} \\cdot {\\bf v} = u_1v_1 + u_2v_2 + \\cdots + u_nv_n = \\sum_{i = 1}^n u_iv_i\\] If \\({\\bf u} \\cdot {\\bf v} = 0\\), the two vectors are orthogonal (or perpendicular). Vector Norm: The norm of a vector is a measure of its length. There are many different ways to calculate the norm, but the most common of is the Euclidean norm (which corresponds to our usual conception of distance in three-dimensional space): \\[ ||{\\bf v}|| = \\sqrt{{\\bf v}\\cdot{\\bf v}} = \\sqrt{ v_1v_1 + v_2v_2 + \\cdots + v_nv_n}\\] 2.2 Linear Independence Linear combinations: The vector \\({\\bf u}\\) is a linear combination of the vectors \\({\\bf v}_1, {\\bf v}_2, \\cdots , {\\bf v}_k\\) if \\[{\\bf u} = c_1{\\bf v}_1 + c_2{\\bf v}_2 + \\cdots + c_k{\\bf v}_k\\] Linear independence: A set of vectors \\({\\bf v}_1, {\\bf v}_2, \\cdots , {\\bf v}_k\\) is linearly independent if the only solution to the equation \\[c_1{\\bf v}_1 + c_2{\\bf v}_2 + \\cdots + c_k{\\bf v}_k = 0\\] is \\(c_1 = c_2 = \\cdots = c_k = 0\\). If another solution exists, the set of vectors is linearly dependent. A set \\(S\\) of vectors is linearly dependent iff at least one of the vectors in \\(S\\) can be written as a linear combination of the other vectors in \\(S\\). Linear independence is only defined for sets of vectors with the same number of elements; any linearly independent set of vectors in \\(n\\)-space contains at most \\(n\\) vectors. Exercises: Are the following sets of vectors linearly independent? 2.3 Basics of Matrix Algebra Matrix: A matrix is an array of real numbers arranged in \\(m\\) rows by \\(n\\) columns. The dimensionality of the matrix is defined as the number of rows by the number of columns, \\(m x n\\). \\[{\\bf A}=\\begin{pmatrix} a_{11} &amp; a_{12} &amp; \\cdots &amp; a_{1n} \\\\ a_{21} &amp; a_{22} &amp; \\cdots &amp; a_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{m1} &amp; a_{m2} &amp; \\cdots &amp; a_{mn} \\end{pmatrix}\\] Note that you can think of vectors as special cases of matrices; a column vector of length \\(k\\) is a \\(k \\times 1\\) matrix, while a row vector of the same length is a \\(1 \\times k\\) matrix. It’s also useful to think of matrices as being made up of a collection of row or column vectors. For example, \\[\\bf A = \\begin{pmatrix} {\\bf a}_1 &amp; {\\bf a}_2 &amp; \\cdots &amp; {\\bf a}_m \\end{pmatrix}\\] Matrix Addition: Let \\(\\bf A\\) and \\(\\bf B\\) be two \\(m\\times n\\) matrices. \\[{\\bf A+B}=\\begin{pmatrix} a_{11}+b_{11} &amp; a_{12}+b_{12} &amp; \\cdots &amp; a_{1n}+b_{1n} \\\\ a_{21}+b_{21} &amp; a_{22}+b_{22} &amp; \\cdots &amp; a_{2n}+b_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{m1}+b_{m1} &amp; a_{m2}+b_{m2} &amp; \\cdots &amp; a_{mn}+b_{mn} \\end{pmatrix}\\] Note that matrices \\({\\bf A}\\) and \\({\\bf B}\\) must have the same dimensionality, in which case they are conformable for addition. Example: \\[{\\bf A}=\\begin{pmatrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\end{pmatrix}, \\qquad {\\bf B}=\\begin{pmatrix} 1 &amp; 2 &amp; 1 \\\\ 2 &amp; 1 &amp; 2 \\end{pmatrix}\\] \\[{\\bf A+B}= \\phantom{\\begin{pmatrix} 2 &amp; 4 &amp; 4 \\\\ 6 &amp; 6 &amp; 8 \\end{pmatrix}}\\] Scalar Multiplication: Given the scalar \\(s\\), the scalar multiplication of \\(s {\\bf A}\\) is \\[ s {\\bf A}= s \\begin{pmatrix} a_{11} &amp; a_{12} &amp; \\cdots &amp; a_{1n} \\\\ a_{21} &amp; a_{22} &amp; \\cdots &amp; a_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{m1} &amp; a_{m2} &amp; \\cdots &amp; a_{mn} \\end{pmatrix} = \\begin{pmatrix} s a_{11} &amp; s a_{12} &amp; \\cdots &amp; s a_{1n} \\\\ s a_{21} &amp; s a_{22} &amp; \\cdots &amp; s a_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ s a_{m1} &amp; s a_{m2} &amp; \\cdots &amp; s a_{mn} \\end{pmatrix}\\] Example: \\[s=2, \\qquad {\\bf A}=\\begin{pmatrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\end{pmatrix}\\] \\[s {\\bf A} = \\phantom{\\begin{pmatrix} 2 &amp; 4 &amp; 6 \\\\ 8 &amp; 10 &amp; 12 \\end{pmatrix}}\\] Matrix Multiplication: If \\({\\bf A}\\) is an \\(m\\times k\\) matrix and \\(\\bf B\\) is a \\(k\\times n\\) matrix, then their product \\(\\bf C = A B\\) is the \\(m\\times n\\) matrix where \\[c_{ij}=a_{i1}b_{1j}+a_{i2}b_{2j}+\\cdots+a_{ik}b_{kj}\\] Examples: Note that the number of columns of the first matrix must equal the number of rows of the second matrix, in which case they are conformable for multiplication. The sizes of the matrices (including the resulting product) must be \\[(m\\times k)(k\\times n)=(m\\times n)\\] Also note that if AB exists, BA exists only if \\(\\dim({\\bf A}) = m \\times n\\) and \\(\\dim({\\bf B}) = n \\times m\\). This does not mean that AB = BA. AB = BA is true only in special circumstances, like when \\({\\bf A}\\) or \\({\\bf B}\\) is an identity matrix, \\({\\bf A} = {\\bf B}^{-1}\\), or \\({\\bf A} = {\\bf B}\\) and A is idempotent. Laws of Matrix Algebra: Commutative law for multiplication does not hold – the order of multiplication matters: \\[\\bf AB\\ne BA\\] Example: \\[{\\bf A}=\\begin{pmatrix} 1&amp;2\\\\-1&amp;3\\end{pmatrix}, \\qquad {\\bf B}=\\begin{pmatrix} 2&amp;1\\\\0&amp;1\\end{pmatrix}\\] \\[{\\bf AB}=\\begin{pmatrix} 2&amp;3\\\\-2&amp;2\\end{pmatrix}, \\qquad {\\bf BA}=\\begin{pmatrix} 1&amp;7\\\\-1&amp;3\\end{pmatrix}\\] Transpose: The transpose of the \\(m\\times n\\) matrix \\(\\bf A\\) is the \\(n\\times m\\) matrix \\({\\bf A}^T\\) (also written \\({\\bf A}&#39;\\)) obtained by interchanging the rows and columns of \\(\\bf A\\). Examples: The following rules apply for transposed matrices: Example of \\(({\\bf AB})^T = {\\bf B}^T{\\bf A}^T\\): \\[{\\bf A}=\\begin{pmatrix} 1&amp;3&amp;2\\\\2&amp;-1&amp;3\\end{pmatrix}, \\qquad {\\bf B}=\\begin{pmatrix} 0&amp;1\\\\2&amp;2\\\\3&amp;-1\\end{pmatrix}\\] \\[ ({\\bf AB})^T = \\left[ \\begin{pmatrix} 1&amp;3&amp;2\\\\2&amp;-1&amp;3\\end{pmatrix} \\begin{pmatrix} 0&amp;1\\\\2&amp;2\\\\3&amp;-1\\end{pmatrix} \\right]^T = \\begin{pmatrix} 12&amp;7\\\\5&amp;-3 \\end{pmatrix}\\] \\[ {\\bf B}^T{\\bf A}^T= \\begin{pmatrix} 0&amp;2&amp;3\\\\1&amp;2&amp;-1 \\end{pmatrix} \\begin{pmatrix} 1&amp;2\\\\3&amp;-1\\\\2&amp;3 \\end{pmatrix} = \\begin{pmatrix} 12&amp;7\\\\5&amp;-3 \\end{pmatrix}\\] 2.4 Square Matrices Square matrices have the same number of rows and columns; a \\(k \\times k\\) square matrix is referred to as a matrix of order \\(k\\). The diagonal of a square matrix is the vector of matrix elements that have the same subscripts. If A is a square matrix of order \\(k\\), then its diagonal is \\([ a_{11}, a_{22}, \\dots, a_{kk}]&#39;\\). There are several important types of square matrices: Identity Matrix: The \\(n\\times n\\) identity matrix \\({\\bf I}_n\\) is the matrix whose diagonal elements are 1 and all off-diagonal elements are 0. Examples: \\[ {\\bf I}_2=\\begin{pmatrix} 1&amp;0\\\\0&amp;1 \\end{pmatrix}, \\qquad {\\bf I}_3=\\begin{pmatrix} 1&amp;0&amp;0\\\\ 0&amp;1&amp;0\\\\ 0&amp;0&amp;1 \\end{pmatrix}\\] Symmetric Matrix: A matrix A is symmetric if \\({\\bf A} = {\\bf A}&#39;\\); this implies that \\(a_{ij} = a_{ji}\\) for all \\(i\\) and \\(j\\). Examples: \\[ {\\bf A} = \\begin{pmatrix} 1&amp;2\\\\2&amp;1 \\end{pmatrix} = {\\bf A}&#39;, \\qquad {\\bf B} =\\begin{pmatrix} 4&amp;2&amp;-1\\\\ 2&amp;1&amp;3\\\\ -1&amp;3&amp;1 \\end{pmatrix} = {\\bf B}&#39;\\] Diagonal Matrix: A matrix A is diagonal if all of its non-diagonal entries are zero; formally, if \\(a_{ij} = 0\\) for all \\(i \\neq j\\) Examples: \\[ {\\bf A} = \\begin{pmatrix} 1&amp;0\\\\0&amp;2 \\end{pmatrix}, \\qquad {\\bf B} =\\begin{pmatrix} 4&amp;0&amp;0\\\\ 0&amp;1&amp;0\\\\ 0&amp;0&amp;1 \\end{pmatrix}\\] Triangular Matrix: A matrix is triangular one of two cases. If all entries below the diagonal are zero (\\(a_{ij} = 0\\) for all \\(i &gt; j\\)), it is upper triangular. Conversely, if all entries above the diagonal are zero (\\(a_{ij} = 0\\) for all \\(i &lt; j\\)), it is lower triangular. Examples: \\[ {\\bf A}_{LT}= \\begin{pmatrix} 1&amp;0 &amp; 0\\\\4&amp;2&amp;0\\\\-3 &amp; 2 &amp; 5 \\end{pmatrix}, \\qquad {\\bf A}_{UT}=\\begin{pmatrix} 1&amp;7&amp;-4\\\\ 0&amp;3&amp;9\\\\ 0&amp;0&amp;-3 \\end{pmatrix}\\] 2.5 Linear Equations Linear Equation: \\(a_1 x_1 + a_2 x_2 + \\cdots + a_n x_n = b\\) \\(a_i\\) are parameters or coefficients. \\(x_i\\) are variables or unknowns. Linear because only one variable per term and degree is at most 1. 2.6 Systems of Linear Equations We are often interested in solving linear systems like\\ \\[\\begin{matrix} x &amp; - &amp; 3y &amp; = &amp; -3\\\\ 2x &amp; + &amp; y &amp; = &amp; 8 \\end{matrix}\\] More generally, we might have a system of \\(m\\) equations in \\(n\\) unknowns \\[\\begin{matrix} a_{11}x_1 &amp; + &amp; a_{12}x_2 &amp; + &amp; \\cdots &amp; + &amp; a_{1n}x_n &amp; = &amp; b_1\\\\ a_{21}x_1 &amp; + &amp; a_{22}x_2 &amp; + &amp; \\cdots &amp; + &amp; a_{2n}x_n &amp; = &amp; b_2\\\\ \\vdots &amp; &amp; &amp; &amp; \\vdots &amp; &amp; &amp; \\vdots &amp; \\\\ a_{m1}x_1 &amp; + &amp; a_{m2}x_2 &amp; + &amp; \\cdots &amp; + &amp; a_{mn}x_n &amp; = &amp; b_m \\end{matrix}\\] A solution to a linear system of \\(m\\) equations in \\(n\\) unknowns is a set of \\(n\\) numbers \\(x_1, x_2, \\cdots, x_n\\) that satisfy each of the \\(m\\) equations. Example: \\(x=3\\) and \\(y=2\\) is the solution to the above \\(2\\times 2\\) linear system. Notice from the graph that the two lines intersect at \\((3,2)\\). Does a linear system have one, no, or multiple solutions? For a system of 2 equations in 2 unknowns (i.e., two lines): Methods to solve linear systems: Substitution Elimination of variables Matrix methods 2.7 Systems of Equations as Matrices Matrices provide an easy and efficient way to represent linear systems such as \\[\\begin{matrix} a_{11}x_1 &amp; + &amp; a_{12}x_2 &amp; + &amp; \\cdots &amp; + &amp; a_{1n}x_n &amp; = &amp; b_1\\\\ a_{21}x_1 &amp; + &amp; a_{22}x_2 &amp; + &amp; \\cdots &amp; + &amp; a_{2n}x_n &amp; = &amp; b_2\\\\ \\vdots &amp; &amp; &amp; &amp; \\vdots &amp; &amp; &amp; \\vdots &amp; \\\\ a_{m1}x_1 &amp; + &amp; a_{m2}x_2 &amp; + &amp; \\cdots &amp; + &amp; a_{mn}x_n &amp; = &amp; b_m \\end{matrix}\\] as \\[{\\bf A x = b}\\] where Augmented Matrix: When we append \\(\\bf b\\) to the coefficient matrix \\(\\bf A\\), we get the augmented matrix \\(\\widehat{\\bf A}=[\\bf A | b]\\) \\[\\begin{pmatrix} a_{11} &amp; a_{12} &amp; \\cdots &amp; a_{1n} &amp; | &amp; b_1\\\\ a_{21} &amp; a_{22} &amp; \\cdots &amp; a_{2n} &amp; | &amp; b_2\\\\ \\vdots &amp; &amp; \\ddots &amp; \\vdots &amp; | &amp; \\vdots\\\\ a_{m1} &amp; a_{m2} &amp; \\cdots &amp; a_{mn} &amp; | &amp; b_m \\end{pmatrix}\\] 2.8 Finding Solutions to Augmented Matrices and Systems of Equations Row Echelon Form: Our goal is to translate our augmented matrix or system of equations into row echelon form. This will provide us with the values of the vector x which solve the system. We use the row operations to change coefficients in lower triangle of the augmented matrix to 0. An augmented matrix of the form \\[\\begin{pmatrix} \\fbox{$a&#39;_{11}$}&amp; a&#39;_{12} &amp; a&#39;_{13}&amp; \\cdots &amp; a&#39;_{1n} &amp; | &amp; b&#39;_1\\\\ 0 &amp; \\fbox{$a&#39;_{22}$} &amp; a&#39;_{23}&amp; \\cdots &amp; a&#39;_{2n} &amp; | &amp; b&#39;_2\\\\ 0 &amp; 0 &amp; \\fbox{$a&#39;_{33}$}&amp; \\cdots &amp; a&#39;_{3n} &amp; | &amp; b&#39;_3\\\\ 0 &amp; 0 &amp;0 &amp; \\ddots &amp; \\vdots &amp; | &amp; \\vdots \\\\ 0 &amp; 0 &amp;0 &amp;0 &amp; \\fbox{$a&#39;_{mn}$} &amp; | &amp; b&#39;_m \\end{pmatrix}\\] is said to be in row echelon form — each row has more leading zeros than the row preceding it. Reduced Row Echelon Form: We can go one step further and put the matrix into reduced row echelon form. Reduced row echelon form makes the value of x which solves the system very obvious. For a system of \\(m\\) equations in \\(m\\) unknowns, with no all-zero rows, the reduced row echelon form would be \\[\\begin{pmatrix} \\fbox{$1$} &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; | &amp; b^*_1\\\\ 0 &amp; \\fbox{$1$} &amp; 0 &amp; 0 &amp; 0 &amp; | &amp; b^*_2\\\\ 0 &amp; 0 &amp; \\fbox{$1$} &amp; 0 &amp; 0 &amp; | &amp; b^*_3\\\\ 0 &amp; 0 &amp; 0 &amp;\\ddots &amp; 0 &amp; | &amp;\\vdots\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\fbox{$1$} &amp; | &amp; b^*_m \\end{pmatrix}\\] Gaussian and Gauss-Jordan elimination: We can conduct elementary row operations to get our augmented matrix into row echelon or reduced row echelon form. The methods of transforming a matrix or system into row echelon and reduced row echelon form are referred to as Gaussian elimination and Gauss-Jordan elimination, respectively. Elementary Row Operations: To do Gaussian and Gauss-Jordan elimination, we use three basic operations to transform the augmented matrix into another augmented matrix that represents an equivalent linear system – equivalent in the sense that the same values of \\(x_j\\) solve both the original and transformed matrix/system: Interchanging Rows: Suppose we have the augmented matrix \\[{\\widehat{\\bf A}}=\\begin{pmatrix} a_{11} &amp; a_{12} &amp; | &amp; b_1\\\\ a_{21} &amp; a_{22} &amp; | &amp; b_2 \\end{pmatrix}\\] If we interchange the two rows, we get the augmented matrix \\[\\begin{pmatrix} a_{21} &amp; a_{22} &amp; | &amp; b_2\\\\ a_{11} &amp; a_{12} &amp; | &amp; b_1 \\end{pmatrix}\\] which represents a linear system equivalent to that represented by matrix \\(\\widehat{\\bf A}\\). Multiplying by a Constant: If we multiply the second row of matrix \\(\\widehat{\\bf A}\\) by a constant \\(c\\), we get the augmented matrix \\[\\begin{pmatrix} a_{11} &amp; a_{12} &amp; | &amp; b_1\\\\ c a_{21} &amp; c a_{22} &amp; | &amp; c b_2 \\end{pmatrix}\\] which represents a linear system equivalent to that represented by matrix \\(\\widehat{\\bf A}\\). Adding (subtracting) Rows: If we add (subtract) the first row of matrix \\(\\widehat{\\bf A}\\) to the second, we obtain the augmented matrix \\[\\begin{pmatrix} a_{11} &amp; a_{12} &amp; | &amp; b_1\\\\ a_{11}+a_{21} &amp; a_{12}+a_{22} &amp; | &amp; b_1+b_2 \\end{pmatrix}\\] which represents a linear system equivalent to that represented by matrix \\(\\widehat{\\bf A}\\). Exercises: Using Gaussian or Gauss-Jordan elimination, solve the following linear systems by putting them into row echelon or reduced row echelon form: 2.9 Rank — and Whether a System Has One, Infinite, or No Solutions We previously noted that a \\(2\\times 2\\) system had one, infinite, or no solutions if the two lines intersected, were the same, or were parallel, respectively. More generally, to determine how many solutions exist, we can use information about (1) the number of equations \\(m\\), (2) the number of unknowns \\(n\\), and (3) the rank of the matrix representing the linear system. Rank: The row rank or column rank of a matrix is the number of nonzero rows or columns in its row echelon form. The rank also corresponds to the maximum number of linearly independent row or column vectors in the matrix. For any matrix A, the row rank always equals column rank, and we refer to this number as the rank of A. Examples: Let \\(\\bf A\\) be the coefficient matrix and \\(\\widehat{\\bf A}=[ {\\bf A} | {\\bf b}]\\) be the augmented matrix. Then Existence of Solutions: Find the rank and number of solutions for the systems of equations below.: 2.10 The Inverse of a Matrix Inverse Matrix: An \\(n\\times n\\) matrix \\({\\bf A}\\) is nonsingular or invertible if there exists an \\(n\\times n\\) matrix \\({\\bf A}^{-1}\\) such that \\[{\\bf A} {\\bf A}^{-1} = {\\bf A}^{-1} {\\bf A} = {\\bf I}_n\\] where \\({\\bf A}^{-1}\\) is the inverse of \\({\\bf A}\\). If there is no such \\({\\bf A}^{-1}\\), then \\({\\bf A}\\) is singular or noninvertible. Example: Let \\[{\\bf A} = \\begin{pmatrix} 2&amp;3\\\\2&amp;2 \\end{pmatrix}, \\qquad {\\bf B}=\\begin{pmatrix} -1&amp;\\frac{3}{2}\\\\ 1&amp;-1 \\end{pmatrix}\\] Since \\[{\\bf A} {\\bf B} = {\\bf B} {\\bf A} = {\\bf I}_n\\] we conclude that \\({\\bf B}\\) is the inverse, \\({\\bf A}^{-1}\\), of \\({\\bf A}\\) and that \\({\\bf A}\\) is nonsingular. Properties of the Inverse: : We know that if \\({\\bf B}\\) is the inverse of \\({\\bf A}\\), then \\[{\\bf A} {\\bf B} = {\\bf B} {\\bf A} = {\\bf I}_n\\] Looking only at the first and last parts of this \\[{\\bf A} {\\bf B} = {\\bf I}_n\\] Solving for \\({\\bf B}\\) is equivalent to solving for \\(n\\) linear systems, where each column of \\({\\bf B}\\) is solved for the corresponding column in \\({\\bf I}_n\\). We can solve the systems simultaneously by augmenting \\({\\bf A}\\) with \\({\\bf I}_n\\) and performing Gauss-Jordan elimination on \\({\\bf A}\\). If Gauss-Jordan elimination on \\([{\\bf A} | {\\bf I}_n]\\) results in \\([{\\bf I}_n | {\\bf B} ]\\), then \\({\\bf B}\\) is the inverse of \\({\\bf A}\\). Otherwise, \\({\\bf A}\\) is singular.\\ [12pt] To summarize: To calculate the inverse of \\({\\bf A}\\) Exercise: Find the inverse of \\({\\bf A}=\\begin{pmatrix} 1&amp;1&amp;1\\\\0&amp;2&amp;3\\\\5&amp;5&amp;1 \\end{pmatrix}\\) 2.11 Linear Systems and Inverses Let’s return to the matrix representation of a linear system \\[\\bf{Ax} = \\bf{b}\\] If \\(\\bf{A}\\) is an \\(n\\times n\\) matrix,then \\(\\bf{Ax}=\\bf{b}\\) is a system of \\(n\\) equations in \\(n\\) unknowns. Suppose \\(\\bf{A}\\) is nonsingular. Then \\(\\bf{A}^{-1}\\) exists. To solve this system, we can premultiply each side by \\(\\bf{A}^{-1}\\) and reduce it as follows: \\[\\begin{eqnarray*} \\bf{A}^{-1} (\\bf{A} \\bf{x}) &amp; = &amp; \\bf{A}^{-1} \\bf{b} \\\\ (\\bf{A}^{-1} \\bf{A})\\bf{x} &amp; = &amp; \\bf{A}^{-1} \\bf{b}\\\\ \\bf{I}_n \\bf{x} &amp; = &amp; \\bf{A}^{-1} \\bf{b}\\\\ \\bf{x} &amp; = &amp; \\bf{A}^{-1} \\bf{b} \\end{eqnarray*}\\] Hence, given \\(\\bf{A}\\) and \\(\\bf{b}\\) and given that \\(\\bf{A}\\) is nonsingular, then \\(\\bf{x} = \\bf{A}^{-1} \\bf{b}\\) is a unique solution to this system. Notice also that the requirements for \\(\\bf{A}\\) to be nonsingular correspond to the requirements for a linear system to have a unique solution: \\[\\text{rank}\\bf{A} = \\text{rows}\\bf{A} = \\text{cols}\\bf{A}\\] 2.12 Determinants Singularity: Determinants can be used to whether a square matrix is nonsingular. A square matrix is nonsingular iff its determinant is not zero. Determinant of a \\(1 \\times 1\\) matrix, A, equals \\(a_{11}\\) Determinant of a \\(2 \\times 2\\) matrix, A, \\(\\begin{vmatrix} a_{11}&amp;a_{12}\\\\ a_{21}&amp;a_{22} \\end{vmatrix}\\): \\[\\begin{eqnarray*} \\det({\\bf A}) &amp;=&amp; |{\\bf A}|\\\\ &amp;=&amp; a_{11}|a_{22}| - a_{12}|a_{21}|\\\\ &amp;=&amp; a_{11}a_{22} - a_{12}a_{21} \\end{eqnarray*}\\] We can extend the second to last equation above to get the definition of the determinant of a \\(3 \\times 3\\) matrix: \\[\\begin{eqnarray*} \\begin{vmatrix} a_{11}&amp;a_{12}&amp;a_{13}\\\\ a_{21} &amp; a_{22}&amp;a_{23}\\\\ a_{31}&amp;a_{32}&amp;a_{33} \\end{vmatrix} &amp;=&amp; a_{11} \\begin{vmatrix} a_{22}&amp;a_{23}\\\\ a_{32}&amp;a_{33} \\end{vmatrix} - a_{12} \\begin{vmatrix} a_{21}&amp;a_{23}\\\\ a_{31}&amp;a_{33} \\end{vmatrix} + a_{13} \\begin{vmatrix} a_{21}&amp;a_{22}\\\\ a_{31}&amp;a_{32} \\end{vmatrix}\\\\ &amp;=&amp; a_{11}(a_{22}a_{33} - a_{23}a_{32}) - a_{12}(a_{21}a_{33} - a_{23}a_{31}) + a_{13}(a_{21}a_{32} - a_{22}a_{31}) \\end{eqnarray*}\\] Let’s extend this now to any \\(n\\times n\\) matrix. Let’s define \\({\\bf A}_{ij}\\) as the \\((n-1)\\times (n-1)\\) submatrix of \\({\\bf A}\\) obtained by deleting row \\(i\\) and column \\(j\\). Let the \\((i,j)\\)th minor of \\({\\bf A}\\) be the determinant of \\({\\bf A}_{ij}\\): \\[M_{ij}=|{\\bf A}_{ij}|\\] Then for any \\(n\\times n\\) matrix \\({\\bf A}\\) \\[|{\\bf A}|= a_{11}M_{11} - a_{12}M_{12} + \\cdots + (-1)^{n+1} a_{1n} M_{1n}\\] Example: Does the following matrix have an inverse? \\[{\\bf A}=\\begin{pmatrix} 1&amp;1&amp;1\\\\0&amp;2&amp;3\\\\5&amp;5&amp;1 \\end{pmatrix}\\] 1. Calculate its determinant. \\[\\begin{eqnarray} &amp;=&amp; 1(2-15) - 1(0-15) + 1(0-10) \\nonumber\\\\ &amp;=&amp; -13+15-10 \\nonumber\\\\ &amp;=&amp; -8\\nonumber \\end{eqnarray}\\] Since \\(|{\\bf A}|\\ne 0\\), we conclude that \\({\\bf A}\\) has an inverse. 2.13 Getting Inverse of a Matrix using its Determinant and Matrix of Cofactors Thus far, we have a number of algorithms to Find the solution of a linear system, Find the inverse of a matrix but these remain just that — algorithms. At this point, we have no way of telling how the solutions \\(x_j\\) change as the parameters \\(a_{ij}\\) and \\(b_i\\) change, except by changing the values and “rerunning” the algorithms. With determinants, we can 1. Provide an explicit formula for the inverse, and 2. Provide an explicit formula for the solution of an \\(n\\times n\\) linear system. Hence, we can examine how changes in the parameters and \\(b_i\\) affect the solutions \\(x_j\\). Determinant Formula for the Inverse of a \\(2 \\times 2\\): The determinant of a \\(2 \\times 2\\) matrix A \\(\\begin{pmatrix} a &amp; b\\\\ c &amp; d\\\\ \\end{pmatrix}\\) is defined as: \\[\\frac{1}{\\det({\\bf A})} \\begin{pmatrix} d &amp; -b\\\\ -c &amp; a\\\\ \\end{pmatrix}\\] "],
["functions-and-notation.html", "Chapter 3 Functions and Notation 3.1 Dimensionality 3.2 Interval Notation for \\({\\bf R}^1\\) 3.3 Neighborhoods: Intervals, Disks, and Balls 3.4 Introduction to Functions 3.5 Domain and Range/Image 3.6 Some General Types of Functions 3.7 \\(\\log\\), \\(\\ln\\), and \\(\\exp\\) 3.8 Other Useful Functions 3.9 Graphing Functions 3.10 Solving for Variables and Finding Inverses 3.11 Finding the Roots or Zeroes of a Function 3.12 The Limit of a Function 3.13 Continuity 3.14 Sets", " Chapter 3 Functions and Notation Topics Dimensionality; Interval Notation for \\({\\bf R}^1\\); Neighborhoods: Intervals, Disks, and Balls; Introduction to Functions; Domain and Range; Some General Types of Functions; \\(\\log\\), \\(\\ln\\), and \\(\\exp\\); Other Useful Functions; Graphing Functions; Solving for Variables; Finding Roots; Limit of a Function; Continuity; Sets, Sets, and More Sets. Much of the material and examples for this lecture are taken from Simon &amp; Blume (1994) , Boyce &amp; Diprima (1988) , and Protter &amp; Morrey (1991) 3.1 Dimensionality \\({\\bf R}^1\\) is the set of all real numbers extending from \\(-\\infty\\) to \\(+\\infty\\) — i.e., the real number line. \\({\\bf R}^n\\) is an \\(n\\)-dimensional space (often referred to as Euclidean space), where each of the \\(n\\) axes extends from \\(-\\infty\\) to \\(+\\infty\\). \\({\\bf R}^1\\) is a one dimensional line. \\({\\bf R}^2\\) is a two dimensional plane. \\({\\bf R}^3\\) is a three dimensional space. \\({\\bf R}^4\\) could be 3-D plus time (or temperature, etc). Points in \\({\\bf R}^n\\) are ordered \\(n\\)-tuples, where each element of the \\(n\\)-tuple represents the coordinate along that dimension. \\({\\bf R}^1\\): (3) \\({\\bf R}^2\\): (-15, 5) \\({\\bf R}^3\\): (86, 4, 0) 3.2 Interval Notation for \\({\\bf R}^1\\) Open interval: \\[(a,b)\\equiv \\{ x\\in{\\bf R}^1: a&lt;x&lt;b\\}\\] \\(x\\) is a one-dimensional element in which x is greater than a and less than b Closed interval: \\[[a,b]\\equiv \\{ x\\in{\\bf R}^1: a\\le x \\le b\\}\\] \\(x\\) is a one-dimensional element in which x is greater or equal to than a and less than or equal to b Half open, half closed: \\[(a,b]\\equiv \\{ x\\in{\\bf R}^1: a&lt;x\\le b\\}\\] \\(x\\) is a one-dimensional element in which x is greater than a and less than or equal to b 3.3 Neighborhoods: Intervals, Disks, and Balls In many areas of math, we need a formal construct for what it means to be “near” a point \\(\\bf c\\) in \\({\\bf R}^n\\). This is generally called the neighborhood of \\(\\bf c\\). It’s represented by an open interval, disk, or ball, depending on whether \\({\\bf R}^n\\) is of one, two, or more dimensions, respectively. Given the point \\(c\\), these are defined as \\(\\epsilon\\)-interval in \\({\\bf R}^1\\): \\(\\{x : |x-c|&lt;\\epsilon \\}\\). \\(x\\) is in the neighborhood of {} if it is in the open interval \\((c-\\epsilon,c+\\epsilon)\\). \\(\\epsilon\\)-disk in \\({\\bf R}^2\\): \\(\\{x : || x-c ||&lt;\\epsilon\\}\\). \\(x\\) is in the neighborhood of {} if it is inside the circle or disc with center \\(\\bf c\\) and radius \\(\\epsilon\\). \\(\\epsilon\\)-ball in \\({\\bf R}^n\\): \\(\\{x : || x-c ||&lt;\\epsilon\\}\\). \\(x\\) is in the neighborhood of {} if it is inside the sphere or ball with center \\(\\bf c\\) and radius \\(\\epsilon\\). 3.4 Introduction to Functions A function (in \\({\\bf R}^1\\)) is a mapping, or transformation, that relates members of one set to members of another set. For instance, if you have two sets: set \\(A\\) and set \\(B\\), a function from \\(A\\) to \\(B\\) maps every value \\(a\\) in set \\(A\\) such that \\(f(a) \\in B\\). Functions can be “many-to-one”, where many values or combinations of values from set \\(A\\) produce a single output in set \\(B\\), or they can be “one-to-one”, where each value in set \\(A\\) corresponds to a single value in set \\(B\\). Examples: Mapping notation Function of one variable: \\(f:{\\bf R}^1\\to{\\bf R}^1\\)\\ \\(f(x)=x+1\\). For each \\(x\\) in \\({\\bf R}^1\\), \\(f(x)\\) assigns the number \\(x+1\\). Function of two variables: \\(f: {\\bf R}^2\\to{\\bf R}^1\\). \\(f(x,y)=x^2+y^2\\). For each ordered pair \\((x,y)\\) in \\({\\bf R}^2\\), \\(f(x,y)\\) assigns the number \\(x^2+y^2\\). We often use variable \\(x\\) as input and another \\(y\\) as output, e.g. \\(y=x+1\\) 3.5 Domain and Range/Image Some functions are defined only on proper subsets of \\({\\bf R}^n\\). Domain: the set of numbers in \\(X\\) at which \\(f(x)\\) is defined. Range: elements of \\(Y\\) assigned by \\(f(x)\\) to elements of \\(X\\), or \\[f(X)=\\{ y : y=f(x), x\\in X\\}\\] Most often used when talking about a function \\(f:{\\bf R}^1\\to{\\bf R}^1\\). Image: same as range, but more often used when talking about a function \\(f:{\\bf R}^n\\to{\\bf R}^1\\). 3.6 Some General Types of Functions Monomials: \\(f(x)=a x^k\\)\\ \\(a\\) is the coefficient. \\(k\\) is the degree.\\ Examples: \\(y=x^2\\), \\(y=-\\frac{1}{2}x^3\\) Polynomials: sum of monomials. Examples: \\(y=-\\frac{1}{2}x^3+x^2\\), \\(y=3x+5\\) The degree of a polynomial is the highest degree of its monomial terms. Also, it’s often a good idea to write polynomials with terms in decreasing degree. Exponential Functions: Example: \\(y=2^x\\) 3.7 \\(\\log\\), \\(\\ln\\), and \\(\\exp\\) Relationship of logarithmic and exponential functions: \\[y=\\log_a(x) \\iff a^y=x\\] The log function can be thought of as an inverse for exponential functions. \\(a\\) is referred to as the “base” of the logarithm. Common Bases: The two most common logarithms are base 10 and base \\(e\\). Base 10: \\(\\quad y=\\log_{10}(x) \\iff 10^y=x\\). The base 10 logarithm is often simply written as “\\(\\log(x)\\)” with no base denoted. Base \\(e\\): \\(\\quad y=\\log_e(x) \\iff e^y=x\\). The base \\(e\\) logarithm is referred to as the “natural” logarithm and is written as ``\\(\\ln(x)\\)“. Properties of exponential functions: \\(a^x a^y = a^{x+y}\\) \\(a^{-x} = 1/a^x\\) \\(a^x/a^y = a^{x-y}\\) \\((a^x)^y = a^{x y}\\) \\(a^0 = 1\\) Properties of logarithmic functions (any base): Generally, when statisticians or social scientists write \\(\\log(x)\\) they mean \\(\\log_e(x)\\). In other words: \\(\\log_e(x) \\equiv \\ln(x) \\equiv \\log(x)\\) \\[\\log_a(a^x)=x\\] and \\[a^{\\log_a(x)}=x\\] \\(\\log(x y)=\\log(x)+\\log(y)\\) \\(\\log(x^y)=y\\log(x)\\) \\(\\log(1/x)=\\log(x^{-1})=-\\log(x)\\) \\(\\log(x/y)=\\log(x\\cdot y^{-1})=\\log(x)+\\log(y^{-1})=\\log(x)-\\log(y)\\) \\(\\log(1)=\\log(e^0)=0\\) Change of Base Formula: Use the change of base formula to switch bases as necessary: \\[\\log_b(x) = \\frac{\\log_a(x)}{\\log_a(b)}\\] Example: \\[\\log_{10}(x) = \\frac{\\ln(x)}{\\ln(10)}\\] 3.8 Other Useful Functions Factorials!: \\[x! = x\\cdot (x-1) \\cdot (x-2) \\cdots (1)\\] Modulo: Tells you the remainder when you divide one number by another. Can be extremely useful for programming: or \\(17 \\mod 3 = 2\\) \\(100 \\ \\% \\ 30 = 10\\) Summation: \\[\\sum\\limits_{i=1}^n x_i = x_1+x_2+x_3+\\cdots+x_n\\] Product: \\[\\prod\\limits_{i=1}^n x_i = x_1 x_2 x_3 \\cdots x_n\\] Properties: You can use logs to go between sum and product notation. This will be particularly important when you’re learning maximum likelihood estimation. \\[\\begin{eqnarray*} \\log \\bigg(\\prod\\limits_{i=1}^n x_i \\bigg) &amp;=&amp; \\log(x_1 \\cdot x_2 \\cdot x_3 \\cdots \\cdot x_n)\\\\ &amp;=&amp; \\log(x_1) + \\log(x_2) + \\log(x_3) + \\cdots + \\log(x_n)\\\\ &amp;=&amp; \\sum\\limits_{i=1}^n \\log (x_i) \\end{eqnarray*}\\] Therefore, you can see that the log of a product is equal to the sum of the logs. We can write this more generally by adding in a constant, \\(c\\): \\[\\begin{eqnarray*} \\log \\bigg(\\prod\\limits_{i=1}^n c x_i\\bigg) &amp;=&amp; \\log(cx_1 \\cdot cx_2 \\cdots cx_n)\\\\ &amp;=&amp; \\log(c^n \\cdot x_1 \\cdot x_2 \\cdots x_n)\\\\ &amp;=&amp; \\log(c^n) + \\log(x_1) + \\log(x_2) + \\cdots + \\log(x_n)\\\\\\\\ &amp;=&amp; n \\log(c) + \\sum\\limits_{i=1}^n \\log (x_i)\\\\ \\end{eqnarray*}\\] 3.9 Graphing Functions What can a graph tell you about a function? Is the function increasing or decreasing? Over what part of the domain? How ``fast&quot; does it increase or decrease? Are there global or local maxima and minima? Where? Are there inflection points? Is the function continuous? Is the function differentiable? Does the function tend to some limit? Other questions related to the substance of the problem at hand. 3.10 Solving for Variables and Finding Inverses Sometimes we’re given a function \\(y=f(x)\\) and we want to find how \\(x\\) varies as a function of \\(y\\). If \\(f\\) is a one-to-one mapping, then it has an inverse. Use algebra to move \\(x\\) to the left hand side (LHS) of the equation and so that the right hand side (RHS) is only a function of \\(y\\).\\ Examples: (we want to solve for \\(x\\)) \\[y=3x+2 \\quad\\Longrightarrow\\quad -3x=2-y \\quad\\Longrightarrow\\quad 3x=y-2 \\quad\\Longrightarrow\\quad x=\\frac{1}{3}(y-2)\\] \\[y=3x-4z+2 \\quad \\Longrightarrow\\quad y+4z-2=3x \\quad\\Longrightarrow\\quad x=\\frac{1}{3}(y+4z-2)\\] \\[\\begin{align*} y=e^x+4 &amp;\\Longrightarrow\\quad y-4=e^x\\\\ &amp;\\Longrightarrow \\ln(y-4) = \\ln(e^x)\\\\ &amp;\\Longrightarrow\\quad x=\\ln(y-4) \\end{align*}\\] Sometimes (often?) the inverse does not exist. For example, we’re given the function \\(y=x^2\\) (a parabola). Solving for \\(x\\), we get \\(x=\\pm\\sqrt{y}\\). For each value of \\(y\\), there are two values of \\(x\\). 3.11 Finding the Roots or Zeroes of a Function Solving for variables is especially important when we want to find the roots of an equation: those values of variables that cause an equation to equal zero. Especially important in finding equilibria and in doing maximum likelihood estimation. Procedure: Given \\(y=f(x)\\), set \\(f(x)=0\\). Solve for \\(x\\). Multiple Roots: \\[f(x)=x^2 - 9 \\quad\\Longrightarrow\\quad 0=x^2 - 9 \\quad\\Longrightarrow\\quad 9=x^2 \\quad\\Longrightarrow\\quad \\pm \\sqrt{9}=\\sqrt{x^2} \\quad\\Longrightarrow\\quad \\pm 3=x\\] Quadratic Formula: For quadratic equations \\(ax^2+bx+c=0\\), use the quadratic formula: \\[x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\\] Examples: 3.12 The Limit of a Function We’re often interested in determining if a function \\(f\\) approaches some number \\(L\\) as its independent variable \\(x\\) moves to some number \\(c\\) (usually 0 or \\(\\pm\\infty\\)). If it does, we say that the limit of \\(f(x)\\), as \\(x\\) approaches \\(c\\), is \\(L\\): \\(\\lim\\limits_{x \\to c} f(x)=L\\). For a limit \\(L\\) to exist, the function \\(f(x)\\) must approach \\(L\\) from both the left and right. Limit of a function. Let \\(f(x)\\) be defined at each point in some open interval containing the point \\(c\\). Then \\(L\\) equals \\(\\lim\\limits_{x \\to c} f(x)\\) if for any (small positive) number \\(\\epsilon\\), there exists a corresponding number \\(\\delta&gt;0\\) such that if \\(0&lt;|x-c|&lt;\\delta\\), then \\(|f(x)-L|&lt;\\epsilon\\). Note: f(x) does not necessarily have to be defined at \\(c\\) for \\(\\lim\\limits_{x \\to c}\\) to exist. Uniqueness: \\(\\lim\\limits_{x \\to c} f(x)=L\\) and \\(\\lim\\limits_{x \\to c} f(x)=M \\Longrightarrow L=M\\) Properties: Let \\(f\\) and \\(g\\) be functions with \\(\\lim\\limits_{x \\to c} f(x)=A\\) and \\(\\lim\\limits_{x \\to c} g(x)=B\\). \\(\\lim\\limits_{x \\to c}[f(x)+g(x)]=\\lim\\limits_{x \\to c} f(x)+ \\lim\\limits_{x \\to c} g(x)\\) \\(\\lim\\limits_{x \\to c} \\alpha f(x) = \\alpha \\lim\\limits_{x \\to c} f(x)\\) \\(\\lim\\limits_{x \\to c} f(x) g(x) = [\\lim\\limits_{x \\to c} f(x)][\\lim\\limits_{x \\to c} g(x)]\\) \\(\\lim\\limits_{x \\to c} \\frac{f(x)}{g(x)} = \\frac{\\lim\\limits_{x \\to c} f(x)}{\\lim\\limits_{x \\to c} g(x)}\\), provided \\(\\lim\\limits_{x \\to c} g(x)\\ne 0\\). Note: In a couple days we’ll talk about L’H^opital’s Rule, which uses simple calculus to help find the limits of functions like this. Examples: \\[\\begin{align*} &amp; \\lim_{x \\to c} k = \\\\ &amp; \\lim_{x \\to c} x = \\\\ &amp; \\lim_{x\\to 2} (2x-3) =\\\\ &amp; \\lim_{x \\to c} x^n = \\end{align*}\\] Types of limits: Right-hand limit: The value approached by \\(f(x)\\) when you move from right to left. Left-hand limit: The value approached by \\(f(x)\\) when you move from left to right. Infinity: The value approached by \\(f(x)\\) as x grows infinitely large. Sometimes this may be a number; sometimes it might be \\(\\infty\\) or \\(-\\infty\\). Negative infinity: The value approached by \\(f(x)\\) as x grows infinitely negative. Sometimes this may be a number; sometimes it might be \\(\\infty\\) or \\(-\\infty\\). 3.13 Continuity Continuity: Suppose that the domain of the function \\(f\\) includes an open interval containing the point \\(c\\). Then \\(f\\) is continuous at \\(c\\) if \\(\\lim\\limits_{x \\to c} f(x)\\) exists and if \\(\\lim\\limits_{x \\to c} f(x)=f(c)\\). Further, \\(f\\) is continuous on an open interval \\((a,b)\\) if it is continuous at each point in the interval. Examples: Continuous functions. Properties: If \\(f\\) and \\(g\\) are continuous at point \\(c\\), then \\(f+g\\), \\(f-g\\), \\(f \\cdot g\\), \\(|f|\\), and \\(\\alpha f\\) are continuous at point \\(c\\) also. \\(f/g\\) is continuous, provided \\(g(c)\\ne 0\\). Boundedness: If \\(f\\) is continuous on the closed bounded interval \\([a,b]\\), then there is a number \\(K\\) such that \\(|f(x)|\\le K\\) for each \\(x\\) in \\([a,b]\\). Max/Min: If \\(f\\) is continuous on the closed bounded interval \\([a,b]\\), then \\(f\\) has a maximum and a minimum on \\([a,b]\\). They may be located at the end points. 3.14 Sets Interior Point: The point \\(\\bf x\\) is an interior point of the set \\(S\\) if \\(\\bf x\\) is in \\(S\\) and if there is some \\(\\epsilon\\)-ball around \\(\\bf x\\) that contains only points in \\(S\\). The interior of \\(S\\) is the collection of all interior points in \\(S\\). The interior can also be defined as the union of all open sets in \\(S\\). If the set \\(S\\) is circular, the interior points are everything inside of the circle, but not on the circle’s rim. Example: The interior of the set \\(\\{ (x,y) : x^2+y^2\\le 4 \\}\\) is \\(\\{ (x,y) : x^2+y^2&lt; 4 \\}\\) . Boundary Point: The point \\(\\bf x\\) is a boundary point of the set \\(S\\) if every \\(\\epsilon\\)-ball around \\(\\bf x\\) contains both points that are in \\(S\\) and points that are outside \\(S\\). The boundary is the collection of all boundary points. If the set \\(S\\) is circular, the boundary points are everything on the circle’s rim. Example: The boundary of \\(\\{ (x,y) : x^2+y^2\\le 4 \\}\\) is \\(\\{ (x,y) : x^2+y^2 = 4 \\}\\). Open: A set \\(S\\) is open if for each point \\(\\bf x\\) in \\(S\\), there exists an open \\(\\epsilon\\)-ball around \\(\\bf x\\) completely contained in \\(S\\). If the set \\(S\\) is circular and open, the points contained within the set get infinitely close to the circle’s rim, but do not touch it. Example: \\(\\{ (x,y) : x^2+y^2&lt;4 \\}\\) Closed: A set \\(S\\) is closed if it contains all of its boundary points. If the set \\(S\\) is circular and closed, the set contains all points within the rim as well as the rim itself. Example: \\(\\{ (x,y) : x^2+y^2\\le 4 \\}\\) Note: a set may be neither open nor closed. Example: \\(\\{ (x,y) : 2 &lt; x^2+y^2\\le 4 \\}\\) Complement: The complement of set \\(S\\) is everything outside of \\(S\\). If the set \\(S\\) is circular, the complement of \\(S\\) is everything outside of the circle. Example: The complement of \\(\\{ (x,y) : x^2+y^2\\le 4 \\}\\) is \\(\\{ (x,y) : x^2+y^2 &gt; 4 \\}\\). Closure: The closure of set \\(S\\) is the smallest closed set that contains \\(S\\). Example: The closure of \\(\\{ (x,y) : x^2+y^2&lt;4 \\}\\) is \\(\\{ (x,y) : x^2+y^2\\le 4 \\}\\) Bounded: A set \\(S\\) is bounded if it can be contained within an \\(\\epsilon\\)-ball. Examples: Bounded: any interval that doesn’t have \\(\\infty\\) or \\(-\\infty\\) as endpoints; any disk in a plane with finite radius. Unbounded: the set of integers in \\({\\bf R}^1\\); any ray. Compact: A set is compact if and only if it is both closed and bounded. Empty: The empty (or null) set is a unique set that has no elements, denoted by {} or \\(\\o\\). Examples: The set of squares with 5 sides; the set of countries south of the South Pole. The set, \\(S\\), denoted by \\(\\{\\o\\}\\) is technically empty. That is because this set contains the empty set within it, so \\(S\\) is not empty. "],
["derivatives.html", "Chapter 4 Calculus 4.1 Sequences 4.2 The Limit of a Sequence 4.3 Series 4.4 Derivatives 4.5 Higher-Order Derivatives or, Derivatives of Derivatives of Derivatives 4.6 Composite Functions and the Chain Rule 4.7 Derivatives of Euler’s number and natural logs 4.8 Applications of the Derivative: Maxima and Minima 4.9 Partial Derivatives 4.10 L’H^opital’s Rule 4.11 Taylor Series Approximation 4.12 Summary: Derivative calculus in 6 steps 4.13 The Indefinite Integral: The Antiderivative 4.14 Common Rules of Integration 4.15 The Definite Integral: The Area under the Curve 4.16 Integration by Substitution 4.17 Integration by Parts, or Ultraviolet Voodoo", " Chapter 4 Calculus Topics: Sequences; Limit of a Sequence; Series; Derivatives; Higher-Order Derivatives; Composite Functions and The Chain Rule; Derivatives of Exp and Ln; Maxima and Minima; Partial Derivatives; L’H^opital’s Rule; Taylor Approximation; Derivative Calculus in 6 Steps; The Indefinite Integral: The Antiderivative; Common Rules of Integration; The Definite Integral: The Area under the Curve; Integration by Substitution; Integration by Parts Much of the material and examples for this lecture are taken from Simon &amp; Blume (1994) and from Boyce &amp; Diprima (1988) 4.1 Sequences A \\(\\{y_n\\}=\\{y_1, y_2, y_3, \\ldots, y_n\\}\\) is an ordered set of real numbers, where \\(y_1\\) is the first term in the sequence and \\(y_n\\) is the \\(n\\)th term. Generally, a sequence is , that is it extends to \\(n=\\infty\\). We can also write the sequence as \\(\\{y_n\\}^\\infty_{n=1}\\). Examples: Think of sequences like functions. Before, we had \\(y=f(x)\\) with \\(x\\) specified over some domain. Now we have \\(\\{y_n\\}=\\{f(n)\\}\\) with \\(n=1,2,3,\\ldots\\). Three kinds of sequences: Sequences like 1 above that converge to a limit. Sequences like 2 above that increase without bound. Sequences like 3 above that neither converge nor increase without bound — alternating over the number line. Boundedness and monotonicity: : if \\(|y_n|\\le K\\) for all \\(n\\) : \\(y_{n+1}&gt;y_n\\) for all \\(n\\) : \\(y_{n+1}&lt;y_n\\) for all \\(n\\) : Choose an infinite collection of entries from \\(\\{ y_n \\}\\), retaining their order. 4.2 The Limit of a Sequence We’re often interested in whether a sequence to a . Limits of sequences are conceptually similar to the limits of functions addressed in the previous lecture. . The sequence \\(\\{y_n\\}\\) has the limit \\(L\\), that is \\(\\lim\\limits_{n \\to \\infty} y_n =L\\), if for any \\(\\epsilon&gt;0\\) there is an integer \\(N\\) (which depends on \\(\\epsilon\\)) with the property that \\(|y_n -L|&lt;\\epsilon\\) for each \\(n&gt;N\\). \\(\\{y_n\\}\\) is said to converge to \\(L\\). If the above does not hold, then \\(\\{y_n\\}\\) diverges. : If \\(\\{y_n\\}\\) converges, then the limit \\(L\\) is unique. Let \\(\\lim\\limits_{n \\to \\infty} y_n = A\\) and \\(\\lim\\limits_{n \\to \\infty} z_n =B\\). Then Examples Finding the limit of a sequence in \\({\\bf R}^n\\) is similar to that in \\({\\bf R}^1\\). The sequence of vectors \\(\\bf \\{ y_n \\}\\) has the limit \\(\\bf L\\), that is \\(\\lim\\limits_{n\\to\\infty} {\\bf y_n}={\\bf L}\\), if for any \\(\\epsilon\\) there is an integer \\(N\\) where \\(\\bf ||y_n-L||&lt;\\epsilon\\) for each \\(n&gt;N\\). The sequence of vectors \\(\\bf \\{ y_n\\}\\) is said to converge to the vector \\(\\bf L\\) — and the distances between \\(\\bf y_n\\) and \\(\\bf L\\) converge to zero. Think of each coordinate of the vector \\(\\bf y_n\\) as being part of its own sequence over \\(n\\). Then a sequence of vectors in \\({\\bf R}^n\\) converges if and only if all \\(n\\) sequences of its components converge. Examples: : Any sequence contained in a compact (i.e., closed and bounded) subset of \\({\\bf R}^n\\) contains a convergent subsequence.\\ 4.3 Series The sum of the terms of a sequence is a . As there are both finite and infinite sequences, there are and . The series associated with the sequence \\(\\{y_n\\}=\\{y_1, y_2, y_3, \\ldots, y_n\\} = \\{y_n\\}_{n=1}^{\\infty}\\) is \\(\\sum_{n=1}^{\\infty} y_n\\). The \\(n\\)th partial sum \\(S_n\\) is defined as \\(S_n=\\sum_{k=1}^n y_k\\),the sum of the first \\(n\\) terms of the sequence. A series \\(\\sum y_n\\) converges if the sequence of partial sums \\(\\{S_1, S_2, S_3, ...\\}\\) converges, i.e has a finite limit. A is a series that can be written as \\(\\sum_{n=0}^{\\infty} r^n\\), where \\(r\\) is called the ratio. A geometric series converges to \\(\\frac{1}{1-r}\\) if \\(|r|&lt; 1\\) and diverges otherwise. For example, \\(\\sum_{n=0}^{\\infty} \\frac{1}{2^n} = 2\\). Examples of other series: 4.4 Derivatives The derivative of \\(f\\) at \\(x\\) is its rate of change at \\(x\\) — i.e., how much \\(f(x)\\) changes with a change in \\(x\\). For a line, the derivative is the slope.\\ For a curve, the derivative is the slope of the line tangent to the curve at \\(x\\). : Let \\(f\\) be a function whose domain includes an open interval containing the point \\(x\\). The derivative of \\(f\\) at \\(x\\) is given by \\[\\begin{eqnarray} f&#39;(x) &amp;=&amp;\\lim\\limits_{h\\to 0} \\frac{f(x+h)-f(x)}{(x+h)-x}\\nonumber\\\\ &amp;=&amp;\\lim\\limits_{h\\to 0} \\frac{f(x+h)-f(x)}{h}\\nonumber \\end{eqnarray}\\] If \\(f&#39;(x)\\) exists at a point \\(x\\), then \\(f\\) is said to be differentiable at \\(x\\). Similarly, if \\(f&#39;(x)\\) exists for every point a long an interval, then \\(f\\) is differentiable along that interval. For \\(f\\) to be differentiable at \\(x\\), \\(f\\) must be both continuous and “smooth’’ at \\(x\\). The process of calculating \\(f&#39;(x)\\) is called differentiation. Notation for derivatives: Suppose that \\(f\\) and \\(g\\) are differentiable at \\(x\\) and that \\(\\alpha\\) is a constant. Then the functions \\(f\\pm g\\), \\(\\alpha f\\), \\(f g\\), and \\(f/g\\) (provided \\(g(x)\\ne 0\\)) are also differentiable at \\(x\\). Additionally, 4.5 Higher-Order Derivatives or, Derivatives of Derivatives of Derivatives We can keep applying the differentiation process to functions that are themselves derivatives. The derivative of \\(f&#39;(x)\\) with respect to \\(x\\), would then be \\[f&#39;&#39;(x)=\\lim\\limits_{h\\to 0}\\frac{f&#39;(x+h)-f&#39;(x)}{h}\\] and so on. Similarly, the derivative of \\(f&#39;&#39;(x)\\) would be denoted \\(f&#39;&#39;&#39;(x)\\). \\(f&#39;(x)\\), \\(y&#39;\\), \\(\\frac{df(x)}{dx}\\), \\(\\frac{dy}{dx}\\) \\(f&#39;&#39;(x)\\), \\(y&#39;&#39;\\), \\(\\frac{d^2f(x)}{dx^2}\\), \\(\\frac{d^2y}{dx^2}\\) \\(\\frac{d^nf(x)}{dx^n}\\), \\(\\frac{d^ny}{dx^n}\\) Example: \\[\\begin{align*} f(x) &amp;=x^3 f&#39;(x) &amp;=3x^2 f&#39;&#39;(x) &amp;=6x f&#39;&#39;&#39;(x) &amp;=6 f&#39;&#39;&#39;&#39;(x) &amp;=0 \\end{align*}\\] 4.6 Composite Functions and the Chain Rule Composite functions are formed by substituting one function into another and are denoted by \\[(f\\circ g)(x)=f[g(x)]\\] To form \\(f[g(x)]\\), the range of \\(g\\) must be contained (at least in part) within the domain of \\(f\\). The domain of \\(f\\circ g\\) consists of all the points in the domain of \\(g\\) for which \\(g(x)\\) is in the domain of \\(f\\). Examples: : Let \\(y=(f\\circ g)(x)= f[g(x)]\\). The derivative of \\(y\\) with respect to \\(x\\) is \\[\\frac{d}{dx} \\{ f[g(x)] \\} = f&#39;[g(x)] g&#39;(x)\\] which can also be written as \\[\\frac{dy}{dx}=\\frac{dy}{dg(x)} \\frac{dg(x)}{dx}\\] (Note: the above does not imply that the \\(dg(x)\\)’s cancel out, as in fractions. They are part of the derivative notation and you can’t separate them out or cancel them.) The chain rule can be thought of as the derivative of the “outside” times the derivative of the “inside”, remembering that the derivative of the outside function is evaluated at the value of the inside function. : If \\(y=[g(x)]^k\\), then \\(dy/dx=k[g(x)]^{k-1}g&#39;(x)\\). 4.7 Derivatives of Euler’s number and natural logs Derivatives of Exp or \\(e\\): Examples: Find \\(dy/dx\\) for : Examples: Find \\(dy/dx\\) for 4.8 Applications of the Derivative: Maxima and Minima The first derivative, \\(f&#39;(x)\\), identifies whether the function \\(f(x)\\) at the point \\(x\\) is increasing or decreasing at \\(x\\). Examples: The second derivative \\(f&#39;&#39;(x)\\) identifies whether the function \\(f(x)\\) at the point \\(x\\) is Maximum (Minimum): \\(x_0\\) is a local maximum (minimum) if \\(f(x_0)&gt;f(x)\\) (\\(f(x_0)&lt;f(x))\\) for all \\(x\\) within some open interval containing \\(x_0\\). \\(x_0\\) is a __ global maximum (minimum)__ if \\(f(x_0)&gt;f(x)\\) (\\(f(x_0)&lt;f(x))\\) for all \\(x\\) in the domain of \\(f\\). Critical points: Given the function \\(f\\) defined over domain \\(D\\), all of the following are defined as critical points: Any interior point of \\(D\\) where \\(f&#39;(x)=0\\). Any interior point of \\(D\\) where \\(f&#39;(x)\\) does not exist. Any endpoint that is in \\(D\\). The maxima and minima will be a subset of the critical points. Second Derivative Test of Maxima/Minima: We can use the second derivative to tell us whether a point is a maximum or minimum of \\(f(x)\\). . Sometimes no global max or min exists — e.g., \\(f(x)\\) not bounded above or below. However, there are three situations where we can fairly easily identify global max or min. Examples: Find any critical points and identify whether they’re a max, min, or saddle point: 4.9 Partial Derivatives Suppose we have a function \\(f\\) now of two (or more) variables and we want to determine the rate of change relative to one of the variables. To do so, we would find it’s partial derivative, which is defined similar to the derivative of a function of one variable. Partial Derivative: Let \\(f\\) be a function of the variables \\((x_1,\\ldots,x_n)\\). The partial derivative of \\(f\\) with respect to \\(x_i\\) is \\[\\frac{\\partial f}{\\partial x_i} (x_1,\\ldots,x_n) = \\lim\\limits_{h\\to 0} \\frac{f(x_1,\\ldots,x_i+h,\\ldots,x_n)-f(x_1,\\ldots,x_i,\\ldots,x_n)}{h}\\] Only the \\(i\\)th variable changes — the others are treated as constants. We can take higher-order partial derivatives, like we did with functions of a single variable, except now we the higher-order partials can be with respect to multiple variables. 4.10 L’H^opital’s Rule In studying limits, we saw that \\(\\lim\\limits_{x \\to c} f(x)/g(x) = \\left(\\lim\\limits_{x \\to c} f(x)\\right)/\\left(\\lim\\limits_{x \\to c} g(x)\\right)\\), provided that \\(\\lim\\limits_{x \\to c} g(x)\\ne 0\\). If both \\(\\lim\\limits_{x \\to c} f(x)=0\\) and \\(\\lim\\limits_{x \\to c} g(x)=0\\), then we get an indeterminate form of the type \\(0/0\\) as \\(x\\to c\\). However, a limit may still exist. We can use L’H^opital’s rule to find the limit. L’H^opital’s Rule: Suppose \\(f\\) and \\(g\\) are differentiable on some interval \\(a&lt;x&lt;b\\) and that either Suppose further that \\(g&#39;(x)\\) is never zero on \\(a&lt;x&lt;b\\) and that \\[\\lim\\limits_{x\\to a^+} \\frac{f&#39;(x)}{g&#39;(x)}=L\\] then \\[\\lim\\limits_{x\\to a^+} \\frac{f(x)}{g(x)}=L\\] %Put more simply, if \\(\\lim\\limits_{x\\to a f(x)}\\) is of the form \\(0/0\\) or \\(\\pm \\infty / \\pm \\infty\\), then \\[\\lim\\limits_{x\\to a} f(x) = \\lim\\limits_{x\\to a} f&#39;(x)\\]\\ And if \\(\\lim\\limits_{x\\to a} \\frac{f&#39;(x)}{g&#39;(x)} = 0/0\\) or \\(\\pm \\infty / \\pm \\infty\\) then you can apply L’H^opital’s rule a second time, and continue applying it until you have a solution. 4.11 Taylor Series Approximation (also known as the delta method) are used commonly to represent functions as infinite series of the function’s derivatives at some point \\(a\\). For example, Taylor series are very helpful in representing nonlinear functions as linear functions. One can thus approximate functions by using lower-order, finite series known as . If \\(a=0\\), the series is called a Maclaurin series. Specifically, a Taylor series of a real or complex function \\(f(x)\\) that is infinitely differentiable in the neighborhood of point \\(a\\) is: \\[\\begin{align*} f(x) &amp;= f(a) + \\frac{f&#39;(a)}{1!} (x-a) + \\frac{f&#39;&#39;(a)}{2!} (x-a)^2 + \\cdots\\\\ &amp;= \\sum_{n=0}^\\infty \\frac{f^{(n)} (a)}{n!} (x-a)^n \\end{align*}\\] Taylor Approximation: We can often approximate the curvature of a function \\(f(x)\\) at point \\(a\\) using a 2nd order Taylor polynomial around point \\(a\\): \\[f(x) = f(a) + \\frac{f&#39;(a)}{1!} (x-a) + \\frac{f&#39;&#39;(a)}{2!} (x-a)^2 + R_2\\] \\(R_2\\) is the Lagrange remainder and often treated as negligible, giving us: \\[f(x) \\approx f(a) + f&#39;(a)(x-a) + \\dfrac{f&#39;&#39;(a)}{2} (x-a)^2\\] Taylor series expansion is easily generalized to multiple dimensions.\\ : The Hessian is used in a Taylor polynomial approximation to \\(\\fx\\) and provides information about the curvature of \\(\\fx\\) at \\(\\bm{x}\\) — e.g., which tells us whether a critical point \\(\\bm{x}^*\\) is a min, max, or saddle point. 4.12 Summary: Derivative calculus in 6 steps With these six rules (and decent algebra and trigonometry skills) you can figure out the derivative of anything. Sum rule: \\[[f(x)\\pm g(x)]&#39; = f&#39;(x)\\pm g&#39;(x)\\] Product rule: \\[[f(x)g(x)]&#39; = f&#39;(x)g(x)+f(x)g&#39;(x)\\] Power rule: \\[[x^k]&#39; = k x^{k-1}\\] Chain rule: \\[\\frac{d}{dx} \\{ f[g(x)] \\} = f&#39;[g(x)] g&#39;(x)\\] \\(e^x\\): \\[\\frac{d}{dx} e^x = e^x\\] Trig identity: \\[\\frac{d}{dx} \\sin(x) = \\cos(x)\\] 4.13 The Indefinite Integral: The Antiderivative So far, we’ve been interested in finding the derivative \\(g=f&#39;\\) of a function \\(f\\). However, sometimes we’re interested in exactly the reverse: finding the function \\(f\\) for which \\(g\\) is its derivative. We refer to \\(f\\) as the {} of \\(g\\). Let \\(DF\\) be the derivative of \\(F\\). And let \\(DF(x)\\) be the derivative of \\(F\\) evaluated at \\(x\\). Then the antiderivative is denoted by \\(D^{-1}\\) (i.e., the inverse derivative). If \\(DF=f\\), then \\(F=D^{-1}f\\). Indefinite Integral: Equivalently, if \\(F\\) is the antiderivative of \\(f\\), then \\(F\\) is also called the indefinite integral of \\(f\\) and written \\(F(x)=\\int\\limits f(x)dx\\). Notice from these examples that while there is only a single derivative for any function, there are multiple antiderivatives: one for any arbitrary constant \\(c\\). \\(c\\) just shifts the curve up or down on the \\(y\\)-axis. If more info is present about the antiderivative — e.g., that it passes through a particular point — then we can solve for a specific value of \\(c\\). \\end{itemize} 4.14 Common Rules of Integration 4.15 The Definite Integral: The Area under the Curve Riemann Sum: Suppose we want to determine the area \\(A(R)\\) of a region \\(R\\) defined by a curve \\(f(x)\\) and some interval \\(a\\le x \\le b\\). One way to calculate the area would be to divide the interval \\(a\\le x\\le b\\) into \\(n\\) subintervals of length \\(\\Delta x\\) and then approximate the region with a series of rectangles, where the base of each rectangle is \\(\\Delta x\\) and the height is \\(f(x)\\) at the midpoint of that interval. \\(A(R)\\) would then be approximated by the area of the union of the rectangles, which is given by \\[S(f,\\Delta x)=\\sum\\limits_{i=1}^n f(x_i)\\Delta x\\] and is called a Riemann sum. As we decrease the size of the subintervals \\(\\Delta x\\), making the rectangles “thinner,” we would expect our approximation of the area of the region to become closer to the true area. This gives the limiting process \\[A(R)=\\lim\\limits_{\\Delta x\\to 0}\\sum\\limits_{i=1}^n f(x_i)\\Delta x\\] Riemann Integral: If for a given function \\(f\\) the Riemann sum approaches a limit as \\(\\Delta x \\to 0\\), then that limit is called the Riemann integral of \\(f\\) from \\(a\\) to \\(b\\). Formally, \\[\\int\\limits_a^b f(x) dx= \\lim\\limits_{\\Delta x\\to 0} \\sum\\limits_{i=1}^n f(x_i)\\Delta x\\] Definite Integral: We use the notation \\(\\int\\limits_a^b f(x) dx\\) to denote the definite integral of \\(f\\) from \\(a\\) to \\(b\\). In words, the definite integral \\(\\int\\limits_a^b f(x)dx\\) is the area under the ``curve&quot; f(x) from \\(x=a\\) to \\(x=b\\). First Fundamental Theorem of Calculus: Let the function \\(f\\) be bounded on \\([a,b]\\) and continuous on \\((a,b)\\). Then the function \\[F(x)=\\int\\limits_a^x f(t)dt, \\quad a\\le x\\le b\\] has a derivative at each point in \\((a,b)\\) and \\[F&#39;(x)=f(x), \\quad a&lt;x&lt;b\\] This last point shows that differentiation is the inverse of integration. Second Fundamental Theorem of Calculus: Let the function \\(f\\) be bounded on \\([a,b]\\) and continuous on \\((a,b)\\). Let \\(F\\) be any function that is continuous on \\([a,b]\\) such that \\(F&#39;(x)=f(x)\\) on \\((a,b)\\). Then \\[\\int\\limits_a^bf(x)dx = F(b)-F(a)\\] \\(\\int\\limits_a^b f(x)dx\\): Find the indefinite integral \\(F(x)\\). Evaluate \\(F(b)-F(a)\\). Properties of Definite Integrals: 4.16 Integration by Substitution Sometimes the integrand doesn’t appear integrable using common rules and antiderivatives. A method one might try is integration by substitution, which is related to the Chain Rule. Suppose we want to find the indefinite integral \\(\\int g(x)dx\\) and assume we can identify a function \\(u(x)\\) such that \\(g(x)=f[u(x)]u&#39;(x)\\). Let’s refer to the antiderivative of \\(f\\) as \\(F\\). Then the chain rule tells us that \\(\\frac{d}{dx} F[u(x)]=f[u(x)]u&#39;(x)\\). So, \\(F[u(x)]\\) is the antiderivative of \\(g\\). We can then write \\[\\int g(x) dx= \\int f[u(x)]u&#39;(x)dx = \\int \\frac{d}{dx} F[u(x)]dx = F[u(x)]+c\\] Procedure to determine the indefinite integral \\(\\int g(x)dx\\) by the method of substitution: Identify some part of \\(g(x)\\) that might be simplified by substituting in a single variable \\(u\\) (which will then be a function of \\(x\\)). Determine if \\(g(x)dx\\) can be reformulated in terms of \\(u\\) and \\(du\\). Solve the indefinite integral. Substitute back in for \\(x\\) Substitution can also be used to calculate a definite integral. Using the same procedure as above, \\[\\int\\limits_a^b g(x)dx=\\int\\limits_c^d f(u)du = F(d)-F(c)\\] where \\(c=u(a)\\) and \\(d=u(b)\\). Example: \\(\\int x^2 \\sqrt{x+1}dx\\) The problem here is the \\(\\sqrt{x+1}\\) term. However, if the integrand had \\(\\sqrt{x}\\) times some polynomial, then we’d be in business. Let’s try \\(u=x+1\\). Then \\(x=u-1\\) and \\(dx=du\\). Substituting these into the above equation, we get \\[\\begin{eqnarray} \\int x^2\\sqrt{x+1}dx&amp;=&amp;\\int (u-1)^2\\sqrt{u}du\\nonumber\\\\ &amp;=&amp;\\int (u^2-2u+1)u^{1/2}du\\nonumber\\\\ &amp;=&amp;\\int (u^{5/2}-2u^{3/2}+u^{1/2})du\\nonumber \\end{eqnarray}\\] We can easily integrate this, since it’s just a polynomial. Doing so and substituting \\(u=x+1\\) back in, we get \\[\\int x^2\\sqrt{x+1}dx=2(x+1)^{3/2}\\left[\\frac{1}{7}(x+1)^2 - \\frac{2}{5}(x+1)+\\frac{1}{3}\\right]+c\\] For the above problem, we could have also used the substitution \\(u=\\sqrt{x+1}\\). Then \\(x=u^2-1\\) and \\(dx=2u du\\). Substituting these in, we get \\[\\int x^2\\sqrt{x+1}dx=\\int (u^2-1)^2 u 2u du\\] which when expanded is again a polynomial and gives the same result as above. Another Example \\(\\int\\limits_0^1 \\frac{5e^{2x}}{(1+e^{2x})^{1/3}}dx\\) When an expression is raised to a power, it’s often helpful to use this expression as the basis for a substitution. So, let \\(u=1+e^{2x}\\). Then \\(du=2e^{2x}dx\\) and we can set \\(5e^{2x}dx=5du/2\\). Additionally, \\(u=2\\) when \\(x=0\\) and \\(u=1+e^2\\) when \\(x=1\\). Substituting all of this in, we get \\[\\begin{eqnarray} \\int\\limits_0^1 \\frac{5e^{2x}}{(1+e^{2x})^{1/3}}dx &amp;=&amp; \\frac{5}{2}\\int\\limits_2^{1+e^2}\\frac{du}{u^{1/3}}\\nonumber\\\\ &amp;=&amp; \\frac{5}{2}\\int\\limits_2^{1+e^2} u^{-1/3}du\\nonumber\\\\ &amp;=&amp; \\left. \\frac{15}{4} u^{2/3} \\right|_2^{1+e^2}\\nonumber\\\\ &amp;=&amp; 9.53\\nonumber \\end{eqnarray}\\] 4.17 Integration by Parts, or Ultraviolet Voodoo Another useful integration technique is {}, which is related to the Product Rule of differentiation. The product rule states that \\[\\frac{d}{dx}(uv)=u\\frac{dv}{dx}+v\\frac{du}{dx}\\] Integrating this and rearranging, we get \\[\\int u\\frac{dv}{dx}dx= u v - \\int v \\frac{du}{dx}dx\\] or \\[\\int u(x) v&#39;(x)dx=u(x)v(x) - \\int v(x)u&#39;(x)dx\\] More frequently remembered as \\[\\int u dv = u v - \\int v du\\] where \\(du=u&#39;(x)dx\\) and \\(dv=v&#39;(x)dx\\). For definite integrals: \\(\\int\\limits_a^b u\\frac{dv}{dx}dx = \\left. u v \\right|_a^b - \\int\\limits_a^b v \\frac{du}{dx}dx\\) Our goal here is to find expressions for \\(u\\) and \\(dv\\) that, when substituted into the above equation, yield an expression that’s more easily evaluated. Examples: "],
["optimization.html", "Chapter 5 Optimization 5.1 Quadratic Forms 5.2 Concavity of Quadratic Forms 5.3 Definiteness of Quadratic Forms 5.4 First Order Conditions 5.5 Second Order Conditions 5.6 Definiteness and Concavity 5.7 Global Maxima and Minima 5.8 Constrained Optimization 5.9 Equality Constraints 5.10 Inequality Constraints 5.11 Kuhn-Tucker Conditions", " Chapter 5 Optimization Topics: \\(\\bullet\\) Quadratic Forms \\(\\bullet\\) Definiteness of Quadratic Forms \\(\\bullet\\) Maxima and Minima in \\({\\bf R}^n\\) \\(\\bullet\\) First Order Conditions \\(\\bullet\\) Second Order Conditions \\(\\bullet\\) Global Maxima and Minima \\(\\bullet\\) Constrained Optimization \\(\\bullet\\) Equality Constraints \\(\\bullet\\) Inequality Constraints \\(\\bullet\\) Kuhn-Tucker Conditions Much of the material and examples for this lecture are taken from Simon &amp; Blume (1994) and Ecker &amp; Kupferschmid (1988) 5.1 Quadratic Forms Quadratic forms important because 1. Approximates local curvature around a point — e.g., used to identify max vs min vs saddle point. 2. Simple, so easy to deal with. 3. Have a matrix representation. Quadratic Form: A polynomial where each term is a monomial of degree 2 in any number of variables: \\[\\begin{align*} \\text{One variable: }&amp; Q(x_1) = a_{11}x_1^2\\\\ \\text{Two variables: }&amp; Q(x_1,x_2) = a_{11}x_1^2 + a_{12}x_1x_2 + a_{22}x_2^2\\\\ \\text{N variables: }&amp; Q(x_1,\\cdots,x_n)=\\sum\\limits_{i\\le j} a_{ij}x_i x_j \\end{align*}\\] which can be written in matrix terms: \\[\\begin{align*} \\text{One variable: }&amp; Q({\\bf x}) = x_1^T a_{11} x_1\\\\ \\text{N variables: }&amp; Q({\\bf x})=\\begin{pmatrix} x1&amp;x2&amp;\\cdots&amp;x_n\\end{pmatrix} \\begin{pmatrix} a_{11}&amp;\\frac{1}{2}a_{12}&amp;\\cdots&amp;\\frac{1}{2}a_{1n}\\\\ \\frac{1}{2}a_{12}&amp;a_{22}&amp;\\cdots&amp;\\frac{1}{2}a_{2n}\\\\ \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\ \\frac{1}{2}a_{1n}&amp;\\frac{1}{2}a_{2n}&amp;\\cdots&amp;a_{nn} \\end{pmatrix} \\begin{pmatrix} x_1\\\\x_2\\\\\\vdots\\\\x_n\\end{pmatrix}\\\\ &amp;={\\bf x}^T{\\bf A}{\\bf x} \\end{align*}\\] Examples: 5.2 Concavity of Quadratic Forms Concavity helps identify the curvature of a function, \\(f( x)\\), in 2 dimensional space. : The second derivative can be used to understand concavity. If \\[\\begin{array}{lll} f&#39;&#39;(x) &lt; 0 &amp; \\Rightarrow &amp; \\text{Concave}\\\\ f&#39;&#39;(x) &gt; 0 &amp; \\Rightarrow &amp; \\text{Convex} \\end{array}\\] 5.3 Definiteness of Quadratic Forms Definiteness helps identify the curvature of a function, \\(Q({\\bf x})\\), in n dimensional space. Definiteness: By definition, a quadratic form always takes on the value of zero when \\(x = 0\\), \\(Q({\\bf x})=0\\) at \\({\\bf x}=0\\). The definiteness of the matrix \\({\\bf A}\\) is determined by whether the quadratic form \\(Q({\\bf x})={\\bf x}^T{\\bf A}{\\bf x}\\) is greater than zero, less than zero, or sometimes both over all \\({\\bf x}\\ne 0\\). Examples: 5.4 First Order Conditions When we examined functions of one variable \\(x\\), we found critical points by taking the first derivative, setting it to zero, and solving for \\(x\\). For functions of \\(n\\) variables, the critical points are found in much the same way, except now we set the partial derivatives equal to zero. Gradient (\\(\\nabla \\fx\\)): Given a function \\(f({\\bf x})\\) in \\(n\\) variables, the gradient \\(\\nabla \\fx\\) is a column vector, where the \\(i\\)th element is the partial derivative of \\(f({\\bf x})\\) with respect to \\(x_i\\): \\[\\nabla \\fx = \\begin{pmatrix} \\frac{\\partial \\fx}{\\partial x_1}\\\\[9pt] \\frac{\\partial \\fx}{\\partial x_2}\\\\ \\vdots \\\\[3pt] \\frac{\\partial \\fx}{\\partial x_n} \\end{pmatrix}\\] Critical Point: \\({\\bf x}^*\\) is a critical point iff \\(\\nabla f({\\bf x}^*)=0\\). If the partial derivative of f(x) with respect to \\(x^*\\) is 0, then \\({\\bf x}^*\\) is a critical point. To solve for \\({\\bf x}^*\\), find the gradient, set each element equal to 0, and solve the system of equations. \\[{\\bf x}^* = \\begin{pmatrix} x_1^*\\\\x_2^*\\\\ \\vdots \\\\ x_n^*\\end{pmatrix}\\] Example: Given a function \\(\\fx=(x_1-1)^2+x_2^2+1\\), find the: \\end{itemize} 5.5 Second Order Conditions When we found a critical point for a function of one variable, we used the second derivative as an indicator of the curvature at the point in order to determine whether the point was a min, max, or saddle (second derivative test of concavity). For functions of \\(n\\) variables, we use as an indicator of curvature. Hessian (\\({\\bf H(x)}\\)): Given a function \\(f({\\bf x})\\) in \\(n\\) variables, the hessian \\({\\bf H(x)}\\) is an \\(n\\times n\\) matrix, where the \\((i,j)\\)th element is the second order partial derivative of \\(f({\\bf x})\\) with respect to \\(x_i\\) and \\(x_j\\): \\[{\\bf H(x)}=\\begin{pmatrix} \\frac{\\partial^2 \\fx}{\\partial x_1^2}&amp;\\frac{\\partial^2\\fx}{\\partial x_1 \\partial x_2}&amp; \\cdots &amp; \\frac{\\partial^2 \\fx}{\\partial x_1 \\partial x_n}\\\\[9pt] \\frac{\\partial^2 \\fx}{\\partial x_2 \\partial x_1}&amp;\\frac{\\partial^2\\fx}{\\partial x_2^2}&amp; \\cdots &amp; \\frac{\\partial^2 \\fx}{\\partial x_2 \\partial x_n}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\[3pt] \\frac{\\partial^2 \\fx}{\\partial x_n \\partial x_1}&amp;\\frac{\\partial^2\\fx}{\\partial x_n \\partial x_2}&amp; \\cdots &amp; \\frac{\\partial^2 \\fx}{\\partial x_n^2}\\end{pmatrix}\\] Note that the hessian will be a symmetric matrix because \\(\\frac{\\partial \\fx}{\\partial x_1\\partial x_2} = \\frac{\\partial \\fx}{\\partial x_2\\partial x_1}\\). Also note that given that \\(\\fx\\) is of quadratic form, each element of the hessian will be a constant. Second Order Conditions:\\[6pt] Given a function \\(\\fx\\) and a point \\({\\bf x}^*\\) such that \\(\\nabla f({\\bf x}^*)=0\\), Example: We found that the only critical point of \\(\\fx=(x_1-1)^2+x_2^2+1\\) is at \\({\\bf x}^*=(1,0)\\). Is it a min, max, or saddle point? 5.6 Definiteness and Concavity Although definiteness helps us to understand the curvature of an n-dimensional function, it does not necessarily tell us whether the function is globally concave or convex. We need to know whether a function is globally concave or convex to determine whether a critical point is a global min or max. Testing for Global Concavity: We can use the definiteness of the Hessian to determine whether a function is globally concave or convex: Notice that the definiteness conditions must be satisfied over the entire domain. 5.7 Global Maxima and Minima Global Max/Min Conditions: Given a function \\(\\fx\\) and a point \\({\\bf x}^*\\) such that \\(\\nabla f({\\bf x}^*)=0\\), Note that showing that \\(\\bf H(x^*)\\) is negative semidefinite is not enough to guarantee \\({\\bf x}^*\\) is a local max. However, showing that \\(\\bf H(x)\\) is negative semidefinite for all \\({\\bf x}\\) guarantees that \\(x^*\\) is a global max. (The same goes for positive semidefinite and minima.)\\ Example: Take \\(f_1(x)=x^4\\) and \\(f_2(x)=-x^4\\). Both have \\(x=0\\) as a critical point. Unfortunately, \\(f&#39;&#39;_1(0)=0\\) and \\(f&#39;&#39;_2(0)=0\\), so we can’t tell whether \\(x=0\\) is a min or max for either. However, \\(f&#39;&#39;_1(x)=12x^2\\) and \\(f&#39;&#39;_2(x)=-12x^2\\). For all \\(x\\), \\(f&#39;&#39;_1(x)\\ge 0\\) and \\(f&#39;&#39;_2(x)\\le 0\\) — i.e., \\(f_1(x)\\) is globally convex and \\(f_2(x)\\) is globally concave. So \\(x=0\\) is a global min of \\(f_1(x)\\) and a global max of \\(f_2(x)\\). Example Given \\(f({\\bf x})=x_1^3-x_2^3+9x_1x_2\\), find any maxima or minima. 5.8 Constrained Optimization We have already looked at optimizing a function in one or more dimensions over the whole domain of the function. Often, however, we want to find the maximum or minimum of a function over some restricted part of its domain.\\ ex: Maximizing utility subject to a budget constraint Types of Constraints: For a function \\(f(x_1, \\dots, x_n)\\), there are two types of constraints that can be imposed: In any constrained optimization problem, the constrained maximum will always be less than or equal to the unconstrained maximum. If the constrained maximum is less than the unconstrained maximum, then the constraint is binding. Essentially, this means that you can treat your constraint as an equality constraint rather than an inequality constraint. For example, the budget constraint binds when you spend your entire budget. This generally happens because we believe that utility is strictly increasing in consumption, i.e. you always want more so you spend everything you have. Any number of constraints can be placed on an optimization problem. When working with multiple constraints, always make sure that the set of constraints are not pathological; it must be possible for all of the constraints to be satisfied simultaneously. \\[\\max_{x_1,x_2} f(x_1,x_2) \\text{ s.t. } c(x_1,x_2)\\] \\[\\min_{x_1,x_2} f(x_1,x_2) \\text{ s.t. } c(x_1,x_2)\\] This tells us to maximize/minimize our function, \\(f(x_1,x_2)\\), with respect to the choice variables, \\(x_1,x_2\\), subject to the constraint. Example: \\[\\max_{x_1,x_2} f(x_1, x_2) = -(x_1^2 + 2x_2^2) \\text{ s.t. }x_1 + x_2 = 4\\] It is easy to see that the maximum occurs at \\((x_1, x_2) = (0,0)\\), but that does not satisfy the constraint. How should we proceed? 5.9 Equality Constraints Equality constraints are the easiest to deal with because we know that the maximum or minimum has to lie on the (intersection of the) constraint(s). The trick is to change the problem from a constrained optimization problem in \\(n\\) variables to an unconstrained optimization problem in \\(n + k\\) variables, adding variable for equality constraint. We do this using a lagrangian multiplier. Lagrangian function: The Lagrangian function allows us to combine the function we want to optimize and the constraint function into a single function. Once we have this single function, we can proceed as if this were an optimization problem.\\ For each constraint, we must include a (\\(\\lambda_i\\)) as an additional variable in the analysis. These terms are the link between the constraint and the Lagrangian function.\\ Given a set-up: \\[\\max_{x_1,x_2}/\\min_{x_1,x_2} f(x_1,x_2) \\text{ s.t. } c(x_1,x_2) = a\\] We define the Lagrangian function \\(L(x_1,x_2,\\lambda_1)\\) as follows: \\[L(x_1,x_2,\\lambda_1) = f(x_1,x_2) - \\lambda_1 (c(x_1,x_2) - a)\\] More generally, in : \\[ L(x_1, \\dots, x_n, \\lambda_1, \\dots, \\lambda_k) = f(x_1, \\dots, x_n) - \\sum_{i=1}^k\\lambda_i(c_i(x_1,\\dots, x_n) - r_i)\\] \\ Note that above we subtract the lagrangian term we subtract the constraint constant from the constraint function. Occasionally, you may see the following alternative form of the Lagrangian, which is : \\[ L(x_1, \\dots, x_n, \\lambda_1, \\dots, \\lambda_k) = f(x_1, \\dots, x_n) + \\sum_{i=1}^k\\lambda_i(r_i - c_i(x_1,\\dots, x_n))\\] Here we add the lagrangian term we subtract the constraing function from the constraint constant. : To find the critical points, we take the partial derivatives of lagrangian function, \\(L(x_1, \\dots, x_n, \\lambda_1, \\dots, \\lambda_k)\\), with respect to each of its variables (all choice variables \\({\\bf x}\\) all lagrangian multipliers \\({\\bf \\lambda}\\)). At a critical point, of these partial derivatives must be equal to zero, so we obtain a system of : \\[\\begin{eqnarray*} \\frac{\\partial L}{\\partial x_1} = \\frac{\\partial f}{\\partial x_1} - \\sum_{i = 1}^k\\lambda_i\\frac{\\partial c_i}{\\partial x_1} &amp; = &amp; 0\\\\ \\vdots &amp; = &amp; \\vdots \\nonumber \\\\ \\frac{\\partial L}{\\partial x_n} = \\frac{\\partial f}{\\partial x_n} - \\sum_{i = 1}^k\\lambda_i\\frac{\\partial c_i}{\\partial x_n} &amp; = &amp; 0\\\\ \\frac{\\partial L}{\\partial \\lambda_1} = c_1(x_i, \\dots, x_n) - r_1&amp; = &amp; 0\\\\ \\vdots &amp; = &amp; \\vdots \\nonumber \\\\ \\frac{\\partial L}{\\partial \\lambda_k} = c_k(x_i, \\dots, x_n) - r_k &amp; = &amp; 0 \\end{eqnarray*}\\] We can then solve this system of equations, because there are \\(n+k\\) equations and \\(n+k\\) unknowns, to calculate the critical point \\((x_1^*,\\dots,x_n^*,\\lambda_1^*,\\dots,\\lambda_k^*)\\). There may be more than one critical point, i.e. we need to verify that the critical point we find is a maximum/minimum. Similar to unconstrained optimization, we can do this by checking the second-order conditions. Example: \\[\\max_{x_1,x_2} f(x) = -(x_1^2 + 2x_2^2) \\text{ s.t. } x_1 + x_2 = 4\\] Notice that when we take the partial derivative of L with respect to the lagranigian multiplier and set it equal to 0, we return exactly our constraint! This is why signs matter. 5.10 Inequality Constraints Inequality constraints define the boundary of a region over which we seek to optimize the function. This makes inequality constraints more challenging because we do not know if the maximum/minimum lies along one of the constraints (the constraint binds) or in the interior of the region. We must introduce more variables in order to turn the problem into an unconstrained optimization. Slack: For inequality constraint \\(c_i(x_1, \\dots, x_n) \\leq a_i\\), we define a slack variable \\(s_i^2\\) for which the expression \\(c_i(x_1, \\dots, x_n) \\leq a_i - s_i^2\\) would hold with equality. These slack variables capture how close the constraint comes to binding. We use \\(s^2\\) rather than \\(s\\) to ensure that the slack is positive. Slack is just a way to transform our constraints. Given a set-up and these edited constraints: \\[\\max_{x_1,x_2}/\\min_{x_1,x_2} f(x_1,x_2) \\text{ s.t. } c(x_1,x_2) \\le a_1\\] Adding in Slack: \\[\\max_{x_1,x_2}/\\min_{x_1,x_2} f(x_1,x_2) \\text{ s.t. } c(x_1,x_2) \\le a_1 - s_1^2\\] We define the Lagrangian function \\(L(x_1,x_2,\\lambda_1,s_1)\\) as follows: \\[L(x_1,x_2,\\lambda_1,s_1) = f(x_1,x_2) - \\lambda_1 ( c(x_1,x_2) + s_1^2 - a_1)\\] More generally, in : \\[ L(x_1, \\dots, x_n, \\lambda_1, \\dots, \\lambda_k, s_1, \\dots, s_k) = f(x_1, \\dots, x_n) - \\sum_{i = 1}^k \\lambda_i(c_i(x_1,\\dots, x_n) + s_i^2 - a_i)\\] : To find the critical points, we take the partial derivatives of the lagrangian function, \\(L(x_1,\\dots,x_n,\\lambda_1,\\dots,\\lambda_k,s_1,\\dots,s_k)\\), with respect to each of its variables (all choice variables \\(x\\), all lagrangian multipliers \\(\\lambda\\), and all slack variables \\(s\\)). At a critical point, of these partial derivatives must be equal to zero, so we obtain a system of : \\[\\begin{eqnarray*} \\frac{\\partial L}{\\partial x_1} = \\frac{\\partial f}{\\partial x_1} - \\sum_{i = 1}^k\\lambda_i\\frac{\\partial c_i}{\\partial x_1} &amp; = &amp; 0\\\\ \\vdots &amp; = &amp; \\vdots \\nonumber \\\\ \\frac{\\partial L}{\\partial x_n} = \\frac{\\partial f}{\\partial x_n} - \\sum_{i = 1}^k\\lambda_i\\frac{\\partial c_i}{\\partial x_n} &amp; = &amp; 0\\\\ \\frac{\\partial L}{\\partial \\lambda_1} = c_1(x_i, \\dots, x_n) + s_1^2 - b_1&amp; = &amp; 0\\\\ \\vdots &amp; = &amp; \\vdots \\nonumber \\\\ \\frac{\\partial L}{\\partial \\lambda_k} = c_k(x_i, \\dots, x_n) + s_k^2 - b_k &amp; = &amp; 0\\\\ \\frac{\\partial L}{\\partial s_1} = 2s_1\\lambda_1 &amp; = &amp; 0\\\\ \\vdots &amp; = &amp; \\vdots \\nonumber \\\\ \\frac{\\partial L}{\\partial s_k} = 2s_k\\lambda_k &amp; = &amp; 0 \\end{eqnarray*}\\] : The last set of first order conditions of the form \\(2s_i\\lambda_i = 0\\) (the partials taken with respect to the slack variables) are known as complementary slackness conditions. These conditions can be satisfied one of three ways: Example: Find the critical points for the following constrained optimization: \\[\\max_{x_1,x_2} f(x) = -(x_1^2 + 2x_2^2) \\text{ s.t. } x_1 + x_2 \\le 4\\] Example: Find the critical points for the following constrained optimization: \\[\\max_{x_1,x_2} f(x) = -(x_1^2 + 2x_2^2) \\text{ s.t. } \\begin{array}{l} x_1 + x_2 \\le 4\\\\ x_1 \\ge 0\\\\ x_2 \\ge 0 \\end{array}\\] 5.11 Kuhn-Tucker Conditions As you can see, this can be a pain. When dealing explicitly with , this process is simplified by using the Kuhn-Tucker method. : Because the problem of maximizing a function subject to inequality and non-negativity constraints arises frequently in economics, the Kuhn-Tucker approach provides a method that often makes it easier to both calculate the critical points and identify points that are (local) maxima.\\ Given a : \\[\\max_{x_1,x_2}/\\min_{x_1,x_2} f(x_1,x_2) \\text{ s.t. } \\begin{array}{l} c(x_1,x_2) \\le a_1\\\\ x_1 \\ge 0 \\\\ gx_2 \\ge 0 \\end{array}\\] We define the Lagrangian function \\(L(x_1,x_2,\\lambda_1)\\) the same as if we did not have the non-negativity constraints: \\[L(x_1,x_2,\\lambda_2) = f(x_1,x_2) - \\lambda_1(c(x_1,x_2) - a_1)\\] More generally, in : \\[ L(x_1, \\dots, x_n, \\lambda_1, \\dots, \\lambda_k) = f(x_1, \\dots, x_n) - \\sum_{i=1}^k\\lambda_i(c_i(x_1,\\dots, x_n) - a_i)\\] : To find the critical points, we first calculate the by taking the partial derivatives of the lagrangian function, \\(L(x_1,\\dots,x_n,\\lambda_1,\\dots,\\lambda_k)\\), with respect to each of its variables (all choice variable s\\(x\\) and all lagrangian multipliers \\(\\lambda\\)) we calculate the by multiplying each partial derivative by its respective variable include for all variables (choice variables \\(x\\) and lagrangian multipliers \\(\\lambda\\)).\\ \\[\\begin{eqnarray*} \\frac{\\partial L}{\\partial x_1} \\leq 0, &amp; \\dots, &amp; \\frac{\\partial L}{\\partial x_n} \\leq 0\\\\ \\frac{\\partial L}{\\partial \\lambda_1} \\geq 0, &amp; \\dots, &amp; \\frac{\\partial L}{\\partial \\lambda_m} \\geq 0 \\end{eqnarray*}\\] \\[\\begin{eqnarray*} x_1\\frac{\\partial L}{\\partial x_1} = 0, &amp; \\dots, &amp; x_n\\frac{\\partial L}{\\partial x_n} = 0\\\\ \\lambda_1\\frac{\\partial L}{\\partial \\lambda_1} = 0, &amp; \\dots, &amp; \\lambda_m \\frac{\\partial L}{\\partial \\lambda_m} = 0 \\end{eqnarray*}\\] \\[\\begin{eqnarray*} x_1 \\geq 0 &amp; \\dots &amp; x_n \\geq 0\\\\ \\lambda_1 \\geq 0 &amp; \\dots &amp; \\lambda_m \\geq 0 \\end{eqnarray*}\\] Note that some of these conditions are set equal to 0, while others are set as inequalities!\\ Note also that to minimize the function \\(f(x_1, \\dots, x_n)\\), the simplest thing to do is maximize the function \\(-f(x_1, \\dots, x_n)\\); all of the conditions remain the same after reformulating as a maximization problem.\\ There are additional assumptions (notably, f(x) is quasi-concave and the constraints are convex) that are sufficient to ensure that a point satisfying the Kuhn-Tucker conditions is a global max; if these assumptions do not hold, you may have to check more than one point. : Given the above conditions, to find the critical points we solve the above system of equations. To do so, we must check border and interior solutions to see if they satisfy the above conditions. In a two-dimensional set-up, this means we must check the following cases: Example: \\[\\max_{x_1,x_2} f(x) = -(x_1^2 + 2x_2^2) \\text{ s.t. } \\begin{array}{l} x_1 + x_2 \\le 4\\\\ x_1 \\ge 0\\\\ x_2 \\ge 0 \\end{array}\\] Example: \\[\\max_{x_1,x_2} f(x) = \\frac{1}{3}\\log (x_1 + 1) + \\frac{2}{3}\\log (x_2 + 1) \\text{ s.t. } \\begin{array}{l} x_1 + 2x_2 \\leq 4\\\\ x_1 \\geq 0\\\\ x_2 \\geq 0 \\end{array}\\] "],
["probability-theory.html", "Chapter 6 Probability Theory 6.1 Counting rules 6.2 Sets 6.3 Probability 6.4 Conditional Probability and Bayes Law 6.5 Random Variables 6.6 Independence 6.7 Types of Observed Data 6.8 Distributions 6.9 Expectation and Other Moments 6.10 Special Distributions 6.11 Joint Distributions 6.12 Summarizing Observed Events (Data) 6.13 Asymptotic Theory", " Chapter 6 Probability Theory Topics: Counting rules; Sets; Probability; Conditional Probability and Bayes’ Rule; Random Variables; Independence; Levels of Measurement; Distributions; Expectation and Moments; Special Distributions; Joint Distributions; Summarizing Observed Data; Asymptotics Much of the material and examples for this lecture are taken from Gill (2006) , Wackerly, Mendenhall, &amp; Scheaffer (1996) , Degroot (1985) , Morrow (1994) , King (1989) , and Ross (1987) . 6.1 Counting rules Fundamental Theorem of Counting: If an object has \\(j\\) different characteristics and each characteristic has \\(n_j\\) ways of being expressed, then there are \\(\\prod_{i = 1}^j n_j\\) possible unique objects. Example: Cards can be either red or black and can take on any of 13 values. j $= $ $n_{color} = $ $n_{number} = $ # Outcomes \\(=\\) We often need to count the number of ways to choose a from some set of possibilities. The number of outcomes depends on two characteristics of the process: does the matter and is allowed? Sampling Table: If there are \\(n\\) objects and we select \\(k &lt; n\\) of them, how many different outcomes are possible? Where \\(\\binom{x}{y} = \\frac{x!}{(x-y)!y!}\\) and \\(0! = 1\\) Example: There are five balls numbered from 1 through 5 in a jar. Three balls are chosen. How many possible choices are there? Ordered, with replacement \\(=\\) Ordered, without replacement \\(=\\) Unordered, with replacement \\(=\\) Unordered, without replacement \\(=\\) 6.2 Sets Set : A set is any well defined collection of elements. If \\(x\\) is an element of \\(S\\), \\(x \\in S\\). Sample Space (S): A set or collection of all possible outcomes from some process. Outcomes in the set can be discrete elements (countable) or points along a continuous interval (uncountable). Examples: Discrete: the numbers on a die, the number of possible wars that could occur each year, whether a vote cast is republican or democrat. Continuous: GNP, arms spending, age. Event: Any collection of possible outcomes of an experiment. Any subset of the full set of possibilities, including the full set itself. Event A \\(\\subset\\) S. Empty Set: a set with no elements. \\(S = \\{\\emptyset\\}\\) Set operations: Union: The union of two sets \\(A\\) and \\(B\\), \\(A \\cup B\\), is the set containing all of the elements in \\(A\\) or \\(B\\). \\[A_1 \\cup A_2 \\cup... A_n = \\bigcup_{i=1}^n A_i\\] Intersection: The intersection of sets \\(A\\) and \\(B\\), \\(A \\cap B\\), is the set containing all of the elements in both \\(A\\) and \\(B\\). \\[A_1 \\cap A_2 \\cap... A_n = \\bigcap_{i=1}^n A_i\\] Complement: If set \\(A\\) is a subset of \\(S\\), then the complement of \\(A\\), denoted \\(A^C\\), is the set containing all of the elements in \\(S\\) that are not in \\(A\\). Properties of set operations: Commutative: \\(A \\cup B = B \\cup A\\); \\(A \\cap B = B \\cap A\\) Associative: \\(A \\cup (B \\cup C) = (A \\cup B) \\cup C\\); \\(A \\cap (B \\cap C) = (A \\cap B) \\cap C\\) \\item \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\); \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\) de Morgan’s laws: \\((A \\cup B)^C = A^C \\cap B^C\\); \\((A \\cap B)^C = A^C \\cup B^C\\) Disjointness: Sets are disjoint when they do not intersect, such that \\(A \\cap B = \\{\\emptyset\\}\\). A collection of sets is pairwise disjoint () if, for all \\(i \\neq j\\), \\(A_i \\cap A_j = \\{\\emptyset\\}\\). A collection of sets form a partition of set \\(S\\) if they are pairwise disjoint and they cover set \\(S\\), such that \\(\\bigcup_{i = 1}^k A_i = S\\). 6.3 Probability Probability: Many events or outcomes are random. In everyday speech, we say that we are about the outcome of random events. Probability is a formal model of uncertainty which provides a measure of uncertainty governed by a particular set of rules. A different model of uncertainty would, of course, have a different set of rules and measures. Our focus on probability is justified because it has proven to be a particularly useful model of uncertainty. Probability Distribution Function (Pr(A)): a mapping of each event in the sample space \\(S\\) to the real numbers that satisfy the following three axioms (also called Kolmogorov’s Axioms). Axioms of Probability: Define \\(\\Pr(A)\\) as the probability of event \\(A\\) occurring in sample space \\(S\\), such that: For any event \\(A\\), \\(\\Pr(A)\\ge 0\\). \\(\\Pr(S)=1\\) For any sequence of (mutually exclusive) events \\(A_1,A_2,\\ldots\\) (of which there may be infinitely many), \\[\\Pr\\left( \\bigcup\\limits_{i=1}^k A_i\\right)=\\sum\\limits_{i=1}^k \\Pr(A_i)\\] Probability Operations: Using these three axioms, we can define all of the common rules of probability. \\(\\Pr(\\emptyset)=0\\) For any event \\(A\\), \\(0\\le \\Pr(A) \\le 1\\). \\(\\Pr({A}^C)=1-\\Pr(A)\\) If \\(A\\subset B\\) (\\(A\\) is a subset of \\(B\\)), then \\(\\Pr(A)\\le \\Pr(B)\\). For two events \\(A\\) and \\(B\\), \\(\\Pr(A\\cup B)=\\Pr(A)+\\Pr(B)-\\Pr(A\\cap B)\\) Boole’s Inequality: For any sequence of \\(n\\) events (which need not be disjoint) \\(A_1,A_2,\\ldots,A_n\\), then \\(\\Pr\\left( \\bigcup\\limits_{i=1}^n A_i\\right) \\leq \\sum\\limits_{i=1}^n \\Pr(A_i)\\). 6.4 Conditional Probability and Bayes Law Conditional Probability: The conditional probability \\(\\Pr(A|B)\\) of an event \\(A\\) is the probability of \\(A\\), given that another event \\(B\\) has occurred. Conditional probability allows for the inclusion of other information into the calculation of the probability of an event. It is calculated as \\[\\Pr(A|B)=\\frac{\\Pr(A\\cap B)}{\\Pr(B)}\\] Note that conditional probabilities are probabilities and must also follow the Kolmagorov axioms of probability. Multiplicative Law of Probability: The probability of the intersection of two events \\(A\\) and \\(B\\) is \\(\\Pr(A\\cap B)=\\Pr(A)\\Pr(B|A)=\\Pr(B)\\Pr(A|B)\\) which follows directly from the definition of conditional probability. More generally,\\ \\(P(A_1\\cap ...\\cap A_k) = P(A_k| A_{k-1}\\cap... \\cap A_1)\\times P(A_{k-1}|A_{k-2}\\cap ...A_1)...\\times P(A_2|A_1)\\times P(A_1)\\) Law of Total Probability: Let \\(S\\) be the sample space of some experiment and let the disjoint \\(k\\) events \\(B_1,\\ldots,B_k\\) partition \\(S\\), such that \\(P(B_1\\cup ... \\cup B_k) = P(S) = 1\\). If \\(A\\) is some other event in \\(S\\), then the events \\(A\\cap B_1, A\\cap B_2, \\ldots, A\\cap B_k\\) will form a partition of \\(A\\) and we can write \\(A\\) as \\(A=(A\\cap B_1)\\cup\\cdots\\cup (A\\cap B_k)\\). Since the \\(k\\) events are disjoint, \\[\\begin{eqnarray*} \\Pr(A)&amp;=&amp;\\sum\\limits_{i=1}^k \\Pr(A \\cap B_i)\\\\ &amp;=&amp;\\sum\\limits_{i=1}^k \\Pr(B_i)\\Pr(A|B_i) \\end{eqnarray*}\\] Sometimes it is easier to calculate these conditional probabilities and sum them than it is to calculate \\(\\Pr(A)\\) directly. Bayes Rule: Assume that events \\(B_1,\\ldots,B_k\\) form a partition of the space \\(S\\). Then by the Law of Total Probability \\[\\Pr(B_j|A)= \\frac{\\Pr(A \\cap B_j)} {\\Pr(A)} = \\frac{\\Pr(B_j) \\Pr(A|B_j)}{\\sum\\limits_{i=1}^k \\Pr(B_i)\\Pr(A|B_i)}\\] If there are only two states of \\(B\\), then this is just \\[\\Pr(B_1|A)=\\frac{\\Pr(B_1)\\Pr(A|B_1)} {\\Pr(B_1)\\Pr(A|B_1)+\\Pr(B_2)\\Pr(A|B_2)}\\] Bayes’ rule determines the posterior probability of a state \\(\\Pr(B_j|A)\\) by calculating the probability \\(\\Pr(A \\cap B_j)\\) that both the event \\(A\\) and the state \\(B_j\\) will occur and dividing it by the probability that the event will occur regardless of the state (by summing across all \\(B_i\\)). The states could be something like Normal/Defective, Healthy/Diseased, Republican/Democrat/Independent, etc. The event on which one conditions could be something like a sampling from a batch of components, a test for a disease, or a question about a policy position. Prior and Posterior Probabilities: Above, \\(\\Pr(B_1)\\) is often called the prior probability, since it’s the probability of \\(B_1\\) before anything else is known. \\(\\Pr(B_1|A)\\) is called the posterior probability, since it’s the probability after other information is taken into account. 6.5 Random Variables Most questions in the social sciences involve events, rather than numbers per se. To analyze and reason about events quantiatively, we need a way of mapping events to numbers. A random variable does exactly that. A is a measurable function \\(X\\) that maps from the sample space \\(S\\) to the set of real numbers \\(R.\\) It assigns a real number to every outcome \\(s \\in S\\). It might seem strange to define a random variable as a function – which is neither random nor variable. The randomness comes from the realization of an event from the sample space \\(s\\). means that the outcome of some experiment is not deterministic, i.e. there is some probability (\\(0 &lt; P(A) &lt; 1\\)) that the event will occur. The of a random variable is all values for which there is a positive probability of occurrence. 6.6 Independence Independence: If the occurrence or nonoccurrence of either events \\(A\\) and \\(B\\) have no effect on the occurrence or nonoccurrence of the other, then \\(A\\) and \\(B\\) are independent. If \\(A\\) and \\(B\\) are independent, then \\(\\Pr(A|B)=\\Pr(A)\\) \\(\\Pr(B|A)=\\Pr(B)\\) \\(\\Pr(A\\cap B)=\\Pr(A)\\Pr(B)\\) More generally than the above, \\(\\Pr(\\bigcap_{i=1}^k A_i) = \\prod_{i = 1}^K \\Pr(A_i)\\) Are mutually exclusive events independent of each other? No. If A and B are mutually exclusive, then they cannot happen simultaneously. If we know that A occurred, then we know that B couldn’t have occurred. Because of this, A and B aren’t independent. : A set of more than two events \\(A_1, A_2, \\dots, A_k\\) is pairwise independent if \\(\\Pr(A_i\\cap A_j)=\\Pr(A_i)\\Pr(A_j)\\), \\(\\forall i\\neq j\\). Note that this does necessarily imply independence. : If \\(A\\) and \\(B\\) are independent once you know the occurrence of a third event \\(C\\), then \\(A\\) and \\(B\\) are conditionally independent (conditional on \\(C\\)): \\(\\Pr(A|B \\cap C)=\\Pr(A|C)\\) \\(\\Pr(B|A \\cap C)=\\Pr(B|C)\\) \\(\\Pr(A\\cap B|C)=\\Pr(A|C)\\Pr(B|C)\\) 6.7 Types of Observed Data In empirical research, data can be classified along several dimensions. We can look at the precision with which the underlying quantities are measured. (Categorical): data are nominal if there is no way to put the categories represented by the data into a meaningful order. Typically, this kind of data represents names (hence `nominal’) or attributes. Example: Republican or Democrat, Male or Female. : data are ordinal if there is a logical order to the categories represented by the data, but there is no common scale for differences between adjacent categories. Example: Party identification, common survey responses. : data are interval if there is an order to the values and there is a common scale, so that differences between two values have substantive meanings. Example: dates, temperature. : Discrete or continuous data are ratio if the data have the characteristics of interval data and zero is a meaningful quantity. This allows us to consider the ratio of two values as well as difference between them. Allows direct ratio comparison because of the meaningful baseline of 0. Example: quantities measured in dollars, crime rates. 6.8 Distributions The distribution of a random variable \\(X\\) is the probability function it induces on the real line. It is given, roughly speaking, by \\(p(s) = P(X \\in s)\\) The formal definition of a random variable is easier to given by separating out two cases: discrete random variables when the numeric summaries of the events are discrete, and continuous random variables whern they are continuous. Discrete Random Variable: \\(Y\\) is a discrete random variable if it can assume only a finite or countably infinite number of distinct values. Examples: number of wars per year, heads or tails. Probability Mass Function (p(y)): For a discrete random variable \\(Y\\), the probability mass function (Also referred to simply as the “probability distribution.”) (pmf), \\(p(y)=\\Pr(Y=y)\\), assigns probabilities to a countable number of distinct \\(y\\) values such that \\(0\\le p(y)\\le 1\\) \\(\\sum\\limits_y p(y)=1\\) Cumulative Density Function: The cumulative density function (Also referred to simply as the “cumulative distribution.”), \\(F(y)\\) or \\(\\Pr(Y\\le y)\\), is the probability that \\(Y\\) is less than or equal to some value \\(y\\), or \\[\\Pr(Y\\le y)=\\sum\\limits_{i\\le y} p(i)\\] \\(F(y)\\) is non-decreasing in \\(y\\). \\(\\lim\\limits_{y \\to -\\infty} F(y) = 0\\) and \\(\\lim\\limits_{y \\to \\infty} F(y) = 1\\) \\(F(y)\\) is right-continuous. Note that \\(P(Y &gt; y) = 1 - P(Y \\le y)\\). We also have a similar definition for random variables. Continuous Random Variable: \\(Y\\) is a continuous random variable if there exists a nonnegative function \\(f(y)\\) defined for all real \\(y\\in (-\\infty,\\infty)\\), such that for any interval \\(A\\), \\(\\Pr(Y\\in A)=\\int\\limits_A f(y)dy\\). Examples: age, income, GNP, temperature. Probability Density Function: The function \\(f\\) above is called the probability density function (pdf) of \\(Y\\) and must satisfy Note also that \\(\\Pr(Y=y)=0\\) — i.e., the probability of any point \\(y\\) is zero. For both discrete and continous random variables, we have a unifying concept of another measure: the cumulative distribution: Cumulative Density Function: Because the probability that a continuous random variable will assume any particular value is zero, we can only make statements about the probability of a continuous random variable being within an interval. The cumulative distribution gives the probability that \\(Y\\) lies on the interval \\((-\\infty,y)\\) and is defined as \\[F(y)=\\Pr(Y\\le y)=\\int\\limits_{-\\infty}^y f(s)ds\\] Note that \\(F(y)\\) has similar properties with continuous distributions as it does with discrete - non-decreasing, continuous (not just right-continuous), and \\(\\lim\\limits_{y \\to -\\infty} F(y) = 0\\) and \\(\\lim\\limits_{y \\to \\infty} F(y) = 1\\).\\ We can also make statements about the probability of \\(Y\\) falling in an interval \\(a\\le y\\le b\\). \\[\\Pr(a\\le y\\le b)=\\int\\limits_a^b f(y)dy\\] \\[f(y) = F&#39;(y)=\\frac{dF(y)}{dy}\\] 6.9 Expectation and Other Moments We often want to summarize some characteristics of the distribution of a random variable. The most important summary is the expectation (or expected value, or mean), in which the possible values of a random variable are weighted by their probabilities. Expectation of a Discrete Random Variable: The expected value of a discrete random variable \\(Y\\) is \\[E(Y)=\\sum\\limits_{y} y P(Y=y)= \\sum\\limits_{y} y p(y)\\] In words, it is the weighted average of all possible values of \\(Y\\), weighted by the probability that \\(y\\) occurs. It is not necessarily the number we would expect \\(Y\\) to take on, but the average value of \\(Y\\) after a large number of repetitions of an experiment. Expectation of a Continuous Random Variable: The expected value of a continuous random variable is similar in concept to that of the discrete random variable, except that instead of summing using probabilities as weights, we integrate using the density to weight. Hence, the expected value of the continuous variable \\(Y\\) is defined by \\[E(Y)=\\int\\limits_{y} y f(y) dy\\] Expected Value of a Function : Conditional Expectation: With joint distributions, we are often interested in the expected value of a variable \\(Y\\) if we could hold the other variable \\(X\\) fixed. This is the conditional expectation of \\(Y\\) given \\(X = x\\): The conditional expectation is often used for prediction when one knows the value of \\(X\\) but not \\(Y\\); the realized value of \\(X\\) contains information about the unknown \\(Y\\) so long as \\(E(Y|X = x) \\neq E(Y) \\forall x\\). Variance: We can also look at other summaries of the distribution, which build on the idea of taking expectations. Variance tells us about the ``spread&quot; of the distribution; it is the expected value of the squared deviations from the mean of the distribution. The standard deviation is simply the square root of the variance. : The covariance measures the degree to which two random variables vary together; if the covariance is positive, X tends to be larger than its mean when Y is larger than its mean. The covariance of a variable with itself is the variance of that variable. \\[\\Cov(X,Y) = E[(X - E(X))(Y - E(Y))] = E(XY) - E(X)E(Y)\\] The correlation coefficient is the covariance divided by the standard deviations of X and Y. It is a unitless measure and always takes on values in the interval \\([-1,1]\\). \\[\\rho = \\frac{\\Cov(X,Y)}{\\sqrt{\\Var(X)\\Var(Y)}} = \\frac{\\Cov(X,Y)}{\\SD(X)\\SD(Y)}\\] : \\end{itemize} 6.10 Special Distributions Two discrete distributions used often are: Binomial Distribution: \\(Y\\) is distributed binomial if it represents the number of successes&quot; observed in $n$ independent, identicaltrials,&quot; where the probability of success in any trial is \\(p\\) and the probability of failure is \\(q=1-p\\).\\[6pt] For any particular sequence of \\(y\\) successes and \\(n-y\\) failures, the probability of obtaining that sequence is \\(p^y q^{n-y}\\) (by the multiplicative law and independence). However, there are \\(\\binom{n}{y}=\\frac{n!}{(n-y)!y!}\\) ways of obtaining a sequence with \\(y\\) successes and \\(n-y\\) failures. So the binomial distribution is given by \\[p(y)=\\binom{n}{y}p^y q^{n-y}, \\quad y=0,1,2,\\ldots,n\\] with mean \\(\\mu=E(Y)=np\\) and variance \\(\\sigma^2=V(Y)=npq\\). Poisson Distribution: A random variable \\(Y\\) has a Poisson distribution if \\[p(y)=\\frac{\\lambda^y}{y!}e^{-\\lambda}, \\quad y=0,1,2,\\ldots, \\quad \\lambda&gt;0\\] The Poisson has the unusual feature that its expectation equals its variance: \\(E(Y)=V(Y)=\\lambda\\). The Poisson distribution is often used to model rare event counts: counts of the number of events that occur during some unit of time. \\(\\lambda\\) is often called the “arrival rate.” Two distributions used often are: Uniform Distribution: A random variable \\(Y\\) has a continuous uniform distribution on the interval \\((\\alpha,\\beta)\\) if its density is given by \\[f(y)=\\frac{1}{\\beta-\\alpha}, \\quad \\alpha\\le y\\le \\beta\\] The mean and variance of \\(Y\\) are \\(E(Y)=\\frac{\\alpha+\\beta}{2}\\) and \\(V(Y)=\\frac{(\\beta-\\alpha)^2}{12}\\). : A random variable \\(Y\\) is normally distributed with mean \\(E(Y)=\\mu\\) and variance \\(V(Y)=\\sigma^2\\) if its density is \\[f(y)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y-\\mu)^2}{2\\sigma^2}}\\] 6.11 Joint Distributions Often, we are interested in two or more random variables defined on the same sample space. The distribution of these variables is called a joint distribution. Joint distributions can be made up of any combination of discrete and continuous random variables. Joint Probability Distribution: If both \\(X\\) and \\(Y\\) are random variable, their joint probability mass/density function assigns probabilities to each pair of outcomes Discrete: \\[p(x, y) = \\Pr(X = x, Y = y)\\] such that \\(p(x,y) \\in [0,1]\\) and \\[\\sum\\sum p(x,y) = 1\\] Continuous: \\[f(x,y);\\Pr((X,Y) \\in A) = \\int\\!\\!\\!\\int_A f(x,y)dx dy \\] s.t. \\(f(x,y)\\ge 0\\) and \\[\\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty f(x,y)dxdy = 1\\] If X and Y are independent, then \\(P(X=x,Y=y) = P(X=x)P(Y=y)\\) and \\(f(x,y) = f(x)f(y)\\) Marginal Probability Distribution: probability distribution of only one of the two variables (ignoring information about the other variable), we can obtain the marginal distribution by summing/integrating across the variable that we don’t care about: Discrete: \\(p_X(x) = \\sum_i p(x, y_i)\\) Continuous: \\(f_X(x) = \\int_{-\\infty}^\\infty f(x,y)dy\\) Conditional Probability Distribution: probability distribution for one variable, holding the other variable fixed. Recalling from the previous lecture that \\(\\Pr(A|B)=\\frac{\\Pr(A\\cap B)}{\\Pr(B)}\\), we can write the conditional distribution as Discrete: \\(p_{Y|X}(y|x) = \\frac{p(x,y)}{p_X(x)}, \\quad p_X(x) &gt; 0\\) Continuous: \\(f_{Y|X}(y|x) = \\frac{f(x,y)}{f_X(x)},\\quad f_X(x) &gt; 0\\) 6.12 Summarizing Observed Events (Data) So far, we’ve talked about distributions in a theoretical sense, looking at different properties of random variables. We don’t observe random variables; we observe realizations of the random variable. These realizations of events are roughly equivalent to what we mean by “data”. Central tendency: The central tendency describes the location of the “middle” of the observed data along some scale. There are several measures of central tendency. Sample mean: This is the most common measure of central tendency, calculated by summing across the observations and dividing by the number of observations. \\[\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_i\\] The sample mean is an of the expected value of a distribution. Sample median: The median is the value of the ``middle’’ observation. It is obtained by ordering \\(n\\) data points from smallest to largest and taking the value of the \\(n+1/2\\)th observation (if \\(n\\) is odd) or the mean of the \\(n/2\\)th and \\((n+1)/2\\)th observations (if \\(n\\) is even). Sample mode: The mode is the most frequently observed value in the data: \\[m_x = X_i : n(X_i) &gt; n(X_j) \\forall j\\neq i\\] When the data are realizations of a continuous random variable, it often makes sense to group the data into bins, either by rounding or some other process, in order to get a reasonable estimate of the mode. Dispersion: We also typically want to know how spread out the data are relative to the center of the observed distribution. There are several ways to measure dispersion. Sample variance: The sample variance is the sum of the squared deviations from the sample mean, divided by the number of observations minus 1. \\[ \\Var(X) = \\frac{1}{n-1}\\sum_{i = 1}^n (x_i - \\bar{x})^2\\] Again, this is an of the variance of a random variable; we divide by \\(n - 1\\) instead of \\(n\\) in order to get an unbiased estimate. Standard deviation: The sample standard deviation is the square root of the sample variance. \\[ \\SD(X) = \\sqrt{\\Var(X)} = \\sqrt{\\frac{1}{n-1}\\sum_{i = 1}^n (x_i - \\bar{x})^2}\\] Median absolute deviation (MAD): The MAD is a different measure of dispersion, based on deviations from the median rather than deviations from the mean. \\[\\mathrm{MAD}(X) = \\mathrm{median}\\left(|x_i - \\mathrm{median}(x)|\\right)\\] Covariance and Correlation: Both of these quantities measure the degree to which two variables vary together, and are estimates of the covariance and correlation of two random variables as defined above. : \\(\\Cov(X,Y) = \\frac{1}{n-1}\\sum_{i = 1}^n(x_i - \\bar{x})(y_i - \\bar{y})\\) : \\(\\rho = \\frac{\\Cov(X,Y)}{\\sqrt{\\Var(X)\\Var(Y)}}\\) 6.13 Asymptotic Theory In theoretical and applied research, asymptotic arguments are often made. In this section we briefly introduce some of this material. What are asymptotics? In probability theory, asymptotic analysis is the study of limiting behavior. By limiting behavior, we mean the behavior of some random process as the number of observations gets larger and larger. Why is this important? We rarely know the true process governing the events we see in the social world. It is helpful to understand how such unknown processes theoretically must behave and asymptotic theory helps us do this. Examples. Central Limit Theorem. Let \\(\\{X_n\\} = \\{X_1, X_2, ..., X_n\\}\\) be a sequence of i.i.d. random variables with finite mean (\\(\\mu\\)) and variance (\\(\\sigma^2\\)). Then, \\[\\begin{align*} \\bar{X}_n = \\frac{x_1 + x_2 + ... + x_n}{n} \\to \\mathcal{N}\\bigg(\\mu, \\frac{\\sigma^2}{n}\\bigg) \\end{align*}\\] as \\(n\\to \\infty\\). This result, known as the Central Limit Theorem, is an important motivation for many quantitative methods, as well as for the widespread use of the Normal distribution. Intuitively, whenever a lot of small, independent processes somehow combine together to form the realized observations, practitioners often feel comfortable assuming Normality. Law of Large Numbers. Let \\(\\{X_n\\} = \\{X_1, X_2, ..., X_n\\}\\) be a sequence of i.i.d. random variables with a finite expected value of \\(\\mu\\). Then, \\[\\begin{align*} \\bar{X}_n = \\frac{x_1 + x_2 + ... + x_n}{n} \\stackrel{\\textrm{a.s.}}{\\to} \\mu \\end{align*}\\] as \\(n\\to \\infty\\). In other words, \\(\\Pr( \\lim_{n\\to\\infty}\\bar{X}_n = \\mu) = 1\\). This theorem, known as the Strong Law of Large Numbers, is an important motivation for the widespread use of the sample mean, as well as the intuition link between averages and expected values. Important note: The Strong Law of Large Numbers holds so long as the expected value exists; no other assumptions are needed. However, the rate of convergence will differ greatly depending on the distribution underlying the observed data. When extreme observations occur often (i.e. kurtosis is large), the rate of convergence is much slower. Cf. The distribution of financial returns. Big \\(\\mathcal{O}\\) Notation. Some of you may encounter “big-OH’’-notation. If \\(f, g\\) are two functions, we say that \\(f = \\mathcal{O}(g)\\) if there exists some constant, \\(c\\), such that \\(f(n) \\leq c \\times g(n)\\) for large enough \\(n\\). This notation is useful for simplifying complex problems in game theory, computer science, and statistics. Example. What is \\(\\mathcal{O}( 5\\exp(0.5 n) + n^2 + n / 2)\\)? Answer: \\(\\exp(n)\\). Why? Because, for large \\(n\\), \\[ \\frac{ 5\\exp(0.5 n) + n^2 + n / 2 }{ \\exp(n)} \\leq \\frac{ c \\exp(n) }{ \\exp(n)} = c. \\] whenever \\(n &gt; 4\\) and where \\(c = 1\\). "],
["counting-and-visualization.html", "Chapter 7 Counting and Visualization 7.1 Where are we? Where are we headed? 7.2 Check your understanding 7.3 Motivation 7.4 Read data 7.5 Counting 7.6 Tabulating 7.7 Visualization 7.8 What is an object? 7.9 Making your own objects 7.10 Types of variables 7.11 What is a function? 7.12 What is a package? 7.13 Review Exercises 7.14 Tell us about this session.", " Chapter 7 Counting and Visualization Module originally written by Shiro Kuriwaki 7.1 Where are we? Where are we headed? Up till now, you should have covered: The tutorial assignment at http://tryr.codeschool.com/ Today we’ll cover: Counting. Visualization. Data Wrangling Objects and Classes. Function and Packages 7.2 Check your understanding What does : mean in R? What about ==? ,?, != , &amp;, |, %in% What does %&gt;% do What is the difference between the console and script? What happens if you “clear” the Console? What happens if you “clear” the script? Your “environment” How do you read in a spreadsheet (csv) into R? How do you count the number of observations for a given category? How do you make a barplot, in base-R and in ggplot? What is the difference between a data frame and a matrix? What are three ways to extract a single variable from a data frame? How would you identify a class or type of an object? How do you define a new function? 7.3 Motivation In this module, let’s jump into using the basic functions of R from an actual Census. Why care about the Census? The Census is one of the fundamental acts of a government. See the Law Review article by Persily (2011), “The Law of the Census”1. The Census is government’s primary tool for apportionment (allocating seats to districts), appropriations (allocating federal funding), and tracking demographic change. See2 for example Hochschild and Powell (2008) on how the categorizations of race in the Census during 1850-1930. library(dplyr) library(readr) library(scales) library(forcats) library(ggplot2) 7.4 Read data The first of line code you will write is often to read in data. Here, let’s read in a subset of the 2010 Census. This is a 0.01 percent random sample of the entire U.S. Census. cen10 &lt;- read_csv(&quot;input/usc2010_001percent.csv&quot;, col_types = cols()) The data comes from IPUMS3, a great source to extract and analyze Census and Census-conducted survey (ACS, CPS) data. What does this data look like? cen10 ## # A tibble: 30,871 x 13 ## year serial pernum region state countyfips city cpuma0010 sex age ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 2010 8.80e6 4 Middl… New … 0 Not … 636 Fema… 8 ## 2 2010 9.80e6 1 East … Ohio 103 Not … 802 Male 24 ## 3 2010 8.69e6 1 Mount… Neva… 3 Not … 582 Male 37 ## 4 2010 6.35e6 3 East … Mich… 0 Not … 476 Fema… 12 ## 5 2010 6.15e6 2 South… Mary… 33 Not … 449 Fema… 18 ## 6 2010 8.10e6 1 New E… New … 0 Not … 586 Male 50 ## 7 2010 4.06e6 1 West … Iowa 0 Not … 362 Fema… 51 ## 8 2010 7.03e6 2 West … Miss… 0 Not … 550 Fema… 41 ## 9 2010 8.16e6 2 Middl… New … 3 Not … 592 Male 62 ## 10 2010 1.12e6 3 Pacif… Cali… 37 Los … 81 Male 25 ## # ... with 30,861 more rows, and 3 more variables: race &lt;chr&gt;, ## # hhtype &lt;chr&gt;, relate &lt;chr&gt; 7.5 Counting How many people are in your sample. Three ways to count: nrow(cen10) ## [1] 30871 dim(cen10) ## [1] 30871 13 length(cen10$year) ## [1] 30871 Multiply this number by the inverse of the sample proportion. Does it equal the total population of the U.S. in 20104? nrow(cen10)*100*100 ## [1] 308710000 This and all subsequent tasks involve manipulating and summarizing data, sometimes called “wrangling”. There are at least two approaches, “base-R” and “tidyverse functions”. The tidyverse functions are add-ons that programmers have built, and appears to be popular. 7.6 Tabulating Here are two ways to count by group, or to tabulate. Use the table function table(cen10$race) ## ## American Indian or Alaska Native Black/Negro ## 295 4013 ## Chinese Japanese ## 354 77 ## Other Asian or Pacific Islander Other race, nec ## 1129 1839 ## Three or more major races Two major races ## 88 869 ## White ## 22207 With tidyverse, use group_by to group by a variable, and then summarize to count. cen10 %&gt;% group_by(race) %&gt;% summarize(count = n()) ## # A tibble: 9 x 2 ## race count ## &lt;chr&gt; &lt;int&gt; ## 1 American Indian or Alaska Native 295 ## 2 Black/Negro 4013 ## 3 Chinese 354 ## 4 Japanese 77 ## 5 Other Asian or Pacific Islander 1129 ## 6 Other race, nec 1839 ## 7 Three or more major races 88 ## 8 Two major races 869 ## 9 White 22207 These tidyverse commands from the dplyr package are newer and not built-in, but they are one of the increasingly more popular ways to wrangle data. 80 percent of your data wrangling needs might be doable with these basic dplyr functions: select, mutate, group_by, summarize, and arrange. These verbs roughly correspond to the same commands in SQL, another important language in data science. The %&gt;% symbol is a pipe. It takes the thing on the left side and pipes it down to the function on the right side. cen10 %&gt;% group_by(race) means take cen10 and pass it on to the function group_by, which will group observations by race. Passing that (%&gt;%) to summarize(count = n()) means to then summarize the grouped output by the variable count, which we define by the number of rows n(). 7.7 Visualization Visualizing data is the key part of communication; good data viz gets the point across5. Two prevalent ways of making graphing are referred to as “base-R” and “ggplot”. 7.7.1 base R “Base-R” graphics are graphics that are made with R’s default graphics commands. First, let’s assign our tabulation to an object, call it tab_race tab_race &lt;- table(cen10$race) Then put it in the barplot() function barplot(tab_race) 7.7.2 ggplot A popular alternative a ggplot graphics. gg stands for grammar of graphics by Hadley Wickham, and it has a new semantics of explaining graphics in R. Again, first let’s set up the data. Let’s group and count first, like we just did. grp_race &lt;- group_by(cen10, race) %&gt;% summarize(count = n()) We will now plot this grouped set of numbers. The ggplot() function takes two main arguments, data and aes. First enter a single dataframe from which you will draw a plot. Then enter the aes, or aesthetics. This defines which variable in the data the plotting functions should take for pre-set dimensions in graphics. The dimenions x and y are the most important. We will assign race and count to them, respectively, After you close ggplot() .. add layers by the plus sign. A geom is a layer of graphical representation, for example geom_histogram renders a histogram, geom_point renders a scatter plot. For a barplot, we can use geom_col() ggplot(data = grp_race, aes(x = race, y = count)) + geom_col() 7.7.3 Improving your graphics Adjusting your graphics to make the point clear is an important skill. Here is an example of showing the same numbers but with a different design, in a way that aims to maximize the data-to-ink ratio6 par(oma = c(1, 10, 1, 1)) barplot(sort(tab_race), # sort numbers horiz = TRUE, # flip border = NA, # border is extraneous xlab = &quot;Number in Race Category&quot;, bty = &quot;n&quot;, # no box las = 1) # alignment of axis labels is horizontal Notice that we applied the sort() function to order the bars in terms of their counts. The default ordering of a categorical variable / factor is alphabetical. Alphabetical ordering is uninformative and almost never the way you should order variables. In ggplot you might do this by: grp_race_ordered &lt;- arrange(grp_race, count) %&gt;% mutate(race = forcats::as_factor(race)) ggplot(data = grp_race_ordered, aes(x = race, y = count)) + geom_col() + coord_flip() + labs(y = &quot;Number in Race Category&quot;, x = &quot;&quot;, caption = &quot;Source: 2010 U.S. Census sample&quot;) 7.7.4 Cross-tabs A cross-tab is counting with two types of variables, and is a simple and powerful tool to show the relationship between multiple variables. xtab_race_state &lt;- table(cen10$race, cen10$state) dim(xtab_race_state) ## [1] 9 51 The barplot function kindly takes cross-tabs and figures out how to plot them: par(oma = c(2,2,2,2)) barplot(xtab_race_state) What if we care about proportions within states, rather than counts. We want to compare the racial composition of a small state (like Delaware) and a large state (like California). One way to transform a table of counts to a table of proportions is the function prop.table. Be careful what you want to take proportions of – this is set by the margin argument. In R, the first margin (1) is rows and the second margin (2) is columns. ptab_race_state &lt;- prop.table(xtab_race_state, margin = 2) dim(ptab_race_state) ## [1] 9 51 Now we can plot these numbers. Let’s orient them horizontally: barplot(ptab_race_state, horiz = TRUE, las = 1) To make the same figure with ggplot(). First, we want a count for each state \\(\\times\\) race combination. So group by those two factors and count how many observations are in each two-way categorization. grp_race_state &lt;- cen10 %&gt;% group_by(race, state) %&gt;% summarize(count = n()) Can you tell from the code what grp_race_state will look like? # run on your own grp_race_state Now, we want to tell ggplot2 something like the following: I want bars by state, where heights indicate racial groups. Each bar should be colored by the race. With some googling, you will get something like this ggplot(data = grp_race_state, aes(x = state, y = count, fill = race)) + geom_col(position = &quot;fill&quot;) + # the position is dertemined by the fill ae scale_fill_brewer(palette = &quot;OrRd&quot;, direction = -1) + # choose palette coord_flip() + # flip axes scale_y_continuous(labels = percent) + # label numbers as percentage labs(y = &quot;Proportion of Racial Group within State&quot;, x = &quot;&quot;, source = &quot;Source: 2010 Census sample&quot;) 7.7.5 Histograms When our data is continuous rather than categorical, our first graphics will probably be a histogram. hist(cen10$age, main = &quot;Age Distribution&quot;, xlab = &quot;Age&quot;) ggplot(data = cen10, aes(x = age)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 7.8 What is an object? Now that we have covered some hands-on ways to use graphics, let’s go into some fundamentals of the R language. Objects are abstract symbols in which you store data. Here we will create an object from copy, and assign cen10 to it. copy &lt;- cen10 This looks the same as the original dataset: copy ## # A tibble: 30,871 x 13 ## year serial pernum region state countyfips city cpuma0010 sex age ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 2010 8.80e6 4 Middl… New … 0 Not … 636 Fema… 8 ## 2 2010 9.80e6 1 East … Ohio 103 Not … 802 Male 24 ## 3 2010 8.69e6 1 Mount… Neva… 3 Not … 582 Male 37 ## 4 2010 6.35e6 3 East … Mich… 0 Not … 476 Fema… 12 ## 5 2010 6.15e6 2 South… Mary… 33 Not … 449 Fema… 18 ## 6 2010 8.10e6 1 New E… New … 0 Not … 586 Male 50 ## 7 2010 4.06e6 1 West … Iowa 0 Not … 362 Fema… 51 ## 8 2010 7.03e6 2 West … Miss… 0 Not … 550 Fema… 41 ## 9 2010 8.16e6 2 Middl… New … 3 Not … 592 Male 62 ## 10 2010 1.12e6 3 Pacif… Cali… 37 Los … 81 Male 25 ## # ... with 30,861 more rows, and 3 more variables: race &lt;chr&gt;, ## # hhtype &lt;chr&gt;, relate &lt;chr&gt; What happens if you do this next? copy &lt;- &quot;&quot; It got reassigned: copy ## [1] &quot;&quot; 7.8.1 lists Lists are one of the most generic and flexible type of object. You can make an empty list by the function list() my_list &lt;- list() my_list ## list() And start filling it in. Slots on the list are invoked by double square brackets [[]] my_list[[1]] &lt;- &quot;contents of the first slot -- this is a string&quot; my_list[[&quot;slot 2&quot;]] &lt;- &quot;contents of slot named slot 2&quot; my_list ## [[1]] ## [1] &quot;contents of the first slot -- this is a string&quot; ## ## $`slot 2` ## [1] &quot;contents of slot named slot 2&quot; each slot can be anything. What are we doing here? We are defining the 1st slot of the list my_list to be a vector c(1, 2, 3, 4, 5) my_list[[1]] &lt;- c(1, 2, 3, 4, 5) You can even make nested lists. Let’s say we want the 1st slot of the list to be another list of three elements. my_list[[1]][[1]] &lt;- &quot;subitem 1 in slot 1 of my_list&quot; my_list[[1]][[2]] &lt;- &quot;subitem 1 in slot 2 of my_list&quot; my_list[[1]][[3]] &lt;- &quot;subitem 1 in slot 3 of my_list&quot; my_list ## [[1]] ## [1] &quot;subitem 1 in slot 1 of my_list&quot; &quot;subitem 1 in slot 2 of my_list&quot; ## [3] &quot;subitem 1 in slot 3 of my_list&quot; &quot;4&quot; ## [5] &quot;5&quot; ## ## $`slot 2` ## [1] &quot;contents of slot named slot 2&quot; 7.9 Making your own objects We’ve covered one type of object, which is a list. You saw it was quite flexible. How many types of objects are there? There are an infinite number of objects, because people make their own class of object. You can detect the type of the object (the class) by the function class What is type of object is cen10? class(cen10) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; What about this text? class(&quot;some random text&quot;) ## [1] &quot;character&quot; To change or create the class of any object, you can assign it. To do this, assign the name of your class to character to an object’s class(). We can start from a simple list. For example, say we wanted to store data about pokemon. Because there is no pre-made package for this, we decide to make our own class. pikachu &lt;- list(name = &quot;Pikachu&quot;, number = 25, type = &quot;Electric&quot;, color = &quot;Yellow&quot;) and we can give it any class name we want. class(pikachu) &lt;- &quot;Pokemon&quot; 7.9.1 Seeing R through objects Most of the R objects that you will see as you advance are their own objects. For example, here’s a linear regression object (which you will learn more about in Gov 2000): ols &lt;- lm(mpg ~ wt + vs + gear + carb, mtcars) class(ols) ## [1] &quot;lm&quot; Anything can be an object! Even graphs (in ggplot) can be assigned, re-assigned, and edited. gg_tab &lt;- ggplot(data = grp_race_ordered) + aes(x = race, y = count) + geom_col() + labs(caption = &quot;Source: U.S. Census 2010&quot;) gg_tab You can change the orientation gg_tab + coord_flip() Or even change the variables altogether, while still maintaining the same format. 7.9.2 Parsing an object by str()s It can be hard to understand an R object because it’s contents are unknown. The function str, short for structure, is a quick way to look into the innards of an object str(my_list) ## List of 2 ## $ : chr [1:5] &quot;subitem 1 in slot 1 of my_list&quot; &quot;subitem 1 in slot 2 of my_list&quot; &quot;subitem 1 in slot 3 of my_list&quot; &quot;4&quot; ... ## $ slot 2: chr &quot;contents of slot named slot 2&quot; Same for the object we just made str(pikachu) ## List of 4 ## $ name : chr &quot;Pikachu&quot; ## $ number: num 25 ## $ type : chr &quot;Electric&quot; ## $ color : chr &quot;Yellow&quot; ## - attr(*, &quot;class&quot;)= chr &quot;Pokemon&quot; What does a ggplot object look like? Very complicated, but at least you can see it: # enter this on your console str(gg_tab) 7.10 Types of variables In the social science we often analyze variables. As you saw in the tutorial, different types of variables require different care. A key link with what we just learned is that variables are also types of R objects. 7.10.1 scalars One number. How many people did we count in our Census sample? nrow(cen10) ## [1] 30871 Question: What proportion of our census sample is Native American? This number is also a scalar # Enter yourself Hint: you can use the function mean() to calcualte the sample mean. The sample proportion is the mean of a sequence of number, where your event of interest is a 1 (or TRUE) and others are 0 (or FALSE). 7.10.2 numeric vectors A sequence of numbers. grp_race_ordered$count ## [1] 77 88 295 354 869 1129 1839 4013 22207 Or even, all the ages of the millions of people in our Census. Here are just the first few numbers of the list. head(cen10$age) ## [1] 8 24 37 12 18 50 7.10.3 characters (aka strings) This can be just one stretch of characters my_name &lt;- &quot;Shiro&quot; my_name ## [1] &quot;Shiro&quot; or more characters. Notice here that there’s a difference between a vector of individual characters and a length-one object of characters. my_name_letters &lt;- c(&quot;S&quot;, &quot;h&quot;, &quot;i&quot;, &quot;r&quot;, &quot;o&quot;) my_name_letters ## [1] &quot;S&quot; &quot;h&quot; &quot;i&quot; &quot;r&quot; &quot;o&quot; Finally, remember that lower vs. upper case matters in R! my_name2 &lt;- &quot;shiro&quot; my_name == my_name2 ## [1] FALSE 7.10.4 matricies Matrices are rectangular structures of numbers (they have to be numbers, and they can’t be characters). A cross-tab can be considered a matrix: table(cen10$race, cen10$sex) ## ## Female Male ## American Indian or Alaska Native 142 153 ## Black/Negro 2070 1943 ## Chinese 192 162 ## Japanese 51 26 ## Other Asian or Pacific Islander 587 542 ## Other race, nec 877 962 ## Three or more major races 37 51 ## Two major races 443 426 ## White 11252 10955 But a subset of your data – individual values– can be considered a matrix too. cen10[1:20, c(&quot;year&quot;, &quot;age&quot;)] ## # A tibble: 20 x 2 ## year age ## &lt;int&gt; &lt;int&gt; ## 1 2010 8 ## 2 2010 24 ## 3 2010 37 ## 4 2010 12 ## 5 2010 18 ## 6 2010 50 ## 7 2010 51 ## 8 2010 41 ## 9 2010 62 ## 10 2010 25 ## 11 2010 23 ## 12 2010 66 ## 13 2010 57 ## 14 2010 73 ## 15 2010 43 ## 16 2010 29 ## 17 2010 8 ## 18 2010 78 ## 19 2010 10 ## 20 2010 9 A vector is a special type of matrix with only one column or only one row (more on this in tomorrow’s linear algebra session). cen10[1:10, c(&quot;age&quot;)] ## # A tibble: 10 x 1 ## age ## &lt;int&gt; ## 1 8 ## 2 24 ## 3 37 ## 4 12 ## 5 18 ## 6 50 ## 7 51 ## 8 41 ## 9 62 ## 10 25 7.10.5 data frames You can think of data frames maybe as matrices-plus, because a column can take on characters as well as numbers. As we just saw, this is often useful for real data analyses. cen10 ## # A tibble: 30,871 x 13 ## year serial pernum region state countyfips city cpuma0010 sex age ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 2010 8.80e6 4 Middl… New … 0 Not … 636 Fema… 8 ## 2 2010 9.80e6 1 East … Ohio 103 Not … 802 Male 24 ## 3 2010 8.69e6 1 Mount… Neva… 3 Not … 582 Male 37 ## 4 2010 6.35e6 3 East … Mich… 0 Not … 476 Fema… 12 ## 5 2010 6.15e6 2 South… Mary… 33 Not … 449 Fema… 18 ## 6 2010 8.10e6 1 New E… New … 0 Not … 586 Male 50 ## 7 2010 4.06e6 1 West … Iowa 0 Not … 362 Fema… 51 ## 8 2010 7.03e6 2 West … Miss… 0 Not … 550 Fema… 41 ## 9 2010 8.16e6 2 Middl… New … 3 Not … 592 Male 62 ## 10 2010 1.12e6 3 Pacif… Cali… 37 Los … 81 Male 25 ## # ... with 30,861 more rows, and 3 more variables: race &lt;chr&gt;, ## # hhtype &lt;chr&gt;, relate &lt;chr&gt; Another way to think about data frames is that it is a type of list. Try the str() code below and notice how it is organized in slots. Each slot is a vector. They can be vectors of numbers or characters. # enter this on your console str(cen10) 7.10.6 Extracting variables from lists Often you want to inspect one variable of you r dataset. There are multiple ways to do this. with the single-square bracket, as in a matrix: cen10[, &quot;race&quot;] ## # A tibble: 30,871 x 1 ## race ## &lt;chr&gt; ## 1 White ## 2 White ## 3 White ## 4 White ## 5 Black/Negro ## 6 White ## 7 White ## 8 White ## 9 White ## 10 White ## # ... with 30,861 more rows which you can also refer to by the number of the column cen10[, 11] ## # A tibble: 30,871 x 1 ## race ## &lt;chr&gt; ## 1 White ## 2 White ## 3 White ## 4 White ## 5 Black/Negro ## 6 White ## 7 White ## 8 White ## 9 White ## 10 White ## # ... with 30,861 more rows with double-square brackets as in a data frame head(cen10[[&quot;race&quot;]]) ## [1] &quot;White&quot; &quot;White&quot; &quot;White&quot; &quot;White&quot; &quot;Black/Negro&quot; ## [6] &quot;White&quot; and with the dollar-sign $ head(cen10$race) ## [1] &quot;White&quot; &quot;White&quot; &quot;White&quot; &quot;White&quot; &quot;Black/Negro&quot; ## [6] &quot;White&quot; in the dplyr package, you can select multiple variables like this: cen10 %&gt;% select(race, state, age) ## # A tibble: 30,871 x 3 ## race state age ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 White New York 8 ## 2 White Ohio 24 ## 3 White Nevada 37 ## 4 White Michigan 12 ## 5 Black/Negro Maryland 18 ## 6 White New Hampshire 50 ## 7 White Iowa 51 ## 8 White Missouri 41 ## 9 White New Jersey 62 ## 10 White California 25 ## # ... with 30,861 more rows 7.11 What is a function? Most of what we do in R is executing a function. read_csv(), nrow(), ggplot() .. pretty much anything with a parentheses is a function. And even things like &lt;- and [ are functions as well. A function is a set of instructions with specified ingredients. It takes an input, then manipulates it – changes it in some way – and then returns the manipulated product. One way to see what a function actually does is to enter it without parentheses. # enter this on your console table You’ll see below that the most basic functions are quite complicated internally. You’ll notice that functions contain other functions. wrapper functions are functions that “wrap around” existing functions. This sounds redundant, but it’s an important feature of programming. If you find yourself repeating a command more than two times, you should make your own function, rather than writing the same type of code. 7.11.1 Write your own function It’s worth remembering the basic structure of a function. You create a new function, call it my_fun by this: my_fun &lt;- function() { } If we wanted to generate a function that computed the number of men in your data, what would that look like? count_men &lt;- function(data) { nmen &lt;- sum(data$sex == &quot;Male&quot;) return(nmen) } Then all we need to do is feed this function a dataset count_men(cen10) ## [1] 15220 The point of a function is that you can use it again and again without typing up the set of constituent manipulations. So, what if we wanted to figure out the number of men in California? count_men(filter(cen10, state == &quot;California&quot;)) ## [1] 1876 Let’s go one step further. What if we want to know the proportion of non-whites in a state, just by entering the name of the state? There’s multiple ways to do it, but it could look something like this nw_in_state &lt;- function(data, state) { s.subset &lt;- filter(data, state == state) total.s &lt;- nrow(s.subset) nw.s &lt;- sum(s.subset$race != &quot;White&quot;) nw.s / total.s } The last line is what gets generated from the function. To be more explicit you can wrap the last line around return(). (as in return(nw.s/total.s). return() is used when you want to break out of a function in the middle of it and not wait till the last line. Try it on your favorite state! nw_in_state(cen10, &quot;Alabama&quot;) ## [1] 0.2806517 Exercise. Try making your own function, asians_in_state, that will give you the number of Chinese, Japanese, and Other Asian or Pacific Islander people in a given state. # Enter on your own 7.12 What is a package? You can think of a package as a suite of functions that other people have already built for you to make your life easier. help(package = &quot;ggplot2&quot;) To use a package, you need to do two things: (1) install it, and then (2) load it. Installing is a one-time thing install.packages(&quot;ggplot2&quot;) But you need to load each time you start a R instance. So always keep these commands on a script. library(ggplot2) In rstudio.cloud, we already installed a set of packages for you. But when you start your own R instance, you need to have installed the package at some point. 7.13 Review Exercises In the time remaining, try the following exercises. Order doesn’t matter. 7.13.1 Exercise 1: Make your own graphic Make a graphic from the census data that tells us something interesting about the U.S. 2010 population. # Enter yourself 7.13.2 Exercise 2: Counting CVAP A issue raised in Persily’s article is that the full-count U.S. Census does not record whether the residents are citizens of the United States7. Instead, this question is asked in a survey, the American Community Survey. The two are fundamentally different exercises: the Census counts everyone by definition, a survey samples its data. Load the 1 percent sample of the 2015 ACS (acs2015_1percent.csv, in the input folder) and give an estimate of the proportion of a state’s ACS respondents that are reportedly U.S. citizens. # Enter yourself 7.13.3 Exercise 3: Write your own function Write your own function that makes some task of data analysis simpler. Ideally, it would be a function that helps you do either of the previous tasks in fewer lines of code. # Enter yourself 7.14 Tell us about this session. This is day 1 and we covered a lot of material. Some of you might have found this completely new; others not so. Please click through this survey before you leave so we can adjust accordingly on the next few days. Persily, Nathaniel. 2011. “The Law of the Census: How to Count, What to Count, Whom to Count, and Where to Count Them.” Cardozo Law Review 32(3): 755–91.↩ Hochschild, Jennifer L., and Brenna Marea Powell. 2008. “Racial Reorganization and the United States Census 1850–1930: Mulattoes, Half-Breeds, Mixed Parentage, Hindoos, and the Mexican Race.” Studies in American Political Development 22(1): 59–96.↩ Ruggles, Steven, Katie Genadek, Ronald Goeken, Josiah Grover, and Matthew Sobek. 2015. Integrated Public Use Microdata Series: Version 6.0 dataset↩ The 2010 Census reported 308,745,539. Wikipedia↩ Kastellec, Jonathan P., and Eduardo L. Leoni. 2007. “Using Graphs Instead of Tables in Political Science.”&quot; Perspectives on Politics 5 (4): 755–71.↩ Tufte, Edward. The Visual Display of Quantitative Information↩ Here is that argument of his again, more recently in the popular press. “The Mysterious Number of American Citizens”. June 2, 2015. POLITICO↩ "],
["manipulating-vectors-and-matrices.html", "Chapter 8 Manipulating Vectors and Matrices 8.1 Where are we? Where are we headed? 8.2 Motivation 8.3 Setup 8.4 Read Data 8.5 data.frame vs. matricies 8.6 Speed considerations 8.7 Handling matricies in R 8.8 Variable Transformations 8.9 Linear Combinations 8.10 Functions in functions 8.11 Extension and Exercises", " Chapter 8 Manipulating Vectors and Matrices 8.1 Where are we? Where are we headed? Up till now, you should have covered: R basic programming Counting. Visualization. Statistical Summaries. Objects and Classes. Functions. Today we’ll cover Matrices in R Manipulating variables And other R tips! 8.2 Motivation Nunn and Wantchekon (2011) – “The Slave Trade and the Origins of Mistrust in Africa”8 – argues that across African countries, the distrust of co-ethnics fueled by the slave trade has had long-lasting effects on modern day trust in these territories. They argued that the slave trade created distrust in these societies in part because as some African groups were employed by European traders to capture their neighbors and bring them to the slave ships. Nunn and Wantchekon use a variety of statistical tools to make their case (adding controls, ordered logit, instrumental variables, falsification tests, causal mechanisms), many of which will be covered in future courses. In this module we will only touch on their first set of analysis that use Ordinary Least Squares (OLS). OLS is likely the most common application of linear algebra in the social sciences. We will cover some linear algebra, matrix manipulation, and vector manipulation from this data. 8.3 Setup library(dplyr) library(readr) library(haven) library(ggplot2) 8.4 Read Data library(haven) nunn_full &lt;- read_dta(&quot;./input/Nunn_Wantchekon_AER_2011.dta&quot;) Nunn and Wantchekon’s main dataset has more than 20,000 observations. Each observation is a respondent from the Afrobarometer survey. nunn_full ## # A tibble: 21,822 x 59 ## respno ethnicity murdock_name isocode region district townvill ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 BEN0001 fon FON BEN atlnatique KPOMASSE TOKPA-DO… ## 2 BEN0002 fon FON BEN atlnatique KPOMASSE TOKPA-DO… ## 3 BEN0003 fon FON BEN atlnatique OUIDAH 3ARROND ## 4 BEN0004 fon FON BEN atlnatique OUIDAH 3ARROND ## 5 BEN0005 fon FON BEN atlnatique OUIDAH PAHOU ## 6 BEN0006 fon FON BEN atlnatique OUIDAH PAHOU ## 7 BEN0007 fon FON BEN atlnatique TORI-BOSSI… TORI-GARE ## 8 BEN0008 fon FON BEN atlnatique TORI-BOSSI… TORI-GARE ## 9 BEN0009 fon FON BEN atlnatique ALLADA TOKPA ## 10 BEN0010 fon FON BEN atlnatique ALLADA TOKPA ## # ... with 21,812 more rows, and 52 more variables: location_id &lt;dbl&gt;, ## # trust_relatives &lt;dbl&gt;, trust_neighbors &lt;dbl&gt;, intra_group_trust &lt;dbl&gt;, ## # inter_group_trust &lt;dbl&gt;, trust_local_council &lt;dbl&gt;, ## # ln_export_area &lt;dbl&gt;, export_area &lt;dbl&gt;, export_pop &lt;dbl&gt;, ## # ln_export_pop &lt;dbl&gt;, age &lt;dbl&gt;, age2 &lt;dbl&gt;, male &lt;dbl&gt;, ## # urban_dum &lt;dbl&gt;, occupation &lt;dbl&gt;, religion &lt;dbl&gt;, ## # living_conditions &lt;dbl&gt;, education &lt;dbl&gt;, near_dist &lt;dbl&gt;, ## # distsea &lt;dbl&gt;, loc_murdock_name &lt;chr&gt;, loc_ln_export_area &lt;dbl&gt;, ## # local_council_performance &lt;dbl&gt;, council_listen &lt;dbl&gt;, ## # corrupt_local_council &lt;dbl&gt;, school_present &lt;dbl&gt;, ## # electricity_present &lt;dbl&gt;, piped_water_present &lt;dbl&gt;, ## # sewage_present &lt;dbl&gt;, health_clinic_present &lt;dbl&gt;, ## # district_ethnic_frac &lt;dbl&gt;, frac_ethnicity_in_district &lt;dbl&gt;, ## # townvill_nonethnic_mean_exports &lt;dbl&gt;, ## # district_nonethnic_mean_exports &lt;dbl&gt;, ## # region_nonethnic_mean_exports &lt;dbl&gt;, ## # country_nonethnic_mean_exports &lt;dbl&gt;, murdock_centr_dist_coast &lt;dbl&gt;, ## # centroid_lat &lt;dbl&gt;, centroid_long &lt;dbl&gt;, explorer_contact &lt;dbl&gt;, ## # railway_contact &lt;dbl&gt;, dist_Saharan_node &lt;dbl&gt;, ## # dist_Saharan_line &lt;dbl&gt;, malaria_ecology &lt;dbl&gt;, v30 &lt;dbl+lbl&gt;, ## # v33 &lt;dbl+lbl&gt;, fishing &lt;dbl&gt;, exports &lt;dbl&gt;, ln_exports &lt;dbl&gt;, ## # total_missions_area &lt;dbl&gt;, ln_init_pop_density &lt;dbl&gt;, ## # cities_1400_dum &lt;dbl&gt; First, let’s consider a small subset of this dataset. nunn &lt;- read_dta(&quot;./input/Nunn_Wantchekon_sample.dta&quot;) nunn ## # A tibble: 10 x 5 ## trust_neighbors exports ln_exports export_area ln_export_area ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3 0.388 0.328 0.00407 0.00406 ## 2 3 0.631 0.489 0.0971 0.0926 ## 3 3 0.994 0.690 0.0125 0.0124 ## 4 0 183. 5.21 1.82 1.04 ## 5 3 0 0 0 0 ## 6 2 0 0 0 0 ## 7 2 666. 6.50 14.0 2.71 ## 8 0 0.348 0.298 0.00608 0.00606 ## 9 3 0.435 0.361 0.0383 0.0376 ## 10 3 0 0 0 0 8.5 data.frame vs. matricies This is a data.frame object. class(nunn) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; But it can be also consider a matrix in the linear algebra sense. What are the dimensions of this matrix? nrow(nunn) ## [1] 10 data.frames and matrices have much overlap in R, but to explicitly treat an object as a matrix, you’d need to coerce its class. Let’s call this matrix X. X &lt;- as.matrix(nunn) What is the difference between a data.frame and a matrix? A data.frame can have columns that are of different types, whereas — in a matrix — all columns must be of the same type (usually either “numeric” or “character”). 8.6 Speed considerations Nrow &lt;- 100 Ncol &lt;- 5 Xmat &lt;- matrix(rnorm(Nrow * Ncol), nrow = Nrow, ncol = Ncol) Xdf &lt;- as.data.frame(Xmat) system.time(replicate(50000, colMeans(Xmat))) ## user system elapsed ## 0.313 0.012 0.343 system.time(replicate(50000, colMeans(Xdf))) ## user system elapsed ## 3.980 0.067 5.089 100 * (0.3 - 3.0)/3.0 ## [1] -90 8.7 Handling matricies in R t(X) ## [,1] [,2] [,3] [,4] [,5] [,6] ## trust_neighbors 3.000000000 3.00000000 3.00000000 0.000000 3 2 ## exports 0.388349682 0.63112360 0.99418926 182.589127 0 0 ## ln_exports 0.328115761 0.48926911 0.69023758 5.212700 0 0 ## export_area 0.004067405 0.09705944 0.01252469 1.824284 0 0 ## ln_export_area 0.004059155 0.09263337 0.01244691 1.038255 0 0 ## [,7] [,8] [,9] [,10] ## trust_neighbors 2.000000 0.000000000 3.00000000 3 ## exports 665.965210 0.347641766 0.43498713 0 ## ln_exports 6.502738 0.298356235 0.36115587 0 ## export_area 13.975567 0.006082553 0.03833238 0 ## ln_export_area 2.706420 0.006064130 0.03761595 0 X[, 1] ## [1] 3 3 3 0 3 2 2 0 3 3 X[, &quot;exports&quot;] ## [1] 0.3883497 0.6311236 0.9941893 182.5891266 0.0000000 ## [6] 0.0000000 665.9652100 0.3476418 0.4349871 0.0000000 X[1, ] ## trust_neighbors exports ln_exports export_area ## 3.000000000 0.388349682 0.328115761 0.004067405 ## ln_export_area ## 0.004059155 X[1, 1] ## trust_neighbors ## 3 Pause and consider the following problem on your own. What is the following code doing? X[X[,&quot;trust_neighbors&quot;] == 0,&quot;export_area&quot;] ## [1] 1.824284434 0.006082553 Why does it give the same output as the following? X[which(X[,&quot;trust_neighbors&quot;] == 0),&quot;export_area&quot;] ## [1] 1.824284434 0.006082553 Some more manipulation X + X ## trust_neighbors exports ln_exports export_area ln_export_area ## [1,] 6 0.7766994 0.6562315 0.008134809 0.00811831 ## [2,] 6 1.2622472 0.9785382 0.194118887 0.18526673 ## [3,] 6 1.9883785 1.3804752 0.025049388 0.02489382 ## [4,] 0 365.1782532 10.4254007 3.648568869 2.07651019 ## [5,] 6 0.0000000 0.0000000 0.000000000 0.00000000 ## [6,] 4 0.0000000 0.0000000 0.000000000 0.00000000 ## [7,] 4 1331.9304199 13.0054760 27.951133728 5.41283989 ## [8,] 0 0.6952835 0.5967125 0.012165107 0.01212826 ## [9,] 6 0.8699743 0.7223117 0.076664761 0.07523189 ## [10,] 6 0.0000000 0.0000000 0.000000000 0.00000000 X - X ## trust_neighbors exports ln_exports export_area ln_export_area ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## [3,] 0 0 0 0 0 ## [4,] 0 0 0 0 0 ## [5,] 0 0 0 0 0 ## [6,] 0 0 0 0 0 ## [7,] 0 0 0 0 0 ## [8,] 0 0 0 0 0 ## [9,] 0 0 0 0 0 ## [10,] 0 0 0 0 0 t(X) %*% X ## trust_neighbors exports ln_exports export_area ## trust_neighbors 62.000000 1339.276 18.61181 28.40709 ## exports 1339.276369 476850.298 5283.76294 9640.42990 ## ln_exports 18.611811 5283.763 70.50077 100.46202 ## export_area 28.407085 9640.430 100.46202 198.65558 ## ln_export_area 5.853106 1992.047 23.08189 39.72847 ## ln_export_area ## trust_neighbors 5.853106 ## exports 1992.046502 ## ln_exports 23.081893 ## export_area 39.728468 ## ln_export_area 8.412887 cbind(X, 1:10) ## trust_neighbors exports ln_exports export_area ln_export_area ## [1,] 3 0.3883497 0.3281158 0.004067405 0.004059155 ## [2,] 3 0.6311236 0.4892691 0.097059444 0.092633367 ## [3,] 3 0.9941893 0.6902376 0.012524694 0.012446908 ## [4,] 0 182.5891266 5.2127004 1.824284434 1.038255095 ## [5,] 3 0.0000000 0.0000000 0.000000000 0.000000000 ## [6,] 2 0.0000000 0.0000000 0.000000000 0.000000000 ## [7,] 2 665.9652100 6.5027380 13.975566864 2.706419945 ## [8,] 0 0.3476418 0.2983562 0.006082553 0.006064130 ## [9,] 3 0.4349871 0.3611559 0.038332380 0.037615947 ## [10,] 3 0.0000000 0.0000000 0.000000000 0.000000000 ## ## [1,] 1 ## [2,] 2 ## [3,] 3 ## [4,] 4 ## [5,] 5 ## [6,] 6 ## [7,] 7 ## [8,] 8 ## [9,] 9 ## [10,] 10 cbind(X, 1) ## trust_neighbors exports ln_exports export_area ln_export_area ## [1,] 3 0.3883497 0.3281158 0.004067405 0.004059155 1 ## [2,] 3 0.6311236 0.4892691 0.097059444 0.092633367 1 ## [3,] 3 0.9941893 0.6902376 0.012524694 0.012446908 1 ## [4,] 0 182.5891266 5.2127004 1.824284434 1.038255095 1 ## [5,] 3 0.0000000 0.0000000 0.000000000 0.000000000 1 ## [6,] 2 0.0000000 0.0000000 0.000000000 0.000000000 1 ## [7,] 2 665.9652100 6.5027380 13.975566864 2.706419945 1 ## [8,] 0 0.3476418 0.2983562 0.006082553 0.006064130 1 ## [9,] 3 0.4349871 0.3611559 0.038332380 0.037615947 1 ## [10,] 3 0.0000000 0.0000000 0.000000000 0.000000000 1 colnames(X) ## [1] &quot;trust_neighbors&quot; &quot;exports&quot; &quot;ln_exports&quot; &quot;export_area&quot; ## [5] &quot;ln_export_area&quot; 8.8 Variable Transformations exports is the total number of slaves that were taken from the individual’s ethnic group between Africa’s four slave trades between 1400-1900. What is ln_exports? The article describes this as the natural log of one plus the exports. This is a transformation of one column by a particular function log(1 + X[, &quot;exports&quot;]) ## [1] 0.3281158 0.4892691 0.6902376 5.2127003 0.0000000 0.0000000 6.5027379 ## [8] 0.2983562 0.3611559 0.0000000 Question for you: why add the 1? Verify that this is the same as X[, &quot;ln_exports&quot;] What is ln_export_area? Why do you think they do this transformation? 8.9 Linear Combinations In Table 1 we see “OLS Estimates”. These are estimates of OLS coefficients and standard errors. You do not need to know what these are for now, but it doesn’t hurt to getting used to seeing them. A very crude way to describe regression is through linear combinations. The simplest linear combination is a one-to-one transformation. Take the first number in Table 1, which is -0.00068. Now, multiply this by exports -0.00068 * X[, &quot;exports&quot;] ## [1] -0.0002640778 -0.0004291640 -0.0006760487 -0.1241606061 0.0000000000 ## [6] 0.0000000000 -0.4528563428 -0.0002363964 -0.0002957912 0.0000000000 Now, just one more step. Make a new matrix with just exports and the value 1 X2 &lt;- cbind(1, X[, &quot;exports&quot;]) name this new column “intercept” colnames(X2) ## NULL colnames(X2) &lt;- c(&quot;intercept&quot;, &quot;exports&quot;) What are the dimensions of the matrix X2? dim(X2) ## [1] 10 2 Now consider a new matrix, called B. B &lt;- matrix(c(1.62, -0.00068)) What are the dimensions of B? dim(B) ## [1] 2 1 What is the product of X2 and B? From the dimensions, can you tell if it will be conformable? X2 %*% B ## [,1] ## [1,] 1.619736 ## [2,] 1.619571 ## [3,] 1.619324 ## [4,] 1.495839 ## [5,] 1.620000 ## [6,] 1.620000 ## [7,] 1.167144 ## [8,] 1.619764 ## [9,] 1.619704 ## [10,] 1.620000 What is this multiplication doing in terms of equations? 8.10 Functions in functions tapply(nunn_full$trust_neighbors, INDEX = nunn_full$isocode, FUN = mean) ## BEN BWA GHA KEN LSO MDG MLI MOZ ## NA NA NA NA 1.279931 NA NA NA ## MWI NAM NGA SEN TZA UGA ZAF ZMB ## NA NA NA NA NA NA NA NA ## ZWE ## NA tapply(nunn_full$trust_neighbors, INDEX = nunn_full$isocode, FUN = function (x) mean(x, na.rm = TRUE)) ## BEN BWA GHA KEN LSO MDG MLI MOZ ## 1.529362 1.315593 1.715736 1.703410 1.279931 1.571205 2.140992 1.977567 ## MWI NAM NGA SEN TZA UGA ZAF ZMB ## 2.220067 1.667343 1.463006 2.516568 2.158358 1.806658 1.569271 1.543786 ## ZWE ## NaN 8.11 Extension and Exercises 8.11.0.1 Exercise 1 First start from visualization. In ggplot, using the full dataset, make a “facetted” scatterplot where each facet is a (respondent’s current) country, the x-axis is the natural log of (one plus a respondent’s ethnicity’s slave exports divided by the land area), and the y-axis is the respondent’s level of mistrust (with the numerical coding preserved). You should define a new column in the dataset for the x-axis, calling it something like ln_exports_area. ## Enter yourself or see your_script.R 8.11.0.2 Exercise 2: Fitted vs. Observed values Make a scatterplot with: x axis: The linear combination of the intercept and log_export_area (a n by 2 matrix) with the coefficient matrix given above (matrix(c(1.62, -0.00068))). y axis: The observed level of mistrust for each respondent. Then add a facetting layer to show a scatterplot by country. ## Enter yourself 8.11.0.3 Exercise 3: Matrix powers Let \\[\\mathbf{A} = \\left[\\begin{array} {rrr} 0.6 &amp; 0.2\\\\ 0.4 &amp; 0.8\\\\ \\end{array}\\right] \\] Use R to write a loop that will consecutively multiply \\(A\\) to itself. What is the value of \\(A^{100}\\)? \\(A^{500}\\)? Store each iteration of \\(A^n\\) where \\(n = 1, 2....\\) and plot how each element of the product changes over \\(n\\) iterations. ## Enter yourself Note that R notation of matrices is different from the math notation. Simply trying X^n where X is a matrix will only take the power of each element to n. Instead, this problem asks you to perform matrix multiplication. 8.11.0.4 Exercise 4: Challenge problem! Write an R function that takes two inputs (A and B). A and B can both either be matrices or data frames. Write code that checks to make sure whether A and B are either matrices or dateframe. Print an error message if one of them is not a matrix or data frame. Convert any data frames to matrices. Check whether the A and B have compatible dimensions. If they don’t, print an error message. If they do, perform the matrix multiplication A * B. Nunn, Nathan, and Leonard Wantchekon. 2011. “The Slave Trade and the Origins of Mistrust in Africa.” American Economic Review 101(7): 3221–52.↩ "],
["joins-and-merges-wide-and-long.html", "Chapter 9 Joins and Merges, Wide and Long 9.1 Where are we? Where are we headed? 9.2 Motivation 9.3 Setting up 9.4 Create a project directory 9.5 Data Sources 9.6 Example with 2 Datasets 9.7 Loops 9.8 Merging 9.9 Main Project", " Chapter 9 Joins and Merges, Wide and Long 9.1 Where are we? Where are we headed? Up till now, you should have covered: R basic programming Counting. Visualization. Objects and Classes. Functions. Matrix algebra in R Today you will work on your own, but feel free to ask a fellow classmate nearby or the instructor. The objective for this session is to get more experience using R, but in the process (a) test a prominent theory in the political science literature and (b) explore related ideas of interest to you. 9.2 Motivation The “Democratic Peace” is one of the most widely discussed propositions in political science, covering the fields of International Relations and Comparative Politics, with insights to domestic politics of democracies (e.g. American Politics). The one-sentence idea is that democracies do not fight with each other. There have been much theoretical debate – for example in earlier work, Oneal and Russet (1999) argue that the democratic peace is not due to the hegemony of strong democracies like the U.S. and attempt to distinguish between realist and what they call Kantian propositions (e.g. democratic governance, international organizations)9. An empirical demonstration of the democratic peace is also a good example of a Time Series Cross Sectional (or panel) dataset, where the same units (in this case countries) are observed repeatedly for multiple time periods. Experience in assembling and analyzing a TSCS dataset will prepare you for any future research in this area. 9.3 Setting up library(dplyr) library(readr) library(data.table) library(foreach) library(readxl) library(ggplot2) 9.4 Create a project directory First start a directory for this project. This can be done manually or through RStudio’s Project feature(File &gt; New Project...) Directories is the computer science / programming name for folders. While advice about how to structure your working directories might strike you as petty, we believe that starting from some well-tested guides will go a long way in improving the quality and efficiency of your work. Chapter 4 of Gentzkow and Shapiro’s memo, Code and Data for the Social Scientist] provides a good template. 9.5 Data Sources Most projects you do will start with downloading data from elsewhere. For this task, you’ll probably want to track down and download the following: Correlates of war dataset (COW): Find and download the Militarized Interstate Disputes (MIDs) data from the Correlates of War website: http://www.correlatesofwar.org/data-sets. Or a dyad-version on dataverse: https://dataverse.harvard.edu/dataset.xhtml?persistentId=hdl:1902.1/11489 PRIO Data on Armed Conflict: Find and download the Uppsala Conflict Data Program (UCDP) and PRIO dyad-year data on armed conflict(https://www.prio.org) or this link to to the flat csv file (http://ucdp.uu.se/downloads/dyadic/ucdp-dyadic-171.csv). Polity: The Polity data can be downloaded from their website (http://www.systemicpeace.org/inscrdata.html). Look for the newest version of the time series that has the widest coverage. 9.6 Example with 2 Datasets Let’s read in a sample dataset. polity &lt;- read_csv(&quot;input/sample_polity.csv&quot;) ## Parsed with column specification: ## cols( ## scode = col_character(), ## ccode = col_integer(), ## country = col_character(), ## year = col_double(), ## polity2 = col_integer() ## ) mid &lt;- read_csv(&quot;input/sample_mid.csv&quot;) ## Parsed with column specification: ## cols( ## ccode = col_integer(), ## polity_code = col_character(), ## dispute = col_integer(), ## StYear = col_integer(), ## EndYear = col_integer() ## ) What does polity look like? ggplot(polity, aes(x = year, y = polity2)) + facet_wrap(~ country) + geom_line() MID is a dataset that captures a dispute for a given country and year. mid ## # A tibble: 6,132 x 5 ## ccode polity_code dispute StYear EndYear ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 200 UKG 1 1902 1903 ## 2 2 USA 1 1902 1903 ## 3 345 YGS 1 1913 1913 ## 4 300 &lt;NA&gt; 1 1913 1913 ## 5 339 ALB 1 1946 1946 ## 6 200 UKG 1 1946 1946 ## 7 200 UKG 1 1951 1952 ## 8 651 EGY 1 1951 1952 ## 9 630 IRN 1 1856 1857 ## 10 200 UKG 1 1856 1857 ## # ... with 6,122 more rows 9.7 Loops Notice that in the mid data, we have a start of a dispute vs. an end of a dispute.In order to combine this into the polity data, we want a way to give each of the interval years a row. There are many ways to do this, but one is a loop. We go through one row at a time, and then for each we make a new dataset. that has year as a sequence of each year. mid_year_by_year &lt;- foreach(i = 1:nrow(mid), .combine = &quot;bind_rows&quot;) %do% { data_frame(ccode = mid$ccode[i], ## row i&#39;s country year = mid$StYear[i]:mid$EndYear[i], ## sequence of years for dispute in row i dispute = 1) } 9.8 Merging We want to combine these two datasets by merging. Base-R has a function called merge. dplyr has several types of joins (the same thing). Those names are based on SQL syntax. Here we can do a left_join from polity to mid. We want to keep the rows in polity that do not match in mid, and label them as non-disputes. p_m &lt;- left_join(polity, distinct(mid_year_by_year), by = c(&quot;ccode&quot;, &quot;year&quot;)) Replace dispute = NA rows with a zero. p_m &lt;- p_m %&gt;% mutate(dispute = replace(dispute, is.na(dispute), 0)) long to wide p_m_w &lt;- dcast(data = as.data.table(p_m), formula = ccode ~ year, value.var = &quot;polity2&quot;) 9.9 Main Project Try building a panel that would be useful in answering the Democratic Peace Question, perhaps in these steps. 9.9.1 Task 1: Data Input and Standardization Often, files we need are saved in the .xls or xlsx format. It is possible to read these files directly into R, but experience suggests that this process is slower than converting them first to .csv format and reading them in as .csv files. The rio package10 has functions to convert between file types. readxl/readr/haven packages(https://github.com/tidyverse/tidyverse) is constantly expanding to capture more file types. read_xl is new but quite good. 9.9.2 Task 2: Data Merging We will use data to test a version of the Democratic Peace Thesis (DPS): are democracies less likely to engage in militarized interstate disputes with one another? To start, let’s download and merge some data. Load in the Militarized Interstate Dispute (MID) files. Militarized interstate disputes are hostile action between two formally recognized states. Examples of this would be threats to use force, threats to declare war, beginning war, fortifying a border with troops, and so on. Find a way to merge the Polity IV dataset and the MID data. This process can be a bit tricky. An advanced version of this task would be to download the dyadic form of the data and try merging that with polity. 9.9.3 Task 3: Tabulations and Visualization Calculate the mean Polity2 score by year. Plot the result. Use graphical indicators of your choosing to show where key events fall in this timeline (such as 1914, 1929, 1939, 1989, 2008). Speculate on why the behavior from 1800 to 1920 seems to be qualitatively different than behavior afterwards. Once you have merged the datasets, what fraction of all MIDs in the time period we have data for involve 2 countries both with Polity2 scores greater than 5? Greater than 8? If there are any of the latter, find out what MIDs those are and research them for a bit. What is the mean difference in Polity2 score for countries involved in a MID? How has this quantity changed over time? How do you interpret this? Arrive at a tentative conclusion for how well the Democratic Peace argument seems to hold up in this dataset. Visualize this conclusion. The Kantian Peace: The Pacific Benefits of Democracy, Interdependence, and International Organizations, 1885-1992. World Politics 52(1):1-37↩ https://github.com/leeper/rio↩ "],
["text.html", "Chapter 10 Text 10.1 Where are we? Where are we headed? 10.2 Review 10.3 Goals for today 10.4 Reading and writing text in R 10.5 paste and sprintf 10.6 Regular expressions 10.7 Representing Text 10.8 Important packages for parsing text 10.9 Exercises to check your understanding!", " Chapter 10 Text Module originally written by Connor Jerzak library(dplyr) library(readr) library(data.table) library(scales) library(forcats) library(ggplot2) 10.1 Where are we? Where are we headed? Up till now, you should have covered: Loading in data; R notation; Matrix algebra. 10.2 Review &quot; and ' are usually equivalent. &lt;- and = are interchangeable. (x &lt;- 3 is equivalent to x = 3). Use ; to separate commands on the same line: x &lt;- 3; y &lt;- 4 print(x); print( y ) ## [1] 3 ## [1] 4 Use ( ) when you are giving input to a function: #my_results &lt;- FunctionName(FunctionInputs) Use { } when you are defining a function or writing a for loop: #function MyFunction &lt;- function(InputMatrix){ TempMat &lt;- InputMatrix for(i in 1:5){ TempMat &lt;- t(TempMat) %*% TempMat / 10 } return( TempMat ) } myMat &lt;- matrix(rnorm(100*5), nrow = 100, ncol = 5) print( MyFunction(myMat) ) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1282.0248 1606.5943 1377.5103 -571.0413 -1291.3278 ## [2,] 1606.5943 2044.3711 1688.5264 -759.3901 -1569.2406 ## [3,] 1377.5103 1688.5264 1548.0143 -511.9794 -1469.8026 ## [4,] -571.0413 -759.3901 -511.9794 429.3776 454.7201 ## [5,] -1291.3278 -1569.2406 -1469.8026 454.7201 1403.1795 #loop x &lt;- c() for(i in 1:20){ x[i] &lt;- i } print(x) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 10.3 Goals for today Today, we will learn more about using text data. Our objectives are: Reading and writing in text in R. To learn how to use paste and sprintf; To learn how to use regular expresions; To learn about other tools for representing + analyzing text in R. 10.4 Reading and writing text in R To read in a text file, use readLines readLines(&quot;~/Downloads/Carboxylic acid - Wikipedia.html&quot;) To write a text file, use: write.table(my_string_vector, &quot;~/mydata.txt&quot;, sep=&quot;\\t&quot;) 10.5 paste and sprintf paste and sprintf are useful commands in text processing, such as for automatically naming files or automatically performing a series of commands over a subset of your data. Table making also will often need these commands. Paste concatenates vectors together. #use collapse for inputs of length &gt; 1 my_string &lt;- c(&quot;Not&quot;, &quot;one&quot;, &quot;could&quot;, &quot;equal&quot;) paste(my_string, collapse = &quot; &quot;) ## [1] &quot;Not one could equal&quot; #use sep for inputs of length == 1 paste(&quot;Not&quot;, &quot;one&quot;, &quot;could&quot;, &quot;equal&quot;, sep = &quot; &quot;) ## [1] &quot;Not one could equal&quot; For more sophisticated concatenation, use sprintf. This is very useful for automatically making tables. sprintf(&quot;Coefficient for %s: %.3f (%.2f)&quot;, &quot;Gender&quot;, 1.52324, 0.03143) ## [1] &quot;Coefficient for Gender: 1.523 (0.03)&quot; #%s is replaced by a character string #%.3f is replaced by a floating point digit with 3 decimal places #%.2f is replaced by a floating point digit with 2 decimal places 10.6 Regular expressions Definition. Regular expression — a special text string for describing a search pattern. They are most often used in functions for detecting, locating, and replacing desired text in a corpus. Use cases. TEXT PARSING. E.g. I have 10000 congressional speaches. Find all those which mention Iran. WEB SCRAPING. E.g. Parse html code in order to extract research information from an online table. CLEANING DATA. E.g. After loading in a dataset, we might need to remove mistakes from the dataset, or subset the data using regular expression tools. Example in R. Extract the tweet mentioning Indonesia. s1 &lt;- &quot;If only Bradley&#39;s arm was longer. RT&quot; s2 &lt;- &quot;Share our love in Indonesia and in the World. RT if you agree.&quot; my_string &lt;- c(s1, s2) grepl(my_string, pattern = &quot;Indonesia&quot;) ## [1] FALSE TRUE my_string[ grepl(my_string, pattern = &quot;Indonesia&quot;)] ## [1] &quot;Share our love in Indonesia and in the World. RT if you agree.&quot; Key point: Many R commands use regular expressions. See ?grepl. Assume that x is a character vector and that pattern is the target pattern. In the earlier example, x could have been something like my_string and pattern would have been “Indonesia”. Here are other key uses: DETECT PATTERNS. grepl(pattern, x) goes through all the entries of x and returns a string of TRUE and FALSE values of the same size as x. It will return a TRUE whenever that string entry has the target pattern, and FALSE whenever it doesn’t. REPLACE PATTERNS. gsub(pattern, x, replacement) goes through all the entries of x replaces the pattern with replacement. gsub(x = my_string, pattern = &quot;o&quot;, replacement = &quot;AAAA&quot;) LOCATE PATTERNS. regexpr(pattern, text) goes through each element of the character string. It returns a vector of the same length, with the entries of the vector corresponding to the location of the first pattern match, or a -1 if no match was obtained. regexpr(pattern = &quot;was&quot;, text = my_string) [1] 23 -1 attr(,&quot;match.length&quot;) [1] 3 -1 attr(,&quot;useBytes&quot;) [1] TRUE regexpr(pattern = &quot;was&quot;, text = my_string)[1] ## [1] 23 regexpr(pattern = &quot;was&quot;, text = my_string)[2] ## [1] -1 Seems simple? The problem: the patterns can get pretty complex! PATTERN TYPE 1 – Character classes [[:digit:]] Matches with all digits. [[:lower:]] Matches with lower case letters. [[:alpha:]] Matches with all alphabetic characters. [[:punct:]] Matches with all punctuation characters. [[:cntrl:]] Matches with “control” characters such as \\n, \\r, etc. Example in R: my_string &lt;- &quot;Do you think that 34% of apples are red?&quot; gsub(my_string, pattern = &quot;[[:digit:]]&quot;, replace =&quot;DIGIT&quot;) ## [1] &quot;Do you think that DIGITDIGIT% of apples are red?&quot; gsub(my_string, pattern = &quot;[[:alpha:]]&quot;, replace =&quot;&quot;) ## [1] &quot; 34% ?&quot; PATTERN TYPE 2 – Special Characters. Certain characters (such as ., *, \\) have special meaning in the regular expressions framework (they are used to form conditional patterns as discussed below). Thus, when we want our pattern to explicilty include those characters as characters, we must “escape” them by using \\ or encloding them in \\Q…\\E. Example in R: my_string &lt;- &quot;Do *really* think he will win?&quot; gsub(my_string, pattern = &quot;\\\\*&quot;, replace =&quot;&quot;) ## [1] &quot;Do really think he will win?&quot; my_string &lt;- &quot;Now be brave! \\n Dread what comrades say of you here in combat! &quot; gsub(my_string, pattern = &quot;\\\\\\n&quot;, replace =&quot;&quot;) ## [1] &quot;Now be brave! Dread what comrades say of you here in combat! &quot; PATTERN TYPE 3 – Conditional patterns [...] The target characters to match are located between the brackets. For example, [aAbB] will match with the characteres a, A, b, B. [^...] Matches with everything except the material between the brackets. For example, [^aAbB] will match with everything but the characteres a, A, b, B. (?=) Lookahead – match something that IS followed by the pattern. (?!) Negative lookahead — match something that is NOT followed by the pattern. (?&lt;=) Lookbehind – match with something that follows the pattern. my_string &lt;- &quot;Do you think that 34%of the 23%of apples are red?&quot; gsub(my_string, pattern = &quot;(?&lt;=%)&quot;, replace =&quot; &quot;, perl = T) ## [1] &quot;Do you think that 34% of the 23% of apples are red?&quot; my_string &lt;- c(&quot;legislative1_term1.png&quot;, &quot;legislative1_term1.pdf&quot;, &quot;legislative1_term2.png&quot;, &quot;legislative1_term2.pdf&quot;, &quot;term2_presidential1.png&quot;, &quot;presidential1.png&quot;, &quot;presidential1_term2.png&quot;, &quot;presidential1_term1.pdf&quot;, &quot;presidential1_term2.pdf&quot;) grepl(my_string, pattern = &quot;^(?!presidential1).*\\\\.png&quot;, perl = T) ## [1] TRUE FALSE TRUE FALSE TRUE FALSE FALSE FALSE FALSE #Indicates which file names don&#39;t start with presidential1 but do end in .png #^ indicates that the pattern should start at the beginning of the string. #?! indicates negative lookahead -- we&#39;re looking for any pattern NOT following presidential1 which meets the subsequent conditions. (see below) #The first . indicates that, following the negative lookahead, #there can be any characters and the * says that it doesn&#39;t matter how many. #Note that we have to escape the . in .png. (by writing \\\\. instead of just .) NOTE: You will have the chance to try out some regular expressions for yourself at the end! 10.7 Representing Text In courses and research, we often want to analyze text, to extract meaning out of it. One of the key decisions we need to make is how to represent the text as numbers. Once the text is represented numerically, we can then apply a host of statistical and machine learning methods to it. Those methods are discussed more in the Gov methods sequence (Gov 2000-2003). Here’s a summary of the decisions you must make: WHICH TEXT TO USE? Which text do I want to analyze? What is my universe of documents? HOW TO REPRESENT THE TEXT NUMERICALLY? How do I use numbers to represent different things about the text? HOW TO ANALYZE THE NUMERICAL REPRESENTATION? How do I extract meaning out of the numerical representation? Representing text numerically. Document term matrix. The document term matrix (DTM) is a common method for representing text. The DTM is a matrix. Each row of this matrix corresponds to a document; each column corresponds to a word. It is often useful to look at summary statistics such as the percentage of speaches in which a Democratic lawmaker used the word “inequality” compared to a Republican; the DTM would be very helpful for this and other tasks. doc1 &lt;- &quot;Rage---Goddess, sing the rage of Peleus’ son Achilles, murderous, doomed, that cost the Achaeans countless losses, hurling down to the House of Death so many sturdy souls, great fighters’ souls.&quot; doc2 &lt;- &quot;And fate? No one alive has ever escaped it, neither brave man nor coward, I tell you, it&#39;s born with us the day that we are born.&quot; doc3 &lt;- &quot;Many cities of men he saw and learned their minds, many pains he suffered, heartsick on the open sea, fighting to save his life and bring his comrades home.&quot; DocVec &lt;- c(doc1, doc2, doc3) Now we can use utility functions in the tm package: library(tm) DocCorpus &lt;- Corpus(VectorSource(DocVec) ) DTM1 &lt;- inspect( DocumentTermMatrix(DocCorpus) ) # Consider the effect of different &quot;pre-processing&quot; choices on the resulting DTM! DocVec &lt;- tolower(DocVec) DocVec &lt;- gsub(DocVec, pattern =&quot;[[:punct:]]&quot;, replace = &quot; &quot;) DocVec &lt;- gsub(DocVec, pattern =&quot;[[:cntrl:]]&quot;, replace = &quot; &quot;) DocCorpus &lt;- Corpus(VectorSource(DocVec) ) DTM2 &lt;- inspect(DocumentTermMatrix(DocCorpus, control = list(stopwords = TRUE, stemming = TRUE))) Stemming is the process of reducing inflected/derived words to their word stem or base (e.g. stemming, stemmed, stemmer –&gt; stem*) 10.8 Important packages for parsing text rvest – Useful for downloading and manipulating HTML and XM. tm – Useful for converting text into a numerical representation (forming DTMs). stringr – Useful for string parsing. 10.9 Exercises to check your understanding! 10.9.1 1 Figure out why this command does what it does: sprintf(&quot;%s of spontaneous events are %s in the mind. Really, %.2f?&quot;, &quot;15.03322123&quot;, &quot;puzzles&quot;, 15.03322123) ## [1] &quot;15.03322123 of spontaneous events are puzzles in the mind. \\n Really, 15.03?&quot; 10.9.2 2 Why does this command not work? try(sprintf(&quot;%s of spontaneous events are %s in the mind. Really, %.2f?&quot;, &quot;15.03322123&quot;, &quot;puzzles&quot;, &quot;15.03322123&quot; ), T) 10.9.3 3 Using grepl, these materials, Google, and your friends, describe what the following command does. What changes when value = FALSE? grep(&#39;\\&#39;&#39;,c(&quot;To dare is to lose one&#39;s footing momentarily.&quot;, &quot;To not dare is to lose oneself.&quot;), value = TRUE) ## [1] &quot;To dare is to lose one&#39;s footing momentarily.&quot; 10.9.4 4 Write code to automatically extract the file names that DO end start with presidential and DO end in .pdf my_string &lt;- c(&quot;legislative1_term1.png&quot;, &quot;legislative1_term1.pdf&quot;, &quot;legislative1_term2.png&quot;, &quot;legislative1_term2.pdf&quot;, &quot;term2_presidential1.png&quot;, &quot;presidential1.png&quot;, &quot;presidential1_term2.png&quot;, &quot;presidential1_term1.pdf&quot;, &quot;presidential1_term2.pdf&quot;) 10.9.5 5 Using the same string as in the above, write code to automatically extract the file names that end in .pdf and that contain the text term2. # Your code here 10.9.6 6 Combine these two strings into a single string separated by a “-”. Desired output: “The carbonyl group in aldehydes and ketones is an oxygen analog of the carbon–carbon double bond.” string1 &lt;- &quot;The carbonyl group in aldehydes and ketones is an oxygen analog of the carbon&quot; string2 &lt;- &quot;–carbon double bond.&quot; 10.9.7 7 Challenge problem! Download this webpage https://en.wikipedia.org/wiki/Odyssey Read the html file into your R workspace. Remove all of the htlm tags (you may need Google to help with this one). Remove all punctuation. Make all the characters lower case. Do this same process with this webpage (https://en.wikipedia.org/wiki/Iliad). Form a document term matrix from the two resulting text strings. # Your code here "],
["simulation.html", "Chapter 11 Simulation 11.1 Where are we? Where are we headed? 11.2 Preview! 11.3 Motivation 11.4 Key functions 11.5 sample() 11.6 rbinom() 11.7 runif() 11.8 rnorm() 11.9 set.seed() 11.10 Anything else? Specific questions? General questions? 11.11 Exercises", " Chapter 11 Simulation Module originally written by Connor Jerzak and Shiro Kuriwaki library(readr) library(scales) library(forcats) library(ggplot2) 11.1 Where are we? Where are we headed? Up till now, you should have covered: R basics Wrangling with real data Visualization In this module, we will start to work with generating data within R, from thin air, as it were. This branch of statistics is grouped as “simulation”, and it is becoming increasing relevant and useful for empirical social sciece researchers, not just statisticians. 11.2 Preview! Check if you have an idea of how you might code the following tasks: Simulate 100 rolls of a die Simulate one random ordering of 25 numbers Simulate 100 valus of white noise (uniform random variables) Generate a “bootstrap” sample of an existing dataset We’re going to learn about this today! 11.3 Motivation An increasing amount of political science contributions now include a simulation. Axelrod (1977) demonstrated via simulation how atomized individuals evolve to be grouped in similar clusters or countries, a model of culture11. Chen and Rodden (2013) argued in a 2013 article that the vote-seat inequality in U.S. elections that is often attributed to intentional partisan gerrymandering can actually attributed to simply the reality of “human geography” – Democratic voters tend to be concentrated in smaller area. Put another way, no feasible form of gerrymandering could spread out Democratic voters in such a way to equalize their vote-seat translation effectiveness. After demonstraing the empirical pattern of human geography, they advance their key claim by simulating thousands of redistricting plans and record the vote-seat ratio12. Gary King, James Honaker, and multiple other authors propose a way to analyze missing data with a method of multiple imputation, which uses a lot of simulation from a researcher’s observed dataset13 (Software: Amelia14). Statistical methods also incorporate simulation: 1. The bootstrap: a statistical method for estimating uncertainty around some parameter by re-sampling observations. 2. Bagging: a method for improving machine learning predictions by re-sampling observations, storing the estimate across many re-samples, and averaging these estimates to form the final estimate. A variance reduction technique. 3. Statistical reasoning: if you are trying to understand a quantitative problem, a wonderful first-step to understand the problem better is to simulate it! The analytical solution is often very hard (or impossible), but the simulation is often much easier :-) 11.4 Key functions The core functions for coding up stochastic data revolves around several key functions, so we will simply review them here. 11.5 sample() Suppose you have a vector of values x and from it you want to randomly sample a sample of length size. For this, use the sample function sample(x = 1:10, size = 5) ## [1] 6 5 9 2 10 There are two subtypes of sampling – with and without replacement. help(sample) ## Help on topic &#39;sample&#39; was found in the following packages: ## ## Package Library ## dplyr /Library/Frameworks/R.framework/Versions/3.5/Resources/library ## base /Library/Frameworks/R.framework/Resources/library ## ## ## Using the first match ... Sampling without replacement (replace = FALSE) means once an element of x is chosen, it will not be considered again: sample(x = 1:10, size = 10, replace = FALSE) ## no number appears more than once ## [1] 1 9 2 7 3 6 4 5 10 8 Sampling with repalcement (replace = TRUE) means that even if an element of x is chosen, it is put back in the pool and may be chosen again. sample(x = 1:10, size = 10, replace = TRUE) ## any number can appear more than once ## [1] 1 2 8 3 8 9 10 6 3 4 It follows than that you cannot sample without replacement a sample that is larger than the pool. sample(x = 1:10, size = 100, replace = FALSE) ## Error in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when &#39;replace = FALSE&#39; So far, every element in x has had an equal probability of being chosen. In some application, we want a sampling scheme where some elements are more likely to be chosen than others. The argument prob handles this. For example, this simulates 20 fair coin tosses (each outcome is equally likely to happen) sample(c(&quot;Head&quot;, &quot;Tail&quot;), size = 20, prob = c(0.5, 0.5), replace = TRUE) ## [1] &quot;Head&quot; &quot;Head&quot; &quot;Head&quot; &quot;Tail&quot; &quot;Head&quot; &quot;Head&quot; &quot;Head&quot; &quot;Tail&quot; &quot;Tail&quot; &quot;Tail&quot; ## [11] &quot;Tail&quot; &quot;Head&quot; &quot;Head&quot; &quot;Head&quot; &quot;Tail&quot; &quot;Head&quot; &quot;Head&quot; &quot;Head&quot; &quot;Head&quot; &quot;Head&quot; But this simulates 20 biased coin tosses, where say the probability of Tails is 4 times more likely than the number of Heads sample(c(&quot;Head&quot;, &quot;Tail&quot;), size = 20, prob = c(0.2, 0.8), replace = TRUE) ## [1] &quot;Tail&quot; &quot;Tail&quot; &quot;Tail&quot; &quot;Tail&quot; &quot;Tail&quot; &quot;Head&quot; &quot;Tail&quot; &quot;Tail&quot; &quot;Tail&quot; &quot;Tail&quot; ## [11] &quot;Tail&quot; &quot;Head&quot; &quot;Tail&quot; &quot;Tail&quot; &quot;Tail&quot; &quot;Tail&quot; &quot;Tail&quot; &quot;Tail&quot; &quot;Tail&quot; &quot;Tail&quot; 11.6 rbinom() rbinom builds upon sample as a tool to help you answer the question – what is the total number of successes I would get if I ran sampled a binary (bernoulli) result from a pool of size size, with a event-wise probability of prob, with n number of trials? For example, I want to know how many Heads I would get if I flipped a fair coin 100 times. rbinom(n = 1, size = 100, prob = 0.5) ## [1] 40 Now imagine this I wanted to do this experiment 10 times, which would require I flip the coin 10 x 100 = 1000 times! Helpfully, we can do this in one line rbinom(n = 10, size = 100, prob = 0.5) ## [1] 51 46 50 42 44 50 44 57 52 49 11.7 runif() runif also simulates a stochastic scheme where each event has equal probability of getting chosen like sample, but is a continuous rather than discrete system. We will cover this more in the next math module. The intuition to emphasize here is that one can generate potentially infinite amounts (size n) of noise that is a essentially random runif(n = 5) ## [1] 0.9394177 0.0527925 0.1828390 0.8083526 0.8080019 11.8 rnorm() rnorm is also a continous distribution, but draws from a Normal distribution – perhaps the most important distribution in statistics. It runs the same way as runif rnorm(n = 5) ## [1] 1.43573620 0.96756539 -0.07233411 0.41887767 -1.33971215 To better visualize the difference between the output of runif and rnorm, let’s generate lots of each and plot a histogram. from_runif &lt;- runif(n = 1000) from_rnorm &lt;- rnorm(n = 1000) par(mfrow = c(1, 2)) ## two plots at once hist(from_runif) hist(from_rnorm) 11.9 set.seed() R doesn’t have the ability to generate truly random numbers! Random numbers are actually very hard to generate. (Think: flipping a coin –&gt; can be perfectly predicted if I know windspeed, the angle the coin is flipped, etc.). Some people use random noise in the atmosphere or random behavior in quantuum systems to generate “truly” (?) random numbers. Convserely, R uses deterministic algorithms which take as an input a “seed” and which then perform a series of operations to generate a sequence of random-seeming numbers (that is, numbers whose sequence is sufficiently hard to predict). Let’s think about this another way. Sampling is a stochastic process, so every time you run sample() or runif() you are bound to get a different output (because different random seeds are used). This is intenional in some cases but you might want to avoid it in others. For example, you might want to diagnose a coding discrepancy by setting the random number generator to give the same number each time. To do this, use the function set.seed(). In the function goes any number. When you run a sample function in the same command as a preceding set.seed(), the sampling function will always give you the same sequence of numbers. In a sense, the sampler is no longer random (in the sense of unpredictable to use; remember: it never was “truly” random in the first place) set.seed(02138) runif(n = 5) ## [1] 0.5123614 0.6153055 0.3745144 0.4354126 0.2116653 ## exact same output long as you preced the function by the same seed, set.seed(02138) runif(n = 5) ## [1] 0.5123614 0.6153055 0.3745144 0.4354126 0.2116653 A true random number generator would give you the exact same sequence of output with probability 0! runif(n = 5) ## [1] 0.17812129 0.04420775 0.45567854 0.88718264 0.06970056 11.10 Anything else? Specific questions? General questions? :-) 11.11 Exercises 11.11.1 The Birthday problem Write code that will answer the well-known birthday probelm via simulation15. The problem is fairly simple: Suppose \\(k\\) people gather together in a room. What is the probability at least two people share the same birthday? To simplify reality a bit, assume that (1) there are no leap years, and so there are always 365 days in a year, and (2) a given individual’s birthday is randomly assigned and independent from each other. Step 1: Set k to a concrete number. Pick a number from 1 to 365 randomly, k times to simulate birthdays (would this be with replacement or without?). # Your code Step 2: Write a line (or two) of code that gives a TRUE or FALSE statement of whether or not at least two people share the same birthdate. # Your code Step 3: The above steps will generate a TRUE or FALSE answer for your event of interest, but only for one realization of an event in the sample space. In order to estimate the probability of your event happening, we need a “stochastic”, as opposed to “deterministic”, method. To do this, write a loop that does Steps 1 and 2 repeatedly for many times, call that number of times sims. For each of sims iteration, your code should give you a TRUE or FALSE answer. Code up a way to store these estimates. # Your code Step 4: Finally, generalize the function further by letting k be a user-defined number. You have now created a Monte Carlo simulation! # Your code Step 5: Generate a table or plot that shows how the probability of sharing a birthday changes by k (fixing sims at a large number like 1000). Also generate a similar plot that shows how the probability of sharing a birthday changes by sims (fixing k at some arbitrary number like 10). # Your code Extra credit: Give an “analtyical” answer to this problem, that is an answer through deriving the mathematical expressions of the probability. # Your equations 11.11.2 The Monty Hall problem The Monty Hall problem is a counterintuitive example demonstrating the importance of conditional probability that also shows up in most probability textbooks. The original formulation of the problem appeared on a magazine column in 1990 “Suppose you’re on a game show, and you’re given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what’s behind the doors, opens another door, say No. 3, which has a goat. He then says to you, ‘Do you want to pick door No. 2?’ Is it to your advantage to switch your choice?” https://en.wikipedia.org/wiki/Monty_Hall_problem Give an answer to this question by a Monte Carlo simulation. As in the previous expample, set a number sims for the number of simulations you will run. The key difference in this problem is to record the outcome (whether you won or lost) for two counterfactuals at any given simulation. That is, record the result for two cases: when you switched given the host’s advice or did not switch. Comparing the average success rates of each of the two choices will provide a simulation-based answer to the Monty Hall problem. # Your code A model answer (there are many correct answers) is given in Imai (2017), p.26516 Axelrod, Robert. 1997. “The Dissemination of Culture.” Journal of Conflict Resolution 41(2): 203–26.↩ Chen, Jowei, and Jonathan Rodden. “Unintentional Gerrymandering: Political Geography and Electoral Bias in Legislatures. Quarterly Journal of Political Science, 8:239-269”↩ King, Gary, et al. “Analyzing Incomplete Political Science Data: An Alternative Algorithm for Multiple Imputation”. American Political Science Review, 95: 49-69.↩ James Honaker, Gary King, Matthew Blackwell (2011). Amelia II: A Program for Missing Data. Journal of Statistical Software, 45(7), 1-47.↩ This exercise draws from Imai (2017)↩ with a slight robustness addition here↩ "],
["command-line-markdown-latex-git.html", "Chapter 12 command-line, markdown, LaTeX, git 12.1 Where are we? Where are we headed? 12.2 Check your understanding 12.3 Motivation 12.4 command-line 12.5 Markdown 12.6 LaTeX 12.7 BibTeX 12.8 git 12.9 Concluding PreFresher", " Chapter 12 command-line, markdown, LaTeX, git Module originally written by Shiro Kuriwaki 12.1 Where are we? Where are we headed? Up till now, you should have covered: Statistical Programming in R This is only the beginning of R – programming is like learning a language, so learn more as we use it. Today we will take a quick look at some other software / languages that many of us will end up using. command-line Markdown LaTeX (and BibTeX) git command-line are a basic set of tools that you may have to use from time to time. It also clarifies what more complicated programs are doing. Markdown is an example of compiling a plain text file. LaTeX is a typesetting program and git is a version control program – both are useful for non-quantitative work as well. 12.2 Check your understanding Check if you have an idea of how you might code the following tasks: What does “WYSIWYG” stand for? How would a non-WYSIWYG format text? What is a GUI? What do the following commands stand for in shell: ls (or dir in Windows), cd, rm, mv (or move in windows), cp (or copy in Windows). What is the difference between a relative path and an absolute path? What paths do these refer to in shell/terminal: ~/, ., .. How do you start a header in markdown? What are some “plain text” editors? How do you start a document in .tex? How do you start a environment in .tex? How do you insert a figure in .tex? How do you reference a figure in .tex? What is a .bib file? Say you came across a interesting journal article. How would you want to maintain this reference so that you can refer to its citation in all your subsequent papers? What is a repository in github? What does it mean to “clone” a repository? 12.3 Motivation Statistical programming is a fast-moving field. The beta version of R was released in 2000, ggplot2 was released on 2005, and RStudio started around 2010. Of course, some programming technologies are quite “old”: (C in 1969, C++ around 1989, TeX in 1978, Linux in 1991, Mac OS in 1984). But it is easy to feel you are falling behind in the recent developments of programming. Today we will do a brief and rough overview of some fundamental and new tools other than R, with the general aim of having you break out of your comfort zone so you won’t be shut out from learning these tools in the future. 12.4 command-line Elementary programming operations are done on the command-line, or by entering commands into your computer. This is different from a UI or GUI – graphical user-interface – which are interfaces that allow you to click buttons and enter commands in more readable form. Although there are good enough GUIs for most of your needs, you still might need to go under the hood sometimes and run a command. 12.4.1 command-line commands Open up Terminal in a Mac. (Command Prompt in Windows) Running this command in a Mac (dir in Windows) should show you a list of all files in the directory that you are currently in. ls ## 01_warmup.Rmd ## 02_linear-algebra.Rmd ## 03_functions.Rmd ## 04_calculus-01.Rmd ## 05_optimization.Rmd ## 06_probability.Rmd ## 11_counting-census.Rmd ## 12_matricies-manipulation.Rmd ## 13_project-dempeace.Rmd ## 14_text.Rmd ## 15_simulation.Rmd ## 16_latex-other-tools.Rmd ## 91-references.Rmd ## README.md ## RMarkdownFlow.png ## _book ## _bookdown.yml ## _bookdown_files ## _output.yml ## biblatex_bibliography.png ## biblatex_inline.png ## book.bib ## dplyr-joins.png ## index.Rmd ## input ## nunn_wantchekon_table1.png ## packages.bib ## preamble.tex ## prefresher.Rmd ## prefresher.Rproj ## prefresher.aux ## prefresher.bbl ## prefresher.blg ## prefresher.out ## prefresher.toc ## prefresher_files ## rsconnect ## sample_library.bib ## style.css pwd stands for present working directory (cd in Windows) pwd ## /Users/shirokuriwaki/Dropbox/prefresher cd means change directory. You need to give it what to change your current directory to. You can specify a name of another directory in your directory. Or you can go up to your parent directory. The syntax for that are two periods, .. . One period . refers to the current directory. cd .. pwd ## /Users/shirokuriwaki/Dropbox ~/ stands for your home directory defined by your computer. cd ~/ ls ## Applications ## Desktop ## Documents ## Downloads ## Dropbox ## Google Drive File Stream ## Library ## Movies ## Music ## PaladinTemp ## Pictures ## Public ## Untitled.ipynb Using .. and . are “relative” to where you are currently at. So are things like figures/figure1.pdf, which is implicitly writing ./figures/figure1.pdf. These are called relative paths. In contrast, /Users/shirokuriwaki/project1/figures/figure1.pdf is an “absolute” path because it does not start from your current directory. Relative paths are nice if you have a shared Dropbox, for example, and I had /Users/shirokuriwaki/mathcamp but Connor’s path to the same folder is /Users/connorjerzak/mathcamp. To run the same code in mathcamp, we should be using relative paths that start from “mathcamp”. Relative paths are also shorter, and they are invariant to higher-level changes in your computer. 12.4.2 running things via command-line Suppose you have a simple Rscript, call it hello_world.R. This is simply a plain text file that contains cat(&quot;Hello World&quot;) Then in command-line, go to the directory that contains hello_world.R and enter Rscript hello_world.R This should give you the output Hello World, which verifies that you “executed” the file with R via the command-line. 12.4.3 why do command-line? If you know exactly what you want to do your files and the changes are local, then command-line might be faster and be more sensible than navigating yourself through a GUI. For example, what if you wanted a single command that will run 10 R scripts successively at once (as Gentzkow and Shapiro suggest you should do in your research)? It is tedious to run each of your scripts on Rstudio, especially if running some take more than a few minutes. Instead you could write a “batch” script that you can run on the terminal, Rscript 01_read_data.R Rscript 02_merge_data.R Rscript 03_run_regressions.R Rscript 04_make_graphs.R Rscript 05_maketable.R Then run this single file, call it run_all_Rscripts.sh, on your terminal as sh run_all_Rscripts.sh On the other hand, command-line prompts may require more keystrokes, and is also less intuitive than a good GUI. It can also be dangerous for beginners, because it can allow you to make large irreversible changes inadvertently. For example, removing a file (rm) has no “Undo” feature. 12.5 Markdown Markdown is the text we have been using throughout this course! At its core markdown is just plain text. Plain text does not have any formatting embedded in it. Instead, the formatting is coded up as text. Markdown is not a WYSIWYG (What you see is what you get) text editor like Microsoft Word or Google Docs. This will mean that you need to explicitly code for bold{text} rather than hitting Command+B and making your text look bold on your own computer. Markdown is known as a “light-weight” editor, which means that it is relatively easy to write code that will compile. It is quick and easy and satisfies most presentation purposes; you might want to try LaTeX for more involved papers. 12.5.1 markdown commands For italic and bold, use either the asterisks or the underlines, *italic* **bold** _italic_ __bold__ And for headers use the hash symbols, # Main Header ## Sub-headers 12.5.2 your own markdown RStudio makes it easy to compile your very first markdown file by giving you templates. Got to New &gt; R Markdown, pick a document and click Ok. This will give you a skeleton of a document you can compile – or “knit”. Rmd is actually a slight modification of real markdown. It is a type of file that R reads and turns into a proper md file. Then, it uses a document-conversion called pandoc to compile your md into documents like PDF or HTML. One of the things Rmds facilitates is the use of code chunks, which you have all been using. These start and end with three back-ticks. In the beginning, we can add options in curly braces ({}). Specifying r in the beginning tells the compiler that this is meant to be R code. Options like echo = TRUE or eval = FALSE switch between not executing the code (i.e., just showing it for display), or executing the code but not showing the code that was executed (if you think it is distracting). 12.5.3 A note on plain-text editors Multiple software exist where you can edit plain-text (roughly speaking, text that is not WYSIWYG). RStudio (especially for R-related links) TeXMaker, TeXShop (especially for TeX) emacs, aquamacs (general) vim (general) Sublime Text (general) Each has their own keyboard shortcuts and special features. You can browse a couple and see which one(s) you like. 12.6 LaTeX LaTeX is a typesetting program. You’d engage with LaTeX much like you engage with your R code. You will interact with LaTeX in a text editor, and will writing code which will be interpreted by the LaTeX compiler and which will finally be parsed to form your final PDF. 12.6.1 compile your first LaTeX document. LaTeX is a very stable system, and few changes to it have been made since the 1990s. The main benefit: better control over how your papers will look; better methods for writing equations or making tables; overall pleasing aesthetic. Open a plain text editor. Then type in this. \\documentclass{article} \\begin{document} Hello World \\end{document} Save this as hello_world.tex. Make sure you get the file extension right. Open this in your “LaTeX” editor. This can be TeXMaker, Aqumacs, etc.. Go through the click/dropdown interface and click compile. 12.6.2 main LaTeX commands LaTeX can cover most of your typesetting needs, to clean equations and intricate diagrams. Some main commands you’ll be using: Most involved features require that you begin a specific “environment” for that feature, clearly demarcating them by the notation \\begin{figure} and then \\end{figure}, e.g. in the case of figures. \\begin{figure} \\includegraphics{histogram.pdf} \\end{figure} where histogram.pdf is a path to one of your files. Notice that each line starts with a backslash \\ – in LaTeX this is the symbol to run a command. The following syntax at the endpoints are shorthand for math equations. $$\\int x^2 dx$$ \\[\\int x^2 dx\\] both of these compile math symbols: \\(\\displaystyle \\int x^2 dx.\\) The align environment is useful to align your multi-line math, for example. \\begin{align} P(A \\mid B) &amp;= \\frac{P(A \\cap B)}{P(B)}\\\\ &amp;= \\frac{P(B \\mid A)P(A)}{P(B)} \\end{align} \\[\\begin{align} P(A \\mid B) &amp;= \\frac{P(A \\cap B)}{P(B)}\\\\ &amp;= \\frac{P(B \\mid A)P(A)}{P(B)} \\end{align}\\] Regression tables should be outputted as .tex files with packages like xtable and stargzer, and then called into LaTeX by \\input{regression_table.tex} where regression_table.tex is the path to your regression output. Figures and equations should be labelled with the tag (e.g. label{tab:regression} so that you can refer to them later with their tag Table \\ref{tab:regression}, instead of hard-coding Table 2). For some LaTeX commands you might need to load a separate package that someone else has written. Do this in your preamble (i.e. before \\begin{document}): \\usepackage[options]{package} where package is the name of the package and options are options specific to the package. 12.6.3 more Commands For a more comprehensive listing of LaTeX commands, Mayya Komisarchik (prefresher instructor from 2015-2016) has a great tutorial set of folders that you can download from your website: https://scholar.harvard.edu/mkomisarchik/tutorials-0 There is a version of LaTeX called Beamer, which is a popular way of making a slideshow. Slides in markdown is also a competitor. The language of Beamer is the same as LaTeX but has some special functions for slides. 12.7 BibTeX BibTeX is a reference system for bibliographical tests. We have a .bib file separately on our computer. This is also a plain text file, but it encodes bibliographical resources with special syntax so that a program can rearrange parts accordingly for different citation systems. 12.7.1 what is a .bib file? For example, here is the Nunn and Wantchekon article entry in .bib form. @article{nunn2011slave, title={The Slave Trade and the Origins of Mistrust in Africa}, author={Nunn, Nathan and Wantchekon, Leonard}, journal={American Economic Review}, volume={101}, number={7}, pages={3221--3252}, year={2011} } The first entry, nunn2011slave, is “pick your favorite” – pick your own name for your reference system. The other slots in this @article entry are entries that refer to specific bibliographical text. 12.7.2 what does LaTeX do with .bib files? Now, in LaTeX, if you type \\textcite{nunn2011slave} argue that current variation in the trust among citizens of African countries has historical roots in the European slave trade in the 1600s. as part of your text, then when the .tex file is compiled the PDF shows something like in whatever citation style (APSA, APA, Chicago) you pre-specified! Also at the end of your paper you will have a bibliography with entries ordered and formatted in the appropriate citation. This is a much less frustrating way of keeping track of your references – no need to hand-edit formatting the bibliography to conform to citation rules (which biblatex already knows) and no need to update your bibliography as you add and drop references (biblatex will only show entries that are used in the main text). 12.7.3 stocking up on your .bib files You should keep your own .bib file that has all your bibliographical resources. Storing entries is cheap (does not take much memory), so it is fine to keep all your references in one place (but you’ll want to make a new one for collaborative projects where multiple people will compile a .tex file). For example, Gary’s BibTeX file is here: https://github.com/iqss-research/gkbibtex/blob/master/gk.bib Citation management software (Mendeley or Zotero) automatically generates .bib entries from your library of PDFs for you, provided you have the bibliography attributes right. 12.8 git Git is a tool for version control. It comes pre-installed on Macs, you will probably need to install it yourself on Windows. 12.8.1 why version control? All version control software should be built to preserve all snapshots of your work and catalog them in such a way that you can refer back or even revert back your files to the past snapshot. makes it easy to see exactly which parts of your files you changed between directories. Further, git is most commonly used for collaborative work. maintains “branches”, or parallel universes of your files that people can switch back and forth on, doing version control on each one makes it easy to “merge” a sub-branch to a master branch when it is ready. Note that Dropbox is useful for collaborative work too. But the added value of git’s branches is that people can make different changes simultaneously on their computers and merge them to the master branch later. In Dropbox, there is only one copy of each thing so simultaneous editing is not possible. 12.8.2 open-source code at your fingertips Some links to check out: https://github.com/tidyverse/dplyr https://github.com/apple/swift https://github.com/kosukeimai/qss GitHub https://github.com is the GUI to git. Making an account there is free. Making an account will allow you to be a part of the collaborative programming community. It will also allow you to “fork” other people’s “repositories”. “Forking” is making your own copy of the project that forks off from the master project at a point in time. A “repository” is simply the name of your main project directory. “cloning” someone else’s repository is similar to forking – it gives you your own copy. 12.8.3 commands in git As you might have noticed from all the quoted terms, git uses a lot of its own terms that are not intuitive and hard to remember at first. The nuts and bolts of maintaining your version control further requires “adding”, “committing”, and “push”ing, sometimes “pull”ing. The tutorial https://try.github.io/ is quite good. You’d want to have familiarity with command-line to fully understand this and use it in your work. RStudio Projects has a great git GUI as well. 12.8.4 is git worth it? While git is a powerful tool, you may choose to not use it for everything because git is mainly for code, not data. It has a fairly strict limit on the size of your dataset that you cover. your collaborators might want to work with Dropbox unless you get a paid account, all your repositories will be public. 12.9 Concluding PreFresher Keep on learning, trying new techniques to improve your work, and learn from others! August 18, 2017 12.9.1 please tell us how we can improve the PreFresher The PreFresher is a work in progress, with material mainly driven by graduate students. Please tell us how we should change (or not change) each of its elements: https://harvard.az1.qualtrics.com/jfe/form/SV_9moFLOtHV7lkNhz "],
["references.html", "References", " References "]
]
