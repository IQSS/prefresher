# Calculus {#derivatives}

__Topics__: 
 Sequences;
 Limit of a Sequence;
 Series;
 Derivatives;
 Higher-Order Derivatives;
 Composite Functions and The Chain Rule;
 Derivatives of Exp and Ln;
 Maxima and Minima;
 Partial Derivatives;
 L'H\^opital's Rule;
 Taylor Approximation;
 Derivative Calculus in 6 Steps;
The Indefinite Integral: The Antiderivative;
 Common Rules of Integration;
 The Definite Integral: The Area under the Curve;
 Integration by Substitution;
 Integration by Parts
 

 Much of the material and examples for this lecture are taken from Simon \& Blume (1994) \emph{Mathematics for Economists} and from Boyce \& Diprima (1988) \emph{Calculus}



## Derivatives {#derivintro}

The derivative of $f$ at $x$ is its rate of change at $x$ --- i.e., how much $f(x)$ changes with a change in $x$.

* For a line, the derivative is the slope.
* For a curve, the derivative is the slope of the line tangent to the curve at $x$.


\textbf{Derivative}:  Let $f$ be a function whose domain includes an open interval containing the point $x$.  The derivative of $f$ at $x$ is given by

\begin{eqnarray}
		f'(x) &=&\lim\limits_{h\to 0} \frac{f(x+h)-f(x)}{(x+h)-x}\nonumber\\
		&=&\lim\limits_{h\to 0} \frac{f(x+h)-f(x)}{h}\nonumber
\end{eqnarray}


If $f'(x)$ exists at a point $x$, then $f$ is said to be __differentiable__ at $x$.  Similarly, if $f'(x)$ exists for every point a long an interval, then $f$ is differentiable along that interval.  For $f$ to be differentiable at $x$, $f$ must be both continuous and "smooth'' at $x$.  The process of calculating $f'(x)$ is called __differentiation__.

__Notation for derivatives:__


Prime or Lagrange Notation: $y'$, $f'(x)$
Leibniz's Notation: $\frac{dy}{dx}$, $\frac{df}{dx}(x)$
Operator Notation: $Dy$, $Df(x)$


\underline{Properties of derivatives:}  Suppose that $f$ and $g$ are differentiable at $x$ and that $\alpha$ is a constant.  Then the functions $f\pm g$, $\alpha f$, $f g$, and $f/g$ (provided $g(x)\ne 0$) are also differentiable at $x$.  Additionally,

1. __Power rule:__ $[x^k]' = k x^{k-1}$  
2. __Sum rule:__ $[f(x)\pm g(x)]' = f'(x)\pm g'(x)$ 
3. __Constant rule:__ $[\alpha f(x)]' = \alpha f'(x)$ 
4. __Product rule:__ $[f(x)g(x)]' = f'(x)g(x)+f(x)g'(x)$
5. __Quotient rule:__ $[f(x)/g(x)]' = \frac{f'(x)g(x)-f(x)g'(x)}{[g(x)]^2}$, $g(x)\ne 0$
	

```{exercise, name="Derivative of Polynomials"} 

Express the following derivatives. 


Let $f(x)=c$, then $f^\prime(x)=$

Let $f(x)=x$, then $f^\prime(x)=$
  
Let $f(x)=x^2$, then  $f^\prime(x)=$

Let $f(x)=x^3$, then $f^\prime(x)=$

Let $f(x) = 3x^2 + 2x^{1/3}$, then $f^\prime(x)=$
  
Let $f(x)=(x^3)(2x^4)$, then  $f^\prime(x)=$

Let \[f(x)=\frac{x^2+1}{x^2-1}\], then $f^\prime(x)=$
```

## Higher-Order Derivatives or, Derivatives of Derivatives of Derivatives {#derivpoly}


We can keep applying the differentiation process to functions that are themselves derivatives.  The derivative of $f'(x)$ with respect to $x$, would then be $$f''(x)=\lim\limits_{h\to 0}\frac{f'(x+h)-f'(x)}{h}$$ and so on.  Similarly, the derivative of $f''(x)$ would be denoted $f'''(x)$.

__First derivative:__ $f'(x)$, $y'$, $\frac{df(x)}{dx}$, $\frac{dy}{dx}$

__Second derivative:__ $f''(x)$, $y''$, $\frac{d^2f(x)}{dx^2}$, $\frac{d^2y}{dx^2}$

__nth derivative: __  $\frac{d^nf(x)}{dx^n}$, $\frac{d^ny}{dx^n}$

```{example, name="Succession of Derivatives"}
\begin{align*}
f(x) &=x^3\\
f^{\prime}(x) &=3x^2\\
f^{\prime\prime}(x) &=6x \\
f^{\prime\prime\prime}(x) &=6\\
f^{\prime\prime\prime\prime}(x) &=0\\
\end{align*}
```


## Composite Functions and the Chain Rule
__Composite functions__ are formed by substituting one function into another and are denoted by \[(f\circ g)(x)=f[g(x)]\]  To form $f[g(x)]$, the range of $g$ must be contained (at least in part) within the domain of $f$. The domain of $f\circ g$ consists of all the points in the domain of $g$ for which $g(x)$ is in the domain of $f$.

```{example}
Ket $f(x)=\ln x$ for  $0<x<\infty$ and  $g(x)=x^2$ for $-\infty<x<\infty$.

Then 
\[(f\circ g)(x)=\ln x^2, -\infty<x<\infty - \{0\}\]

Also 
\[(g\circ f)(x)=[\ln x]^2, 0<x<\infty\]

Notice that $f\circ g$ and $g\circ f$ are not the same functions.
```

```{example}
Let $f(x)=4+\sin x$ for all real $x$ and $g(x)=\sqrt{1-x^2}$ for $-1 \leq x \le 1$}.

Then 
\[(f\circ g)(x)=4+\sin \sqrt{1-x^2}, -1 \leq x \leq 1\]

Also 
\[(g\circ f)(x)\]
does _not_ exist. $\sqrt{1-(4+\sin(x))^2}$ is not a real number because $1-(4+\sin(x))^2$ is always negative.
```


__Chain Rule__:  Let $y=(f\circ g)(x)= f[g(x)]$. The derivative of $y$ with respect to $x$ is \[\frac{d}{dx} \{ f[g(x)] \} = f'[g(x)] g'(x)\] which can also be written as \[\frac{dy}{dx}=\frac{dy}{dg(x)} \frac{dg(x)}{dx}\] (Note: the above does not imply that the $dg(x)$'s cancel out, as in fractions.  They are part of the derivative notation and you can't separate them out or cancel them.)

The chain rule can be thought of as the derivative of the "outside" times the derivative of the "inside", remembering that the derivative of the outside function is evaluated at the value of the inside function.
	
	

__Generalized Power Rule__:  If $f(x)=[g(x)]^k$, then $f^\prime(x) =k[g(x)]^{k-1}g^\prime(x)$.


```{example}
Find $f^\prime(x)$ for $f(x) = (3x^2+5x-7)^6$.

Approach: Let $f(z)=z^6$ and $z=g(x)=3x^2+5x-7$.  Then, $y=f[g(x)]$ and

\begin{align*}
\frac{dy}{dx}&=\\
\end{align*}
```



## Derivatives of Euler's number and natural logs

__Derivatives of natural exponential function ($e$)__:


1. Derivative of $e^x$ is itself: $\frac{d}{dx}e^x = e^x$
2. Same thing if there were a constant in front: $\frac{d}{dx}\alpha e^x = \alpha e^x$
3. Same thing no matter how many derivatives there are in front: $\frac{d^n}{dx^n} \alpha e^x = \alpha e^x$
4. Chain Rule: When the exponent is a function of $x$, remember to take derivative of that function and add to product. $\frac{d}{dx}e^{u(x)}= e^{u(x)} u^\prime(x)$


```{example, name="Derivative of exponents"}
Find $dy/dx$ for the following.

1. $y=e^{-3x}$

     Let $u(x)=-3x$.  Then $u^\prime(x)=-3$ and $dy/dx=-3e^{-3x}$. 

2. $y=e^{x^2}$
  
   Let $u(x)=x^2$.  Then $u^\prime(x)=2x$ and $dy/dx=2xe^{x^2}$.

3. $y=e^{\sin 2x}$
  
   Let $u(x)=\sin 2x$.  Then $u^\prime(x) = 2\cos 2x$ and $dy/dx=(2\cos 2x) e^{\sin 2x}$
  
  
```


__Derivatives of___ $\log$

The natural log $\log$ (also written as $\ln$ to distinguish it from logarithms of diffferent bases) is the mirror image of the natural exponent and has mirroring properties.

1. log prime x is one over x: $\frac{d}{dx} \ln x = \frac{1}{x}$
2. Exponents become multiplicative constants: $\frac{d}{dx} \ln x^k = \frac{d}{dx} k \ln x = \frac{k}{x}$
3. Chain rule again: $\frac{d}{dx} \ln u(x) = \frac{u'(x)}{u(x)}\quad$
4. For any positive base $b$, $\frac{d}{dx} b^x = (\ln b)\left(b^x\right)$.


Examples:  Find $dy/dx$ for

```{example, name="Derivative of logs"}
Find $dy/dx$ for the following.

1. $y=\log(x^2+9)$

    Let $u(x)=x^2+9$.  Then $u^\prime(x)=2x$ and \[\frac{dy}{dx}= \frac{u^\prime(x)}{u(x)} = \frac{2x}{(x^2+9)}\]
      
2. $y=\log(\log x)$

    Let $u(x)=\log x$.  Then $u^\prime(x)=1/x$ and $\frac{dy}{dx} = \frac{1}{(x\log x)}$.

3. $y=(\log x)^2$
  
    Use the generalized power rule. \[\frac{dy}{dx} = \frac{(2 \log x)}{x}\]

4. $y=\log e^x$ 

We know that $\log e^x=x$ and that $dx/dx=1$, but we can double check.  Let $u(x)=e^x$.  Then $u^\prime(x)=e^x$ and $\frac{dy}{dx} = \frac{u^\prime(x)}{u(x)} = \frac{e^x}{e^x} = 1.$



```



## Partial Derivatives

Suppose we have a function $f$ now of two (or more) variables and we want to determine the rate of change relative to one of the variables. To do so, we would find it's partial derivative, which is defined similar to the derivative of a function of one variable. 

__Partial Derivative__:  Let $f$ be a function of the variables $(x_1,\ldots,x_n)$.  The partial derivative of $f$ with respect to $x_i$ is 

\[\frac{\partial f}{\partial x_i} (x_1,\ldots,x_n) = \lim\limits_{h\to 0} \frac{f(x_1,\ldots,x_i+h,\ldots,x_n)-f(x_1,\ldots,x_i,\ldots,x_n)}{h}\]
Only the $i$th variable changes --- the others are treated as constants.

We can take higher-order partial derivatives, like we did with functions of a single variable, except now we the higher-order partials can be with respect to multiple variables.

```{example, name = "More than one type of partial"}
Notice that you can take partials with regard to different variables. 

Suppose $f(x,y)=x^2+y^2$. Then

\begin{align*}
\frac{\partial f}{\partial x}(x,y) &=\\
\frac{\partial f}{\partial y}(x,y) &=\\
\frac{\partial^2 f}{\partial x^2}(x,y) &=\\
\frac{\partial^2 f}{\partial x \partial y}(x,y) &=
\end{align*}
```


```{exercise}
Let $f(x,y)=x^3 y^4 +e^x -\log y$. What are the following partial derivaitves?

\begin{align*}
\frac{\partial f}{\partial x}(x,y) &=\\
\frac{\partial f}{\partial y}(x,y) &=\\
\frac{\partial^2 f}{\partial x^2}(x,y) &=\\
\frac{\partial^2 f}{\partial x \partial y}(x,y) &= 
\end{align*}
  

```



## L'Hopital's Rule

In studying limits, we saw that 
\[\lim\limits_{x \to c} f(x)/g(x) = \left(\lim\limits_{x \to c} f(x)\right)/\left(\lim\limits_{x \to c} g(x)\right)\], 

provided that $\lim\limits_{x \to c} g(x)\ne 0$.
	
If both $\lim\limits_{x \to c} f(x)=0$ and $\lim\limits_{x \to c} g(x)=0$, then we get an __indeterminate form__ of the type $\frac{0}{0}$ as $x\to c$.  However, a limit may still exist. We can use L'Hopital's rule to find the limit.
	
__L'Hopital's Rule__:  Suppose $f$ and $g$ are differentiable on some interval $a<x<b$ and that either


1. $\lim\limits_{x\to a^+} f(x)=0$ and $\lim\limits_{x\to a^+} g(x)=0$, or
2. $\lim\limits_{x\to a^+} f(x)=\pm\infty$ and $\lim\limits_{x\to a^+} g(x)=\pm\infty$

Suppose further that $g'(x)$ is never zero on $a<x<b$ and that 
\[\lim\limits_{x\to a^+} \frac{f'(x)}{g'(x)}=L\] then
\[\lim\limits_{x\to a^+} \frac{f(x)}{g(x)}=L\]
	
Put more simply, if $\lim\limits_{x\to a f(x)}$ is of the form $0/0$ or $\pm \infty / \pm \infty$, then $$\lim\limits_{x\to a} f(x) = \lim\limits_{x\to a} f'(x)$$
	
And if $\lim\limits_{x\to a} \frac{f'(x)}{g'(x)} = 0/0$ or $\pm \infty / \pm \infty$ then you can apply L'H\^opital's rule a second time, and continue applying it until you have a solution.

```{example, name="LHopital"}
Use L'Hopital's rule to find the following limits:

1. $\lim\limits_{x\to 0^+}\frac{\ln(1+x^2)}{x^3}$

2. $\lim\limits_{x\to  0^+} \frac{e^{1/x}}{1/x}$
		
3. $\lim\limits_{x\to 2} \frac{x-2}{(x+6)^{1/3}-2}$
  
  
```





## Taylor Series Approximation

__Taylor series__ (also known as the delta method) are used commonly to represent functions as infinite series of the function's derivatives at some point $a$. For example, Taylor series are very helpful in representing _nonlinear_ functions as linear functions. One can thus _approximate_ functions by using lower-order, finite series known as __Taylor polynomials__. If $a=0$, the series is called a Maclaurin series.
  

Specifically, a Taylor series of a real or complex function  $f(x)$ that is infinitely differentiable in the neighborhood of point $a$ is: 


\begin{align*}
	f(x) &= f(a) + \frac{f'(a)}{1!} (x-a) +  \frac{f''(a)}{2!} (x-a)^2 + \cdots\\
	 &= \sum_{n=0}^\infty \frac{f^{(n)} (a)}{n!} (x-a)^n
\end{align*}
  
__Taylor Approximation__: We can often approximate the curvature of a function $f(x)$ at point $a$ using a 2nd order Taylor polynomial around point $a$: 

\[f(x) = f(a) + \frac{f'(a)}{1!} (x-a) +  \frac{f''(a)}{2!} (x-a)^2
+ R_2\]


$R_2$ is the Lagrange remainder and often treated as negligible,
giving us:

\[f(x) \approx f(a) + f'(a)(x-a) +  \dfrac{f''(a)}{2} (x-a)^2\]

Taylor series expansion is easily generalized to multiple dimensions.

__Curvature and The Taylor Polynomial as a Quadratic Form__: 
The Hessian is used in a Taylor polynomial approximation to $f({\bf x})$ and provides information about the curvature of $f({\bf x})$ at $\bm{x}$ --- e.g., which tells us whether a critical point $\bm{x}^*$ is a min, max, or saddle point.


1.  The second order Taylor polynomial about the critical point
${\bf x}^*$ is
  $$f({\bf x}^*+\bf h)=f({\bf x}^*)+\nabla f({\bf x}^*) \bf h +\frac{1}{2} \bf h^T
{\bf H(x^*)} \bf h + R(\bf h)$$
2.  Since we're looking at a critical point, $\nabla f({\bf x}^*)=0$;
and for small $\bf h$, $R(\bf h)$ is negligible.  Rearranging, we get
$$f({\bf x}^*+\bf h)-f({\bf x}^*)\approx \frac{1}{2} \bf h^T {\bf H(x^*)}
\bf h $$
3. The Righthand side here is a quadratic form and we can determine the definiteness of $\bf
H(x^*)$.


## Summary: Derivative calculus in 6 steps

With these six rules (and decent algebra and trigonometry skills) you can figure out the derivative of anything.

1. Sum rule: \[[f(x)\pm g(x)]' = f'(x)\pm g'(x)\]
2. Product rule: \[[f(x)g(x)]' = f'(x)g(x)+f(x)g'(x)\]
3. Power rule: \[[x^k]' = k x^{k-1}\]
4. Chain rule: \[\frac{d}{dx} \{ f[g(x)] \} = f'[g(x)] g'(x)\]
5. $e^x$: \[\frac{d}{dx} e^x = e^x\]
6. Trig identity: \[\frac{d}{dx} \sin(x) = \cos(x)\]



## The Indefinite Integral: The Antiderivative

So far, we've been interested in finding the derivative $g=f'$ of a function $f$.  However, sometimes we're interested in exactly the reverse:  finding the function $f$ for which $g$ is its derivative.  We refer to $f$ as the __antiderivative__ of $g$.

Let $DF$ be the derivative of $F$.  And let $DF(x)$ be the derivative of $F$ evaluated at $x$.  Then the antiderivative is denoted by $D^{-1}$ (i.e., the inverse derivative).  If $DF=f$, then $F=D^{-1}f$.

__Indefinite Integral__:  Equivalently, if $F$ is the antiderivative of $f$, then $F$ is also called the indefinite integral of $f$ and written $F(x)=\int\limits f(x)dx$.

```{example}
1. $\int\limits \frac{1}{x^2}dx=$
2. $\int\limits 3e^{3x}dx=$
3. $\int\limits (x^2-4) dx=$
  
```
\begin{comment}
\parbox[c]{1in}{\,  {\includegraphics[width=1in, angle = 270]{derinteg.eps}}}
\end{comment}

	
Notice from these examples that while there is only a single derivative for any function, there are multiple antiderivatives: one for any arbitrary constant $c$.  $c$ just shifts the curve up or down on the $y$-axis.  If more info is present about the antiderivative --- e.g., that it passes through a particular point --- then we can solve for a specific value of $c$.

## Common Rules of Integration


1. Constants are allowed to slip out: $\int a f(x)dx = a\int f(x)dx$
1. Integration of the sum is sum of integrations:  $\int [f(x)+g(x)]dx=\int f(x)dx + \int g(x)dx$
1. Reverse Power-rule:  $\int x^n dx = \frac{1}{n+1} x^{n+1} + c$
1. Exponents are still exponents:  $\int e^x dx = e^x +c$
1. Recall the derivative of $\log(x)$ is one over $x$, and so:   $\int \frac{1}{x} dx = \log x + c$
1. Reverse chain-rule:  $\int e^{f(x)}f^\prime(x)dx = e^{f(x)}+c$
1. More generally:  $\int [f(x)]^n f'(x)dx = \frac{1}{n+1}[f(x)]^{n+1}+c$
1. Remember the derivative of a log of a function:  $\int \frac{f^\prime(x)}{f(x)}dx=\log f(x) + c$


```{example, name="Common Integration"}
Simplify the following indefinite integrals:
  
* $\int 3x^2 dx =$
* $\int (2x+1)dx=$
* $\int e^x e^{e^x} dx =$
  
  
```





## The Definite Integral: The Area under the Curve

__Riemann Sum__:  Suppose we want to determine the area $A(R)$ of a region $R$ defined by a curve $f(x)$ and some interval $a\le x \le b$.  One way to calculate the area would be to divide the interval $a\le x\le b$ into $n$ subintervals of length $\Delta x$ and then approximate the region with a series of rectangles, where the base of each rectangle is $\Delta x$ and the height is $f(x)$ at the midpoint of that interval.  $A(R)$ would then be approximated by the area of the union of the rectangles, which is given by $$S(f,\Delta x)=\sum\limits_{i=1}^n f(x_i)\Delta x$$ and is called a Riemann sum.

As we decrease the size of the subintervals $\Delta x$, making the rectangles "thinner," we would expect our approximation of the area of the region to become closer to the true area.  This gives the limiting process $$A(R)=\lim\limits_{\Delta x\to 0}\sum\limits_{i=1}^n f(x_i)\Delta x$$

__Riemann Integral__:  If for a given function $f$ the Riemann sum approaches a limit as $\Delta x \to 0$, then that limit is called the Riemann integral of $f$ from $a$ to $b$.  Formally, $$\int\limits_a^b f(x) dx= \lim\limits_{\Delta x\to 0} \sum\limits_{i=1}^n f(x_i)\Delta x$$

__Definite Integral__: We use the notation $\int\limits_a^b f(x) dx$ to denote the definite integral of $f$ from $a$ to $b$.  In words, the definite integral $\int\limits_a^b f(x)dx$ is the area under the ``curve" f(x) from $x=a$ to $x=b$.

__First Fundamental Theorem of Calculus__:  Let the function $f$ be bounded on $[a,b]$ and continuous on $(a,b)$.  Then the function $$F(x)=\int\limits_a^x f(t)dt, \quad a\le x\le b$$ has a derivative at each point in $(a,b)$ and $$F'(x)=f(x), \quad a<x<b$$  This last point shows that differentiation is the inverse of integration.

__Second Fundamental Theorem of Calculus__:  Let the function $f$ be bounded on $[a,b]$ and continuous on $(a,b)$.  Let $F$ be any function that is continuous on $[a,b]$ such that $F'(x)=f(x)$ on $(a,b)$.  Then $$\int\limits_a^bf(x)dx = F(b)-F(a)$$

The procedure to calculate a simple definite integral $\int\limits_a^b f(x)dx$ is then

1. Find the indefinite integral $F(x)$.
2. Evaluate $F(b)-F(a)$.

```{example}
$\int\limits_1^3 3x^2 dx=$
```


```{exercise}
$\int\limits_{-2}^2 e^x e^{e^x} dx =$
```



Properties of Definite Integrals:


1. There is no area below a point: \[\int\limits_a^a f(x)dx=0\]
2. Reversing the limits changes the sign of the integral: \[\int\limits_a^b f(x)dx=-\int\limits_b^a f(x)dx\]
3. Sums can be separated into their own integrals: \[\int\limits_a^b [\alpha f(x)+\beta g(x)]dx = \alpha \int\limits_a^b f(x)dx + \beta \int\limits_a^b g(x)dx\]
4. Areas can be combined as long as limits are linked: \[\int\limits_a^b f(x) dx +\int\limits_b^c f(x)dx = \int\limits_a^c f(x)dx\]


```{example, name="Making integrals definite"}

1. $\int\limits_1^1 3x^2 dx =$ 
1. $\int\limits_0^4 (2x+1)dx=$ 
1. $\int\limits_{-2}^0 e^x e^{e^x} dx + \int\limits_0^2 e^x e^{e^x} dx =$
  
  
```



## Integration by Substitution

Sometimes the integrand doesn't appear integrable using common rules and antiderivatives.  A method one might try is __integration by substitution__, which is related to the Chain Rule.

Suppose we want to find the indefinite integral $\int g(x)dx$ and assume we can identify a function $u(x)$ such that $g(x)=f[u(x)]u'(x)$. Let's refer to the antiderivative of $f$ as $F$.  Then the chain rule tells us that $\frac{d}{dx} F[u(x)]=f[u(x)]u'(x)$.  So, $F[u(x)]$ is the antiderivative of $g$.  We can then write $$\int g(x) dx= \int f[u(x)]u'(x)dx = \int \frac{d}{dx} F[u(x)]dx = F[u(x)]+c$$

__Procedure to determine the indefinite integral $\int g(x)dx$ by the method of substitution:__

1. Identify some part of $g(x)$ that might be simplified by substituting in a single variable $u$ (which will then be a function of $x$).
2. Determine if $g(x)dx$ can be reformulated in terms of $u$ and $du$.
3. Solve the indefinite integral.
4. Substitute back in for $x$


Substitution can also be used to calculate a definite integral. Using the same procedure as above, \[\int\limits_a^b g(x)dx=\int\limits_c^d f(u)du = F(d)-F(c)\]
where $c=u(a)$ and $d=u(b)$.

Example: $\int x^2 \sqrt{x+1}dx$

\vspace{6pt}

The problem here is the $\sqrt{x+1}$ term.  However, if the integrand had $\sqrt{x}$ times some polynomial, then we'd be in business.  Let's try $u=x+1$.  Then $x=u-1$ and $dx=du$. Substituting these into the above equation, we get 

\begin{align*}
			\int x^2\sqrt{x+1}dx&= \int (u-1)^2\sqrt{u}du\\
			&= \int (u^2-2u+1)u^{1/2}du\\
			&= \int (u^{5/2}-2u^{3/2}+u^{1/2})du
\end{align*}

We can easily integrate this, since it's just a polynomial.  Doing so and substituting $u=x+1$ back in, we get \[\int x^2\sqrt{x+1}dx=2(x+1)^{3/2}\left[\frac{1}{7}(x+1)^2 -
\frac{2}{5}(x+1)+\frac{1}{3}\right]+c\]

For the above problem, we could have also used the substitution $u=\sqrt{x+1}$.  Then $x=u^2-1$ and $dx=2u du$.  Substituting these in, we get $$\int x^2\sqrt{x+1}dx=\int (u^2-1)^2 u 2u du$$ which when expanded is again a polynomial and gives the same result as above.

```{example}
Simplify \[\int\limits_0^1 \frac{5e^{2x}}{(1+e^{2x})^{1/3}}dx\]

When an expression is raised to a power, it is often helpful to use this expression as the basis for a substitution.  So, let $u=1+e^{2x}$. Then $du=2e^{2x}dx$ and we can set $5e^{2x}dx=5du/2$.    Additionally, $u=2$ when $x=0$ and $u=1+e^2$ when $x=1$.  Substituting all of this in, we get

\begin{align*}
\int\limits_0^1 \frac{5e^{2x}}{(1+e^{2x})^{1/3}}dx
			&= \frac{5}{2}\int\limits_2^{1+e^2}\frac{du}{u^{1/3}}\\
			&= \frac{5}{2}\int\limits_2^{1+e^2} u^{-1/3}du\\
			&= \left. \frac{15}{4} u^{2/3} \right|_2^{1+e^2}\\
			&= 9.53
\end{align*}

```



## Integration by Parts, or Ultraviolet Voodoo


Another useful integration technique is __integration by parts__, which is related to the Product Rule of differentiation. The product rule states that $$\frac{d}{dx}(uv)=u\frac{dv}{dx}+v\frac{du}{dx}$$  Integrating this and rearranging, we get $$\int u\frac{dv}{dx}dx= u v - \int v \frac{du}{dx}dx$$ or $$\int u(x) v'(x)dx=u(x)v(x) - \int v(x)u'(x)dx$$
More frequently remembered as $$\int u dv = u v - \int v du$$ where $du=u'(x)dx$ and $dv=v'(x)dx$.


For definite integrals: $\int\limits_a^b u\frac{dv}{dx}dx = \left. u v \right|_a^b - \int\limits_a^b v \frac{du}{dx}dx$

Our goal here is to find expressions for $u$ and $dv$ that, when substituted into the above equation, yield an expression that's more easily evaluated.
	
```{example}
1. $\int x e^{ax} dx$
1. $\int x^n e^{ax} dx$
1. $\int x^3 e^{-x^2} dx$
  
  
```
