<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Probability Theory | Math Prefresher for Political Scientists</title>
  <meta name="description" content="Text for Harvard Department of Government Math Prefresher" />
  <meta name="generator" content="bookdown 0.12 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Probability Theory | Math Prefresher for Political Scientists" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="./images/logo.png" />
  <meta property="og:description" content="Text for Harvard Department of Government Math Prefresher" />
  <meta name="github-repo" content="IQSS/prefresher" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Probability Theory | Math Prefresher for Political Scientists" />
  
  <meta name="twitter:description" content="Text for Harvard Department of Government Math Prefresher" />
  <meta name="twitter:image" content="./images/logo.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="optim.html">
<link rel="next" href="linearalgebra.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Gov Prefresher</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Booklet</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#authors-and-contributors"><i class="fa fa-check"></i>Authors and Contributors</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contributing"><i class="fa fa-check"></i>Contributing</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pre-prefresher-exercises.html"><a href="pre-prefresher-exercises.html"><i class="fa fa-check"></i>Pre-Prefresher Exercises</a><ul>
<li class="chapter" data-level="" data-path="pre-prefresher-exercises.html"><a href="pre-prefresher-exercises.html#linear-algebra"><i class="fa fa-check"></i>Linear Algebra</a><ul>
<li class="chapter" data-level="" data-path="pre-prefresher-exercises.html"><a href="pre-prefresher-exercises.html#vectors"><i class="fa fa-check"></i>Vectors</a></li>
<li class="chapter" data-level="" data-path="pre-prefresher-exercises.html"><a href="pre-prefresher-exercises.html#matrices"><i class="fa fa-check"></i>Matrices</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pre-prefresher-exercises.html"><a href="pre-prefresher-exercises.html#operations"><i class="fa fa-check"></i>Operations</a><ul>
<li class="chapter" data-level="" data-path="pre-prefresher-exercises.html"><a href="pre-prefresher-exercises.html#summation"><i class="fa fa-check"></i>Summation</a></li>
<li class="chapter" data-level="" data-path="pre-prefresher-exercises.html"><a href="pre-prefresher-exercises.html#products"><i class="fa fa-check"></i>Products</a></li>
<li class="chapter" data-level="" data-path="pre-prefresher-exercises.html"><a href="pre-prefresher-exercises.html#logs-and-exponents"><i class="fa fa-check"></i>Logs and exponents</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pre-prefresher-exercises.html"><a href="pre-prefresher-exercises.html#limits"><i class="fa fa-check"></i>Limits</a></li>
<li class="chapter" data-level="" data-path="pre-prefresher-exercises.html"><a href="pre-prefresher-exercises.html#calculus"><i class="fa fa-check"></i>Calculus</a></li>
<li class="chapter" data-level="" data-path="pre-prefresher-exercises.html"><a href="pre-prefresher-exercises.html#optimization"><i class="fa fa-check"></i>Optimization</a></li>
<li class="chapter" data-level="" data-path="pre-prefresher-exercises.html"><a href="pre-prefresher-exercises.html#probability"><i class="fa fa-check"></i>Probability</a></li>
</ul></li>
<li class="part"><span><b>I Math</b></span></li>
<li class="chapter" data-level="1" data-path="functions-and-operations.html"><a href="functions-and-operations.html"><i class="fa fa-check"></i><b>1</b> Functions and Operations</a><ul>
<li class="chapter" data-level="1.1" data-path="functions-and-operations.html"><a href="functions-and-operations.html#sum-notation"><i class="fa fa-check"></i><b>1.1</b> Summation Operators <span class="math inline">\(\sum\)</span> and <span class="math inline">\(\prod\)</span></a></li>
<li class="chapter" data-level="1.2" data-path="functions-and-operations.html"><a href="functions-and-operations.html#introduction-to-functions"><i class="fa fa-check"></i><b>1.2</b> Introduction to Functions</a></li>
<li class="chapter" data-level="1.3" data-path="functions-and-operations.html"><a href="functions-and-operations.html#logexponents"><i class="fa fa-check"></i><b>1.3</b> <span class="math inline">\(\log\)</span> and <span class="math inline">\(\exp\)</span></a></li>
<li class="chapter" data-level="1.4" data-path="functions-and-operations.html"><a href="functions-and-operations.html#graphing-functions"><i class="fa fa-check"></i><b>1.4</b> Graphing Functions</a></li>
<li class="chapter" data-level="1.5" data-path="functions-and-operations.html"><a href="functions-and-operations.html#solving-for-variables-and-finding-roots"><i class="fa fa-check"></i><b>1.5</b> Solving for Variables and Finding Roots</a></li>
<li class="chapter" data-level="1.6" data-path="functions-and-operations.html"><a href="functions-and-operations.html#sets"><i class="fa fa-check"></i><b>1.6</b> Sets</a></li>
<li class="chapter" data-level="" data-path="functions-and-operations.html"><a href="functions-and-operations.html#answers-to-examples-and-exercises"><i class="fa fa-check"></i>Answers to Examples and Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="limits-precalc.html"><a href="limits-precalc.html"><i class="fa fa-check"></i><b>2</b> Limits</a><ul>
<li class="chapter" data-level="" data-path="limits-precalc.html"><a href="limits-precalc.html#example-the-central-limit-theorem"><i class="fa fa-check"></i>Example: The Central Limit Theorem</a></li>
<li class="chapter" data-level="" data-path="limits-precalc.html"><a href="limits-precalc.html#example-the-law-of-large-numbers"><i class="fa fa-check"></i>Example: The Law of Large Numbers</a></li>
<li class="chapter" data-level="2.1" data-path="limits-precalc.html"><a href="limits-precalc.html#sequences"><i class="fa fa-check"></i><b>2.1</b> Sequences</a></li>
<li class="chapter" data-level="2.2" data-path="limits-precalc.html"><a href="limits-precalc.html#the-limit-of-a-sequence"><i class="fa fa-check"></i><b>2.2</b> The Limit of a Sequence</a></li>
<li class="chapter" data-level="2.3" data-path="limits-precalc.html"><a href="limits-precalc.html#limitsfun"><i class="fa fa-check"></i><b>2.3</b> Limits of a Function</a></li>
<li class="chapter" data-level="2.4" data-path="limits-precalc.html"><a href="limits-precalc.html#continuity"><i class="fa fa-check"></i><b>2.4</b> Continuity</a></li>
<li class="chapter" data-level="" data-path="limits-precalc.html"><a href="limits-precalc.html#answers-to-examples"><i class="fa fa-check"></i>Answers to Examples</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="derivatives.html"><a href="derivatives.html"><i class="fa fa-check"></i><b>3</b> Calculus</a><ul>
<li class="chapter" data-level="" data-path="derivatives.html"><a href="derivatives.html#example-the-mean-is-a-type-of-integral"><i class="fa fa-check"></i>Example: The Mean is a Type of Integral</a></li>
<li class="chapter" data-level="3.1" data-path="derivatives.html"><a href="derivatives.html#derivintro"><i class="fa fa-check"></i><b>3.1</b> Derivatives</a><ul>
<li class="chapter" data-level="" data-path="derivatives.html"><a href="derivatives.html#properties-of-derivatives"><i class="fa fa-check"></i>Properties of derivatives</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="derivatives.html"><a href="derivatives.html#derivpoly"><i class="fa fa-check"></i><b>3.2</b> Higher-Order Derivatives (Derivatives of Derivatives of Derivatives)</a></li>
<li class="chapter" data-level="3.3" data-path="derivatives.html"><a href="derivatives.html#composite-functions-and-the-chain-rule"><i class="fa fa-check"></i><b>3.3</b> Composite Functions and the Chain Rule</a></li>
<li class="chapter" data-level="3.4" data-path="derivatives.html"><a href="derivatives.html#derivatives-of-natural-logs-and-the-exponent"><i class="fa fa-check"></i><b>3.4</b> Derivatives of natural logs and the exponent</a><ul>
<li><a href="derivatives.html#derivatives-of-natural-exponential-function-e">Derivatives of natural exponential function (<span class="math inline">\(e\)</span>)</a></li>
<li><a href="derivatives.html#derivatives-of-log">Derivatives of <span class="math inline">\(\log\)</span></a></li>
<li class="chapter" data-level="" data-path="derivatives.html"><a href="derivatives.html#outline-of-proof"><i class="fa fa-check"></i>Outline of Proof</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="derivatives.html"><a href="derivatives.html#partial-derivatives"><i class="fa fa-check"></i><b>3.5</b> Partial Derivatives</a></li>
<li class="chapter" data-level="3.6" data-path="derivatives.html"><a href="derivatives.html#taylorapprox"><i class="fa fa-check"></i><b>3.6</b> Taylor Series Approximation</a></li>
<li class="chapter" data-level="3.7" data-path="derivatives.html"><a href="derivatives.html#the-indefinite-integration"><i class="fa fa-check"></i><b>3.7</b> The Indefinite Integration</a><ul>
<li class="chapter" data-level="" data-path="derivatives.html"><a href="derivatives.html#common-rules-of-integration"><i class="fa fa-check"></i>Common Rules of Integration</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="derivatives.html"><a href="derivatives.html#the-definite-integral-the-area-under-the-curve"><i class="fa fa-check"></i><b>3.8</b> The Definite Integral: The Area under the Curve</a><ul>
<li class="chapter" data-level="" data-path="derivatives.html"><a href="derivatives.html#common-rules-for-definite-integrals"><i class="fa fa-check"></i>Common Rules for Definite Integrals</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="derivatives.html"><a href="derivatives.html#integration-by-substitution"><i class="fa fa-check"></i><b>3.9</b> Integration by Substitution</a></li>
<li class="chapter" data-level="3.10" data-path="derivatives.html"><a href="derivatives.html#integration-by-parts"><i class="fa fa-check"></i><b>3.10</b> Integration by Parts</a></li>
<li class="chapter" data-level="" data-path="derivatives.html"><a href="derivatives.html#answers-to-examples-and-exercises-1"><i class="fa fa-check"></i>Answers to Examples and Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="optim.html"><a href="optim.html"><i class="fa fa-check"></i><b>4</b> Optimization</a><ul>
<li class="chapter" data-level="" data-path="optim.html"><a href="optim.html#example-meltzer-richard"><i class="fa fa-check"></i>Example: Meltzer-Richard</a></li>
<li class="chapter" data-level="4.1" data-path="optim.html"><a href="optim.html#maxima-and-minima"><i class="fa fa-check"></i><b>4.1</b> Maxima and Minima</a></li>
<li class="chapter" data-level="4.2" data-path="optim.html"><a href="optim.html#concavity-of-a-function"><i class="fa fa-check"></i><b>4.2</b> Concavity of a Function</a><ul>
<li class="chapter" data-level="" data-path="optim.html"><a href="optim.html#quadratic-forms"><i class="fa fa-check"></i>Quadratic Forms</a></li>
<li class="chapter" data-level="" data-path="optim.html"><a href="optim.html#definiteness-of-quadratic-forms"><i class="fa fa-check"></i>Definiteness of Quadratic Forms</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="optim.html"><a href="optim.html#foc-and-soc"><i class="fa fa-check"></i><b>4.3</b> FOC and SOC</a><ul>
<li class="chapter" data-level="" data-path="optim.html"><a href="optim.html#first-order-conditions"><i class="fa fa-check"></i>First Order Conditions</a></li>
<li class="chapter" data-level="" data-path="optim.html"><a href="optim.html#second-order-conditions"><i class="fa fa-check"></i>Second Order Conditions</a></li>
<li class="chapter" data-level="" data-path="optim.html"><a href="optim.html#definiteness-and-concavity"><i class="fa fa-check"></i>Definiteness and Concavity</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="optim.html"><a href="optim.html#global-maxima-and-minima"><i class="fa fa-check"></i><b>4.4</b> Global Maxima and Minima</a></li>
<li class="chapter" data-level="4.5" data-path="optim.html"><a href="optim.html#constrained-optimization"><i class="fa fa-check"></i><b>4.5</b> Constrained Optimization</a><ul>
<li class="chapter" data-level="" data-path="optim.html"><a href="optim.html#equality-constraints"><i class="fa fa-check"></i>Equality Constraints</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="optim.html"><a href="optim.html#inequality-constraints"><i class="fa fa-check"></i><b>4.6</b> Inequality Constraints</a></li>
<li class="chapter" data-level="4.7" data-path="optim.html"><a href="optim.html#kuhn-tucker-conditions"><i class="fa fa-check"></i><b>4.7</b> Kuhn-Tucker Conditions</a></li>
<li class="chapter" data-level="4.8" data-path="optim.html"><a href="optim.html#applications-of-quadratic-forms"><i class="fa fa-check"></i><b>4.8</b> Applications of Quadratic Forms</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>5</b> Probability Theory</a><ul>
<li class="chapter" data-level="5.1" data-path="probability-theory.html"><a href="probability-theory.html#counting-rules"><i class="fa fa-check"></i><b>5.1</b> Counting rules</a></li>
<li class="chapter" data-level="5.2" data-path="probability-theory.html"><a href="probability-theory.html#setoper"><i class="fa fa-check"></i><b>5.2</b> Sets</a></li>
<li class="chapter" data-level="5.3" data-path="probability-theory.html"><a href="probability-theory.html#probdef"><i class="fa fa-check"></i><b>5.3</b> Probability</a><ul>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#probability-definitions-formal-and-informal"><i class="fa fa-check"></i>Probability Definitions: Formal and Informal</a></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#probability-operations"><i class="fa fa-check"></i>Probability Operations</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="probability-theory.html"><a href="probability-theory.html#conditional-probability-and-bayes-rule"><i class="fa fa-check"></i><b>5.4</b> Conditional Probability and Bayes Rule</a></li>
<li class="chapter" data-level="5.5" data-path="probability-theory.html"><a href="probability-theory.html#independence"><i class="fa fa-check"></i><b>5.5</b> Independence</a></li>
<li class="chapter" data-level="5.6" data-path="probability-theory.html"><a href="probability-theory.html#random-variables"><i class="fa fa-check"></i><b>5.6</b> Random Variables</a></li>
<li class="chapter" data-level="5.7" data-path="probability-theory.html"><a href="probability-theory.html#distributions"><i class="fa fa-check"></i><b>5.7</b> Distributions</a><ul>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#discrete-random-variables"><i class="fa fa-check"></i>Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#continuous-random-variables"><i class="fa fa-check"></i>Continuous Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="probability-theory.html"><a href="probability-theory.html#joint-distributions"><i class="fa fa-check"></i><b>5.8</b> Joint Distributions</a></li>
<li class="chapter" data-level="5.9" data-path="probability-theory.html"><a href="probability-theory.html#expectation"><i class="fa fa-check"></i><b>5.9</b> Expectation</a><ul>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#expected-value-of-a-function"><i class="fa fa-check"></i>Expected Value of a Function</a></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#properties-of-expected-values"><i class="fa fa-check"></i>Properties of Expected Values</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="probability-theory.html"><a href="probability-theory.html#variance-and-covariance"><i class="fa fa-check"></i><b>5.10</b> Variance and Covariance</a></li>
<li class="chapter" data-level="5.11" data-path="probability-theory.html"><a href="probability-theory.html#special-distributions"><i class="fa fa-check"></i><b>5.11</b> Special Distributions</a></li>
<li class="chapter" data-level="5.12" data-path="probability-theory.html"><a href="probability-theory.html#summarizing-observed-events-data"><i class="fa fa-check"></i><b>5.12</b> Summarizing Observed Events (Data)</a></li>
<li class="chapter" data-level="5.13" data-path="probability-theory.html"><a href="probability-theory.html#asymptotic-theory"><i class="fa fa-check"></i><b>5.13</b> Asymptotic Theory</a><ul>
<li class="chapter" data-level="5.13.1" data-path="probability-theory.html"><a href="probability-theory.html#clt-and-lln"><i class="fa fa-check"></i><b>5.13.1</b> CLT and LLN</a></li>
<li class="chapter" data-level="5.13.2" data-path="probability-theory.html"><a href="probability-theory.html#big-mathcalo-notation"><i class="fa fa-check"></i><b>5.13.2</b> Big <span class="math inline">\(\mathcal{O}\)</span> Notation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#answers-to-examples-and-exercises-2"><i class="fa fa-check"></i>Answers to Examples and Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linearalgebra.html"><a href="linearalgebra.html"><i class="fa fa-check"></i><b>6</b> Linear Algebra</a><ul>
<li class="chapter" data-level="6.1" data-path="linearalgebra.html"><a href="linearalgebra.html#vector-def"><i class="fa fa-check"></i><b>6.1</b> Working with Vectors</a></li>
<li class="chapter" data-level="6.2" data-path="linearalgebra.html"><a href="linearalgebra.html#linearindependence"><i class="fa fa-check"></i><b>6.2</b> Linear Independence</a></li>
<li class="chapter" data-level="6.3" data-path="linearalgebra.html"><a href="linearalgebra.html#matrixbasics"><i class="fa fa-check"></i><b>6.3</b> Basics of Matrix Algebra</a></li>
<li class="chapter" data-level="6.4" data-path="linearalgebra.html"><a href="linearalgebra.html#systems-of-linear-equations"><i class="fa fa-check"></i><b>6.4</b> Systems of Linear Equations</a></li>
<li class="chapter" data-level="6.5" data-path="linearalgebra.html"><a href="linearalgebra.html#systems-of-equations-as-matrices"><i class="fa fa-check"></i><b>6.5</b> Systems of Equations as Matrices</a></li>
<li class="chapter" data-level="6.6" data-path="linearalgebra.html"><a href="linearalgebra.html#finding-solutions-to-augmented-matrices-and-systems-of-equations"><i class="fa fa-check"></i><b>6.6</b> Finding Solutions to Augmented Matrices and Systems of Equations</a></li>
<li class="chapter" data-level="6.7" data-path="linearalgebra.html"><a href="linearalgebra.html#rank-and-whether-a-system-has-one-infinite-or-no-solutions"><i class="fa fa-check"></i><b>6.7</b> Rank — and Whether a System Has One, Infinite, or No Solutions</a></li>
<li class="chapter" data-level="6.8" data-path="linearalgebra.html"><a href="linearalgebra.html#the-inverse-of-a-matrix"><i class="fa fa-check"></i><b>6.8</b> The Inverse of a Matrix</a></li>
<li class="chapter" data-level="6.9" data-path="linearalgebra.html"><a href="linearalgebra.html#linear-systems-and-inverses"><i class="fa fa-check"></i><b>6.9</b> Linear Systems and Inverses</a></li>
<li class="chapter" data-level="6.10" data-path="linearalgebra.html"><a href="linearalgebra.html#determinants"><i class="fa fa-check"></i><b>6.10</b> Determinants</a></li>
<li class="chapter" data-level="6.11" data-path="linearalgebra.html"><a href="linearalgebra.html#getting-inverse-of-a-matrix-using-its-determinant"><i class="fa fa-check"></i><b>6.11</b> Getting Inverse of a Matrix using its Determinant</a></li>
<li class="chapter" data-level="" data-path="linearalgebra.html"><a href="linearalgebra.html#answers-to-examples-and-exercises-3"><i class="fa fa-check"></i>Answers to Examples and Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="causal.html"><a href="causal.html"><i class="fa fa-check"></i><b>7</b> Causal Inference</a></li>
<li class="part"><span><b>II Programming</b></span></li>
<li class="chapter" data-level="8" data-path="dataimport.html"><a href="dataimport.html"><i class="fa fa-check"></i><b>8</b> Orientation and Reading in Data</a><ul>
<li class="chapter" data-level="" data-path="dataimport.html"><a href="dataimport.html#where-are-we-where-are-we-headed"><i class="fa fa-check"></i>Where are we? Where are we headed?</a></li>
<li class="chapter" data-level="" data-path="dataimport.html"><a href="dataimport.html#check-your-understanding"><i class="fa fa-check"></i>Check your understanding</a></li>
<li class="chapter" data-level="8.1" data-path="dataimport.html"><a href="dataimport.html#motivation-data-and-you"><i class="fa fa-check"></i><b>8.1</b> Motivation: Data and You</a></li>
<li class="chapter" data-level="8.2" data-path="dataimport.html"><a href="dataimport.html#orienting"><i class="fa fa-check"></i><b>8.2</b> Orienting</a></li>
<li class="chapter" data-level="8.3" data-path="dataimport.html"><a href="dataimport.html#but-what-is-r"><i class="fa fa-check"></i><b>8.3</b> But what is R?</a></li>
<li class="chapter" data-level="8.4" data-path="dataimport.html"><a href="dataimport.html#the-computer-and-you-giving-instructions"><i class="fa fa-check"></i><b>8.4</b> The Computer and You: Giving Instructions</a></li>
<li class="chapter" data-level="8.5" data-path="dataimport.html"><a href="dataimport.html#base-r-vs.tidyverse"><i class="fa fa-check"></i><b>8.5</b> Base-R vs. tidyverse</a><ul>
<li class="chapter" data-level="" data-path="dataimport.html"><a href="dataimport.html#dataframe-subsetting"><i class="fa fa-check"></i>Dataframe subsetting</a></li>
<li class="chapter" data-level="" data-path="dataimport.html"><a href="dataimport.html#read-data"><i class="fa fa-check"></i>Read data</a></li>
<li class="chapter" data-level="" data-path="dataimport.html"><a href="dataimport.html#visualization"><i class="fa fa-check"></i>Visualization</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="dataimport.html"><a href="dataimport.html#a-is-for-athens"><i class="fa fa-check"></i><b>8.6</b> A is for Athens</a><ul>
<li class="chapter" data-level="8.6.1" data-path="dataimport.html"><a href="dataimport.html#locating-the-data"><i class="fa fa-check"></i><b>8.6.1</b> Locating the Data</a></li>
<li class="chapter" data-level="8.6.2" data-path="dataimport.html"><a href="dataimport.html#reading-in-data"><i class="fa fa-check"></i><b>8.6.2</b> Reading in Data</a></li>
<li class="chapter" data-level="8.6.3" data-path="dataimport.html"><a href="dataimport.html#inspecting"><i class="fa fa-check"></i><b>8.6.3</b> Inspecting</a></li>
<li class="chapter" data-level="8.6.4" data-path="dataimport.html"><a href="dataimport.html#finding-observations"><i class="fa fa-check"></i><b>8.6.4</b> Finding observations</a></li>
<li class="chapter" data-level="8.6.5" data-path="dataimport.html"><a href="dataimport.html#extra-a-sneak-peak-at-obers-data"><i class="fa fa-check"></i><b>8.6.5</b> Extra: A sneak peak at Ober’s data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="dataimport.html"><a href="dataimport.html#exercises"><i class="fa fa-check"></i>Exercises</a><ul>
<li class="chapter" data-level="" data-path="dataimport.html"><a href="dataimport.html#section"><i class="fa fa-check"></i>1</a></li>
<li class="chapter" data-level="" data-path="dataimport.html"><a href="dataimport.html#section-1"><i class="fa fa-check"></i>2</a></li>
<li class="chapter" data-level="" data-path="dataimport.html"><a href="dataimport.html#section-2"><i class="fa fa-check"></i>3</a></li>
<li class="chapter" data-level="" data-path="dataimport.html"><a href="dataimport.html#section-3"><i class="fa fa-check"></i>4</a></li>
<li class="chapter" data-level="" data-path="dataimport.html"><a href="dataimport.html#section-4"><i class="fa fa-check"></i>5</a></li>
<li class="chapter" data-level="" data-path="dataimport.html"><a href="dataimport.html#section-5"><i class="fa fa-check"></i>6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="rmatrices.html"><a href="rmatrices.html"><i class="fa fa-check"></i><b>9</b> Manipulating Vectors and Matrices</a><ul>
<li class="chapter" data-level="" data-path="rmatrices.html"><a href="rmatrices.html#where-are-we-where-are-we-headed-1"><i class="fa fa-check"></i>Where are we? Where are we headed?</a></li>
<li class="chapter" data-level="9.1" data-path="rmatrices.html"><a href="rmatrices.html#basics---matrices"><i class="fa fa-check"></i><b>9.1</b> Basics - Matrices</a></li>
<li class="chapter" data-level="" data-path="rmatrices.html"><a href="rmatrices.html#checkpoint"><i class="fa fa-check"></i>Checkpoint</a><ul>
<li class="chapter" data-level="" data-path="rmatrices.html"><a href="rmatrices.html#section-6"><i class="fa fa-check"></i>1</a></li>
<li class="chapter" data-level="" data-path="rmatrices.html"><a href="rmatrices.html#section-7"><i class="fa fa-check"></i>2</a></li>
<li class="chapter" data-level="" data-path="rmatrices.html"><a href="rmatrices.html#section-8"><i class="fa fa-check"></i>3</a></li>
<li class="chapter" data-level="9.1.1" data-path="rmatrices.html"><a href="rmatrices.html#data-frames"><i class="fa fa-check"></i><b>9.1.1</b> data frames</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="rmatrices.html"><a href="rmatrices.html#motivation"><i class="fa fa-check"></i><b>9.2</b> Motivation</a></li>
<li class="chapter" data-level="9.3" data-path="rmatrices.html"><a href="rmatrices.html#read-data-1"><i class="fa fa-check"></i><b>9.3</b> Read Data</a></li>
<li class="chapter" data-level="9.4" data-path="rmatrices.html"><a href="rmatrices.html#data.frame-vs.matricies"><i class="fa fa-check"></i><b>9.4</b> data.frame vs. matricies</a></li>
<li class="chapter" data-level="9.5" data-path="rmatrices.html"><a href="rmatrices.html#speed-considerations"><i class="fa fa-check"></i><b>9.5</b> Speed considerations</a></li>
<li class="chapter" data-level="9.6" data-path="rmatrices.html"><a href="rmatrices.html#handling-matricies-in-r"><i class="fa fa-check"></i><b>9.6</b> Handling matricies in <code>R</code></a></li>
<li class="chapter" data-level="9.7" data-path="rmatrices.html"><a href="rmatrices.html#variable-transformations"><i class="fa fa-check"></i><b>9.7</b> Variable Transformations</a></li>
<li class="chapter" data-level="9.8" data-path="rmatrices.html"><a href="rmatrices.html#linear-combinations"><i class="fa fa-check"></i><b>9.8</b> Linear Combinations</a></li>
<li class="chapter" data-level="" data-path="rmatrices.html"><a href="rmatrices.html#exercises-1"><i class="fa fa-check"></i>Exercises</a><ul>
<li class="chapter" data-level="" data-path="rmatrices.html"><a href="rmatrices.html#section-9"><i class="fa fa-check"></i>1</a></li>
<li class="chapter" data-level="" data-path="rmatrices.html"><a href="rmatrices.html#section-10"><i class="fa fa-check"></i>2</a></li>
<li class="chapter" data-level="" data-path="rmatrices.html"><a href="rmatrices.html#section-11"><i class="fa fa-check"></i>3</a></li>
<li class="chapter" data-level="" data-path="rmatrices.html"><a href="rmatrices.html#section-12"><i class="fa fa-check"></i>4</a></li>
<li class="chapter" data-level="" data-path="rmatrices.html"><a href="rmatrices.html#section-13"><i class="fa fa-check"></i>5</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="robjloops.html"><a href="robjloops.html"><i class="fa fa-check"></i><b>10</b> Objects, Functions, Loops</a><ul>
<li class="chapter" data-level="" data-path="robjloops.html"><a href="robjloops.html#where-are-we-where-are-we-headed-2"><i class="fa fa-check"></i>Where are we? Where are we headed?</a></li>
<li class="chapter" data-level="10.1" data-path="robjloops.html"><a href="robjloops.html#what-is-an-object"><i class="fa fa-check"></i><b>10.1</b> What is an object?</a><ul>
<li class="chapter" data-level="10.1.1" data-path="robjloops.html"><a href="robjloops.html#lists"><i class="fa fa-check"></i><b>10.1.1</b> lists</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="robjloops.html"><a href="robjloops.html#making-your-own-objects"><i class="fa fa-check"></i><b>10.2</b> Making your own objects</a><ul>
<li class="chapter" data-level="10.2.1" data-path="robjloops.html"><a href="robjloops.html#seeing-r-through-objects"><i class="fa fa-check"></i><b>10.2.1</b> Seeing R through objects</a></li>
<li class="chapter" data-level="10.2.2" data-path="robjloops.html"><a href="robjloops.html#parsing-an-object-by-strs"><i class="fa fa-check"></i><b>10.2.2</b> Parsing an object by <code>str()s</code></a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="robjloops.html"><a href="robjloops.html#types-of-variables"><i class="fa fa-check"></i><b>10.3</b> Types of variables</a><ul>
<li class="chapter" data-level="10.3.1" data-path="robjloops.html"><a href="robjloops.html#scalars"><i class="fa fa-check"></i><b>10.3.1</b> scalars</a></li>
<li class="chapter" data-level="10.3.2" data-path="robjloops.html"><a href="robjloops.html#numeric-vectors"><i class="fa fa-check"></i><b>10.3.2</b> numeric vectors</a></li>
<li class="chapter" data-level="10.3.3" data-path="robjloops.html"><a href="robjloops.html#characters-aka-strings"><i class="fa fa-check"></i><b>10.3.3</b> characters (aka strings)</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="robjloops.html"><a href="robjloops.html#what-is-a-function"><i class="fa fa-check"></i><b>10.4</b> What is a function?</a><ul>
<li class="chapter" data-level="10.4.1" data-path="robjloops.html"><a href="robjloops.html#write-your-own-function"><i class="fa fa-check"></i><b>10.4.1</b> Write your own function</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="robjloops.html"><a href="robjloops.html#checkpoint-1"><i class="fa fa-check"></i>Checkpoint</a><ul>
<li class="chapter" data-level="" data-path="robjloops.html"><a href="robjloops.html#section-14"><i class="fa fa-check"></i>1</a></li>
<li class="chapter" data-level="" data-path="robjloops.html"><a href="robjloops.html#section-15"><i class="fa fa-check"></i>2</a></li>
<li class="chapter" data-level="" data-path="robjloops.html"><a href="robjloops.html#section-16"><i class="fa fa-check"></i>3</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="robjloops.html"><a href="robjloops.html#what-is-a-package"><i class="fa fa-check"></i><b>10.5</b> What is a package?</a></li>
<li class="chapter" data-level="10.6" data-path="robjloops.html"><a href="robjloops.html#conditionals"><i class="fa fa-check"></i><b>10.6</b> Conditionals</a></li>
<li class="chapter" data-level="10.7" data-path="robjloops.html"><a href="robjloops.html#for-loops"><i class="fa fa-check"></i><b>10.7</b> For-loops</a></li>
<li class="chapter" data-level="10.8" data-path="robjloops.html"><a href="robjloops.html#nested-loops"><i class="fa fa-check"></i><b>10.8</b> Nested Loops</a></li>
<li class="chapter" data-level="" data-path="robjloops.html"><a href="robjloops.html#exercises-2"><i class="fa fa-check"></i>Exercises</a><ul>
<li class="chapter" data-level="" data-path="robjloops.html"><a href="robjloops.html#exercise-1-write-your-own-function"><i class="fa fa-check"></i>Exercise 1: Write your own function</a></li>
<li class="chapter" data-level="" data-path="robjloops.html"><a href="robjloops.html#exercise-2-using-loops"><i class="fa fa-check"></i>Exercise 2: Using Loops</a></li>
<li class="chapter" data-level="" data-path="robjloops.html"><a href="robjloops.html#exercise-3-storing-information-derived-within-loops-in-a-global-dataframe"><i class="fa fa-check"></i>Exercise 3: Storing information derived within loops in a global dataframe</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="dataviz.html"><a href="dataviz.html"><i class="fa fa-check"></i><b>11</b> Visualization</a><ul>
<li class="chapter" data-level="" data-path="dataviz.html"><a href="dataviz.html#where-are-we-where-are-we-headed-3"><i class="fa fa-check"></i>Where are we? Where are we headed?</a></li>
<li class="chapter" data-level="" data-path="dataviz.html"><a href="dataviz.html#check-your-understanding-1"><i class="fa fa-check"></i>Check your understanding</a></li>
<li class="chapter" data-level="11.1" data-path="dataviz.html"><a href="dataviz.html#motivation-the-law-of-the-census"><i class="fa fa-check"></i><b>11.1</b> Motivation: The Law of the Census</a></li>
<li class="chapter" data-level="11.2" data-path="dataviz.html"><a href="dataviz.html#read-data-2"><i class="fa fa-check"></i><b>11.2</b> Read data</a></li>
<li class="chapter" data-level="11.3" data-path="dataviz.html"><a href="dataviz.html#counting"><i class="fa fa-check"></i><b>11.3</b> Counting</a></li>
<li class="chapter" data-level="11.4" data-path="dataviz.html"><a href="dataviz.html#tabulating"><i class="fa fa-check"></i><b>11.4</b> Tabulating</a></li>
<li class="chapter" data-level="11.5" data-path="dataviz.html"><a href="dataviz.html#base-r-graphics-and-ggplot"><i class="fa fa-check"></i><b>11.5</b> base R graphics and ggplot</a><ul>
<li class="chapter" data-level="11.5.1" data-path="dataviz.html"><a href="dataviz.html#base-r"><i class="fa fa-check"></i><b>11.5.1</b> base R</a></li>
<li class="chapter" data-level="11.5.2" data-path="dataviz.html"><a href="dataviz.html#ggplot"><i class="fa fa-check"></i><b>11.5.2</b> ggplot</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="dataviz.html"><a href="dataviz.html#improving-your-graphics"><i class="fa fa-check"></i><b>11.6</b> Improving your graphics</a></li>
<li class="chapter" data-level="11.7" data-path="dataviz.html"><a href="dataviz.html#cross-tabs"><i class="fa fa-check"></i><b>11.7</b> Cross-tabs</a></li>
<li class="chapter" data-level="11.8" data-path="dataviz.html"><a href="dataviz.html#composition-plots"><i class="fa fa-check"></i><b>11.8</b> Composition Plots</a></li>
<li class="chapter" data-level="11.9" data-path="dataviz.html"><a href="dataviz.html#line-graphs"><i class="fa fa-check"></i><b>11.9</b> Line graphs</a></li>
<li class="chapter" data-level="" data-path="dataviz.html"><a href="dataviz.html#exercises-3"><i class="fa fa-check"></i>Exercises</a><ul>
<li class="chapter" data-level="" data-path="dataviz.html"><a href="dataviz.html#rural-states"><i class="fa fa-check"></i>1: Rural states</a></li>
<li class="chapter" data-level="" data-path="dataviz.html"><a href="dataviz.html#the-swing-justice"><i class="fa fa-check"></i>2: The swing justice</a></li>
<li class="chapter" data-level="" data-path="dataviz.html"><a href="dataviz.html#dont-sort-by-the-alphabet"><i class="fa fa-check"></i>3: Don’t sort by the alphabet</a></li>
<li class="chapter" data-level="" data-path="dataviz.html"><a href="dataviz.html#what-to-show-and-how-to-show-it"><i class="fa fa-check"></i>4 What to show and how to show it</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="dempeace.html"><a href="dempeace.html"><i class="fa fa-check"></i><b>12</b> Joins and Merges, Wide and Long</a><ul>
<li class="chapter" data-level="" data-path="dempeace.html"><a href="dempeace.html#where-are-we-where-are-we-headed-4"><i class="fa fa-check"></i>Where are we? Where are we headed?</a></li>
<li class="chapter" data-level="12.1" data-path="dempeace.html"><a href="dempeace.html#motivation-1"><i class="fa fa-check"></i><b>12.1</b> Motivation</a></li>
<li class="chapter" data-level="12.2" data-path="dempeace.html"><a href="dempeace.html#setting-up"><i class="fa fa-check"></i><b>12.2</b> Setting up</a></li>
<li class="chapter" data-level="12.3" data-path="dempeace.html"><a href="dempeace.html#create-a-project-directory"><i class="fa fa-check"></i><b>12.3</b> Create a project directory</a></li>
<li class="chapter" data-level="12.4" data-path="dempeace.html"><a href="dempeace.html#data-sources"><i class="fa fa-check"></i><b>12.4</b> Data Sources</a></li>
<li class="chapter" data-level="12.5" data-path="dempeace.html"><a href="dempeace.html#example-with-2-datasets"><i class="fa fa-check"></i><b>12.5</b> Example with 2 Datasets</a></li>
<li class="chapter" data-level="12.6" data-path="dempeace.html"><a href="dempeace.html#loops"><i class="fa fa-check"></i><b>12.6</b> Loops</a></li>
<li class="chapter" data-level="12.7" data-path="dempeace.html"><a href="dempeace.html#merging"><i class="fa fa-check"></i><b>12.7</b> Merging</a></li>
<li class="chapter" data-level="12.8" data-path="dempeace.html"><a href="dempeace.html#main-project"><i class="fa fa-check"></i><b>12.8</b> Main Project</a><ul>
<li class="chapter" data-level="" data-path="dempeace.html"><a href="dempeace.html#task-1-data-input-and-standardization"><i class="fa fa-check"></i>Task 1: Data Input and Standardization</a></li>
<li class="chapter" data-level="" data-path="dempeace.html"><a href="dempeace.html#task-2-data-merging"><i class="fa fa-check"></i>Task 2: Data Merging</a></li>
<li class="chapter" data-level="" data-path="dempeace.html"><a href="dempeace.html#task-3-tabulations-and-visualization"><i class="fa fa-check"></i>Task 3: Tabulations and Visualization</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="simulation.html"><a href="simulation.html"><i class="fa fa-check"></i><b>13</b> Simulation</a><ul>
<li class="chapter" data-level="" data-path="simulation.html"><a href="simulation.html#where-are-we-where-are-we-headed-5"><i class="fa fa-check"></i>Where are we? Where are we headed?</a></li>
<li class="chapter" data-level="" data-path="simulation.html"><a href="simulation.html#check-your-understanding-2"><i class="fa fa-check"></i>Check your Understanding</a></li>
<li class="chapter" data-level="13.1" data-path="simulation.html"><a href="simulation.html#motivation-simulation-as-an-analytical-tool"><i class="fa fa-check"></i><b>13.1</b> Motivation: Simulation as an Analytical Tool</a></li>
<li class="chapter" data-level="13.2" data-path="simulation.html"><a href="simulation.html#pick-a-sample-any-sample"><i class="fa fa-check"></i><b>13.2</b> Pick a sample, any sample</a></li>
<li class="chapter" data-level="13.3" data-path="simulation.html"><a href="simulation.html#the-sample-function"><i class="fa fa-check"></i><b>13.3</b> The <code>sample()</code> function</a><ul>
<li class="chapter" data-level="13.3.1" data-path="simulation.html"><a href="simulation.html#sampling-rows-from-a-dataframe"><i class="fa fa-check"></i><b>13.3.1</b> Sampling rows from a dataframe</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="simulation.html"><a href="simulation.html#random-numbers-from-specific-distributions"><i class="fa fa-check"></i><b>13.4</b> Random numbers from specific distributions</a><ul>
<li><a href="simulation.html#rbinom"><code>rbinom()</code></a></li>
<li><a href="simulation.html#runif"><code>runif()</code></a></li>
<li><a href="simulation.html#rnorm"><code>rnorm()</code></a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="simulation.html"><a href="simulation.html#r-p-and-d"><i class="fa fa-check"></i><b>13.5</b> r, p, and d</a></li>
<li class="chapter" data-level="13.6" data-path="simulation.html"><a href="simulation.html#set.seed"><i class="fa fa-check"></i><b>13.6</b> <code>set.seed()</code></a></li>
<li class="chapter" data-level="" data-path="simulation.html"><a href="simulation.html#exercises-4"><i class="fa fa-check"></i>Exercises</a><ul>
<li class="chapter" data-level="" data-path="simulation.html"><a href="simulation.html#census-sampling"><i class="fa fa-check"></i>Census Sampling</a></li>
<li class="chapter" data-level="" data-path="simulation.html"><a href="simulation.html#conditional-proportions"><i class="fa fa-check"></i>Conditional Proportions</a></li>
<li class="chapter" data-level="" data-path="simulation.html"><a href="simulation.html#the-birthday-problem"><i class="fa fa-check"></i>The Birthday problem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html"><i class="fa fa-check"></i><b>14</b> LaTeX and markdown</a><ul>
<li class="chapter" data-level="" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#where-are-we-where-are-we-headed-6"><i class="fa fa-check"></i>Where are we? Where are we headed?</a></li>
<li class="chapter" data-level="" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#check-your-understanding-3"><i class="fa fa-check"></i>Check your understanding</a></li>
<li class="chapter" data-level="14.1" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#motivation-2"><i class="fa fa-check"></i><b>14.1</b> Motivation</a></li>
<li class="chapter" data-level="14.2" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#markdown"><i class="fa fa-check"></i><b>14.2</b> Markdown</a><ul>
<li class="chapter" data-level="14.2.1" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#markdown-commands"><i class="fa fa-check"></i><b>14.2.1</b> markdown commands</a></li>
<li class="chapter" data-level="14.2.2" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#your-own-markdown"><i class="fa fa-check"></i><b>14.2.2</b> your own markdown</a></li>
<li class="chapter" data-level="14.2.3" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#a-note-on-plain-text-editors"><i class="fa fa-check"></i><b>14.2.3</b> A note on plain-text editors</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#latex"><i class="fa fa-check"></i><b>14.3</b> LaTeX</a><ul>
<li class="chapter" data-level="14.3.1" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#compile-online"><i class="fa fa-check"></i><b>14.3.1</b> compile online</a></li>
<li class="chapter" data-level="14.3.2" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#compile-your-first-latex-document-locally"><i class="fa fa-check"></i><b>14.3.2</b> compile your first LaTeX document locally</a></li>
<li class="chapter" data-level="14.3.3" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#main-latex-commands"><i class="fa fa-check"></i><b>14.3.3</b> main LaTeX commands</a></li>
<li class="chapter" data-level="" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#further-guides"><i class="fa fa-check"></i>Further Guides</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#bibtex"><i class="fa fa-check"></i><b>14.4</b> BibTeX</a><ul>
<li class="chapter" data-level="14.4.1" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#what-is-a-.bib-file"><i class="fa fa-check"></i><b>14.4.1</b> what is a <code>.bib</code> file?</a></li>
<li class="chapter" data-level="14.4.2" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#what-does-latex-do-with-.bib-files"><i class="fa fa-check"></i><b>14.4.2</b> what does LaTeX do with .bib files?</a></li>
<li class="chapter" data-level="14.4.3" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#stocking-up-on-your-.bib-files"><i class="fa fa-check"></i><b>14.4.3</b> stocking up on your .bib files</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#exercise"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#concluding-the-prefresher"><i class="fa fa-check"></i>Concluding the Prefresher</a><ul>
<li class="chapter" data-level="" data-path="nonwysiwyg.html"><a href="nonwysiwyg.html#your-feedback-matters"><i class="fa fa-check"></i>Your Feedback Matters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="rtext.html"><a href="rtext.html"><i class="fa fa-check"></i><b>15</b> Text</a><ul>
<li class="chapter" data-level="" data-path="rtext.html"><a href="rtext.html#where-are-we-where-are-we-headed-7"><i class="fa fa-check"></i>Where are we? Where are we headed?</a></li>
<li class="chapter" data-level="15.1" data-path="rtext.html"><a href="rtext.html#review"><i class="fa fa-check"></i><b>15.1</b> Review</a></li>
<li class="chapter" data-level="15.2" data-path="rtext.html"><a href="rtext.html#goals-for-today"><i class="fa fa-check"></i><b>15.2</b> Goals for today</a></li>
<li class="chapter" data-level="15.3" data-path="rtext.html"><a href="rtext.html#reading-and-writing-text-in-r"><i class="fa fa-check"></i><b>15.3</b> Reading and writing text in R</a></li>
<li class="chapter" data-level="15.4" data-path="rtext.html"><a href="rtext.html#paste-and-sprintf"><i class="fa fa-check"></i><b>15.4</b> <code>paste()</code> and <code>sprintf()</code></a></li>
<li class="chapter" data-level="15.5" data-path="rtext.html"><a href="rtext.html#regular-expressions"><i class="fa fa-check"></i><b>15.5</b> Regular expressions</a><ul>
<li class="chapter" data-level="15.5.1" data-path="rtext.html"><a href="rtext.html#character-classes"><i class="fa fa-check"></i><b>15.5.1</b> Character classes</a></li>
<li class="chapter" data-level="15.5.2" data-path="rtext.html"><a href="rtext.html#special-characters."><i class="fa fa-check"></i><b>15.5.2</b> Special Characters.</a></li>
<li class="chapter" data-level="15.5.3" data-path="rtext.html"><a href="rtext.html#conditional-patterns"><i class="fa fa-check"></i><b>15.5.3</b> Conditional patterns</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="rtext.html"><a href="rtext.html#representing-text"><i class="fa fa-check"></i><b>15.6</b> Representing Text</a></li>
<li class="chapter" data-level="15.7" data-path="rtext.html"><a href="rtext.html#important-packages-for-parsing-text"><i class="fa fa-check"></i><b>15.7</b> Important packages for parsing text</a></li>
<li class="chapter" data-level="" data-path="rtext.html"><a href="rtext.html#exercises-5"><i class="fa fa-check"></i>Exercises</a><ul>
<li class="chapter" data-level="" data-path="rtext.html"><a href="rtext.html#section-17"><i class="fa fa-check"></i>1</a></li>
<li class="chapter" data-level="" data-path="rtext.html"><a href="rtext.html#section-18"><i class="fa fa-check"></i>2</a></li>
<li class="chapter" data-level="" data-path="rtext.html"><a href="rtext.html#section-19"><i class="fa fa-check"></i>3</a></li>
<li class="chapter" data-level="" data-path="rtext.html"><a href="rtext.html#section-20"><i class="fa fa-check"></i>4</a></li>
<li class="chapter" data-level="" data-path="rtext.html"><a href="rtext.html#section-21"><i class="fa fa-check"></i>5</a></li>
<li class="chapter" data-level="" data-path="rtext.html"><a href="rtext.html#section-22"><i class="fa fa-check"></i>6</a></li>
<li class="chapter" data-level="" data-path="rtext.html"><a href="rtext.html#section-23"><i class="fa fa-check"></i>7</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="commandline-git.html"><a href="commandline-git.html"><i class="fa fa-check"></i><b>16</b> Command-line, git</a><ul>
<li class="chapter" data-level="16.1" data-path="commandline-git.html"><a href="commandline-git.html#where-are-we-where-are-we-headed-8"><i class="fa fa-check"></i><b>16.1</b> Where are we? Where are we headed?</a></li>
<li class="chapter" data-level="16.2" data-path="commandline-git.html"><a href="commandline-git.html#check-your-understanding-4"><i class="fa fa-check"></i><b>16.2</b> Check your understanding</a></li>
<li class="chapter" data-level="16.3" data-path="commandline-git.html"><a href="commandline-git.html#command-line"><i class="fa fa-check"></i><b>16.3</b> command-line</a><ul>
<li class="chapter" data-level="16.3.1" data-path="commandline-git.html"><a href="commandline-git.html#command-line-commands"><i class="fa fa-check"></i><b>16.3.1</b> command-line commands</a></li>
<li class="chapter" data-level="16.3.2" data-path="commandline-git.html"><a href="commandline-git.html#running-things-via-command-line"><i class="fa fa-check"></i><b>16.3.2</b> running things via command-line</a></li>
<li class="chapter" data-level="16.3.3" data-path="commandline-git.html"><a href="commandline-git.html#why-do-command-line"><i class="fa fa-check"></i><b>16.3.3</b> why do command-line?</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="commandline-git.html"><a href="commandline-git.html#git"><i class="fa fa-check"></i><b>16.4</b> git</a><ul>
<li class="chapter" data-level="16.4.1" data-path="commandline-git.html"><a href="commandline-git.html#why-version-control"><i class="fa fa-check"></i><b>16.4.1</b> why version control?</a></li>
<li class="chapter" data-level="16.4.2" data-path="commandline-git.html"><a href="commandline-git.html#open-source-code-at-your-fingertips"><i class="fa fa-check"></i><b>16.4.2</b> open-source code at your fingertips</a></li>
<li class="chapter" data-level="16.4.3" data-path="commandline-git.html"><a href="commandline-git.html#commands-in-git"><i class="fa fa-check"></i><b>16.4.3</b> commands in git</a></li>
<li class="chapter" data-level="16.4.4" data-path="commandline-git.html"><a href="commandline-git.html#is-git-worth-it"><i class="fa fa-check"></i><b>16.4.4</b> is git worth it?</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Solutions</b></span></li>
<li class="chapter" data-level="" data-path="solutions-to-warmup-questions.html"><a href="solutions-to-warmup-questions.html"><i class="fa fa-check"></i>Solutions to Warmup Questions</a><ul>
<li class="chapter" data-level="" data-path="solutions-to-warmup-questions.html"><a href="solutions-to-warmup-questions.html#linear-algebra-1"><i class="fa fa-check"></i>Linear Algebra</a><ul>
<li class="chapter" data-level="" data-path="solutions-to-warmup-questions.html"><a href="solutions-to-warmup-questions.html#vectors-1"><i class="fa fa-check"></i>Vectors</a></li>
<li class="chapter" data-level="" data-path="solutions-to-warmup-questions.html"><a href="solutions-to-warmup-questions.html#matrices-1"><i class="fa fa-check"></i>Matrices</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="solutions-to-warmup-questions.html"><a href="solutions-to-warmup-questions.html#operations-1"><i class="fa fa-check"></i>Operations</a><ul>
<li class="chapter" data-level="" data-path="solutions-to-warmup-questions.html"><a href="solutions-to-warmup-questions.html#summation-1"><i class="fa fa-check"></i>Summation</a></li>
<li class="chapter" data-level="" data-path="solutions-to-warmup-questions.html"><a href="solutions-to-warmup-questions.html#products-1"><i class="fa fa-check"></i>Products</a></li>
<li class="chapter" data-level="" data-path="solutions-to-warmup-questions.html"><a href="solutions-to-warmup-questions.html#logs-and-exponents-1"><i class="fa fa-check"></i>Logs and exponents</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="solutions-to-warmup-questions.html"><a href="solutions-to-warmup-questions.html#limits-1"><i class="fa fa-check"></i>Limits</a></li>
<li class="chapter" data-level="" data-path="solutions-to-warmup-questions.html"><a href="solutions-to-warmup-questions.html#calculus-1"><i class="fa fa-check"></i>Calculus</a></li>
<li class="chapter" data-level="" data-path="solutions-to-warmup-questions.html"><a href="solutions-to-warmup-questions.html#optimization-1"><i class="fa fa-check"></i>Optimization</a></li>
<li class="chapter" data-level="" data-path="solutions-to-warmup-questions.html"><a href="solutions-to-warmup-questions.html#probability-1"><i class="fa fa-check"></i>Probability</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="suggested-programming-solutions.html"><a href="suggested-programming-solutions.html"><i class="fa fa-check"></i>Suggested Programming Solutions</a><ul>
<li class="chapter" data-level="16.5" data-path="suggested-programming-solutions.html"><a href="suggested-programming-solutions.html#chapter-refdataviz-visualization"><i class="fa fa-check"></i><b>16.5</b> Chapter @ref(dataviz): Visualization</a><ul>
<li class="chapter" data-level="" data-path="suggested-programming-solutions.html"><a href="suggested-programming-solutions.html#state-proportions"><i class="fa fa-check"></i>1 State Proportions</a></li>
<li class="chapter" data-level="" data-path="suggested-programming-solutions.html"><a href="suggested-programming-solutions.html#swing-justice"><i class="fa fa-check"></i>2 Swing Justice</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="suggested-programming-solutions.html"><a href="suggested-programming-solutions.html#chapter-refrobjloops-objects-and-loops"><i class="fa fa-check"></i><b>16.6</b> Chapter @ref(robjloops): Objects and Loops</a><ul>
<li class="chapter" data-level="" data-path="suggested-programming-solutions.html"><a href="suggested-programming-solutions.html#checkpoint-3"><i class="fa fa-check"></i>Checkpoint #3</a></li>
<li class="chapter" data-level="" data-path="suggested-programming-solutions.html"><a href="suggested-programming-solutions.html#exercise-2"><i class="fa fa-check"></i>Exercise 2</a></li>
<li class="chapter" data-level="" data-path="suggested-programming-solutions.html"><a href="suggested-programming-solutions.html#exercise-3"><i class="fa fa-check"></i>Exercise 3</a></li>
</ul></li>
<li class="chapter" data-level="16.7" data-path="suggested-programming-solutions.html"><a href="suggested-programming-solutions.html#chapter-refdempeace-demoratic-peace-project"><i class="fa fa-check"></i><b>16.7</b> Chapter @ref(dempeace): Demoratic Peace Project</a><ul>
<li class="chapter" data-level="" data-path="suggested-programming-solutions.html"><a href="suggested-programming-solutions.html#task-1-data-input-and-standardization-1"><i class="fa fa-check"></i>Task 1: Data Input and Standardization</a></li>
<li class="chapter" data-level="" data-path="suggested-programming-solutions.html"><a href="suggested-programming-solutions.html#task-2-data-merging-1"><i class="fa fa-check"></i>Task 2: Data Merging</a></li>
<li class="chapter" data-level="" data-path="suggested-programming-solutions.html"><a href="suggested-programming-solutions.html#task-3-tabulations-and-visualization-1"><i class="fa fa-check"></i>Task 3: Tabulations and Visualization</a></li>
</ul></li>
<li class="chapter" data-level="16.8" data-path="suggested-programming-solutions.html"><a href="suggested-programming-solutions.html#chapter-refsimulation-simulation"><i class="fa fa-check"></i><b>16.8</b> Chapter @ref(simulation): Simulation</a><ul>
<li class="chapter" data-level="16.8.1" data-path="suggested-programming-solutions.html"><a href="suggested-programming-solutions.html#census-sampling-1"><i class="fa fa-check"></i><b>16.8.1</b> Census Sampling</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Math Prefresher for Political Scientists</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probability-theory" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Probability Theory</h1>
<p>Probability and Inferences are mirror images of each other, and both are integral to social science. Probability quantifies uncertainty, which is important because many things in the social world are at first uncertain. Inference is then the study of how to learn about facts you don’t observe from facts you do observe.</p>
<div id="counting-rules" class="section level2">
<h2><span class="header-section-number">5.1</span> Counting rules</h2>
<p><strong>Fundamental Theorem of Counting</strong>: If an object has <span class="math inline">\(j\)</span> different characteristics that are independent of each other, and each characteristic <span class="math inline">\(i\)</span> has <span class="math inline">\(n_i\)</span> ways of being expressed, then there are <span class="math inline">\(\prod_{i = 1}^j n_i\)</span> possible unique objects.</p>
<p>Example: Cards can be either red or black and can take on any of 13 values.</p>
<p><span class="math inline">\(j =\)</span></p>
<p><span class="math inline">\(n_{\text{color}} =\)</span></p>
<p><span class="math inline">\(n_{\text{number}} =\)</span></p>
<p>Number of Outcomes <span class="math inline">\(=\)</span></p>
<p>We often need to count the number of ways to choose a subset from some set of possibilities. The number of outcomes depends on two characteristics of the process: does the order matter and is replacement allowed?</p>
<p><strong>Sampling Table</strong>: If there are <span class="math inline">\(n\)</span> objects which are numbered 1 to <span class="math inline">\(n\)</span> and we select <span class="math inline">\(k &lt; n\)</span> of them, how many different outcomes are possible?</p>
<p>If the order in which a given object is selected matters, selecting 4 numbered objects in the following order (1, 3, 7, 2) and selecting the same four objects but in a different order such as (7, 2, 1, 3) will be counted as different outcomes.</p>
<p>If replacement is allowed, there are always the same <span class="math inline">\(n\)</span> objects to select from. However, if replacement is not allowed, there is always one less option than the previous round when making a selection. For example, if replacement is not allowed and I am selecting 3 elements from the following set {1, 2, 3, 4, 5, 6}, I will have 6 options at first, 5 options as I make my second selection, and 4 options as I make my third.</p>
<p>So in counting how many different outcomes are possible, if <strong><em>order matters</em></strong> AND we are sampling <strong><em>with replacement</em></strong>, the number of different outcomes is <span class="math inline">\(n^k\)</span>.</p>
<p>If <strong><em>order matters</em></strong> AND we are sampling <strong><em>without replacement</em></strong>, the number of different outcomes is <span class="math inline">\(n(n-1)(n-2)...(n-k+1)=\frac{n!}{(n-k)!}\)</span>.</p>
<p>If <strong><em>order doesn’t matter</em></strong> AND we are sampling <strong><em>without replacement</em></strong>, the number of different outcomes is <span class="math inline">\(\binom{n}{k} = \frac{n!}{(n-k)!k!}\)</span>.</p>
<p>Expression <span class="math inline">\(\binom{n}{k}\)</span> is read as “n choose k” and denotes <span class="math inline">\(\frac{n!}{(n-k)!k!}\)</span>. Also, note that <span class="math inline">\(0! = 1\)</span>.</p>

<div class="example">
<p><span id="exm:counting" class="example"><strong>Example 5.1  (Counting)  </strong></span> There are five balls numbered from 1 through 5 in a jar. Three balls are chosen. How many possible choices are there?</p>
<ol style="list-style-type: decimal">
<li><p>Ordered, with replacement <span class="math inline">\(=\)</span></p></li>
<li><p>Ordered, without replacement <span class="math inline">\(=\)</span></p></li>
<li><p>Unordered, without replacement <span class="math inline">\(=\)</span></p></li>
</ol>
</div>


<div class="exercise">
<p><span id="exr:counting1" class="exercise"><strong>Exercise 5.1  (Counting)  </strong></span> Four cards are selected from a deck of 52 cards. Once a card has been drawn, it is not reshuffled back into the deck. Moreover, we care only about the complete hand that we get (i.e. we care about the set of selected cards, not the sequence in which it was drawn). How many possible outcomes are there?</p>
</div>

</div>
<div id="setoper" class="section level2">
<h2><span class="header-section-number">5.2</span> Sets</h2>
<p><strong>Set</strong> : A set is any well defined collection of elements. If <span class="math inline">\(x\)</span> is an element of <span class="math inline">\(S\)</span>, <span class="math inline">\(x \in S\)</span>.</p>
<p><strong>Sample Space (S)</strong>: A set or collection of all possible outcomes from some process. Outcomes in the set can be discrete elements (countable) or points along a continuous interval (uncountable).</p>
<p>Examples:</p>
<ol style="list-style-type: decimal">
<li>Discrete: the numbers on a die, whether a vote cast is republican or democrat.</li>
<li>Continuous: GNP, arms spending, age.</li>
</ol>
<p><strong>Event</strong>: Any collection of possible outcomes of an experiment. Any subset of the full set of possibilities, including the full set itself. Event A <span class="math inline">\(\subset\)</span> S.</p>
<p><strong>Empty Set</strong>: a set with no elements. <span class="math inline">\(S = \{\}\)</span>. It is denoted by the symbol <span class="math inline">\(\emptyset\)</span>.</p>
<p>Set operations:</p>
<ol style="list-style-type: decimal">
<li><strong>Union</strong>: The union of two sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, <span class="math inline">\(A \cup B\)</span>, is the set containing all of the elements in <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span>. <span class="math display">\[A_1 \cup A_2  \cup \cdots \cup A_n = \bigcup_{i=1}^n A_i\]</span></li>
<li><strong>Intersection</strong>: The intersection of sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, <span class="math inline">\(A \cap B\)</span>, is the set containing all of the elements in both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. <span class="math display">\[A_1 \cap A_2  \cap \cdots \cap A_n = \bigcap_{i=1}^n A_i\]</span></li>
<li><strong>Complement</strong>: If set <span class="math inline">\(A\)</span> is a subset of <span class="math inline">\(S\)</span>, then the complement of <span class="math inline">\(A\)</span>, denoted <span class="math inline">\(A^C\)</span>, is the set containing all of the elements in <span class="math inline">\(S\)</span> that are not in <span class="math inline">\(A\)</span>.</li>
</ol>
<p>Properties of set operations:</p>
<ul>
<li><strong>Commutative</strong>: <span class="math inline">\(A \cup B = B \cup A\)</span>; <span class="math inline">\(A \cap B = B \cap A\)</span></li>
<li><strong>Associative</strong>: <span class="math inline">\(A \cup (B \cup C) = (A \cup B) \cup C\)</span>; <span class="math inline">\(A \cap (B \cap C) = (A \cap B) \cap C\)</span></li>
<li><strong>Distributive</strong>: <span class="math inline">\(A \cap (B \cup C) = (A \cap B) \cup (A \cap C)\)</span>; <span class="math inline">\(A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\)</span></li>
<li><strong>de Morgan’s laws</strong>: <span class="math inline">\((A \cup B)^C = A^C \cap B^C\)</span>; <span class="math inline">\((A \cap B)^C = A^C \cup B^C\)</span></li>
<li><strong>Disjointness</strong>: Sets are disjoint when they do not intersect, such that <span class="math inline">\(A \cap B = \emptyset\)</span>. A collection of sets is pairwise disjoint (<strong>mutually exclusive</strong>) if, for all <span class="math inline">\(i \neq j\)</span>, <span class="math inline">\(A_i \cap A_j = \emptyset\)</span>. A collection of sets form a partition of set <span class="math inline">\(S\)</span> if they are pairwise disjoint and they cover set <span class="math inline">\(S\)</span>, such that <span class="math inline">\(\bigcup_{i = 1}^k A_i = S\)</span>.</li>
</ul>

<div class="example">
<p><span id="exm:sets" class="example"><strong>Example 5.2  (Sets)  </strong></span> Let set <span class="math inline">\(A\)</span> be {1, 2, 3, 4}, <span class="math inline">\(B\)</span> be {3, 4, 5, 6}, and <span class="math inline">\(C\)</span> be {5, 6, 7, 8}. Sets <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, and <span class="math inline">\(C\)</span> are all subsets of the sample space <span class="math inline">\(S\)</span> which is {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}</p>
<p>Write out the following sets:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(A \cup B\)</span></li>
<li><span class="math inline">\(C \cap B\)</span></li>
<li><span class="math inline">\(B^c\)</span></li>
<li><span class="math inline">\(A \cap (B \cup C)\)</span></li>
</ol>
</div>


<div class="exercise">
<p><span id="exr:sets1" class="exercise"><strong>Exercise 5.2  (Sets)  </strong></span></p>
<p>Suppose you had a pair of four-sided dice. You sum the results from a single toss.</p>
<p>What is the set of possible outcomes (i.e. the sample space)?</p>
<p>Consider subsets A {2, 8} and B {2,3,7} of the sample space you found. What is</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(A^c\)</span></li>
<li><span class="math inline">\((A \cup B)^c\)</span></li>
</ol>
</div>

</div>
<div id="probdef" class="section level2">
<h2><span class="header-section-number">5.3</span> Probability</h2>
<div class="figure"><span id="fig:prob-image"></span>
<img src="images/probability.png" alt="Probablity as a Measure^[Images of Probability and Random Variables drawn by Shiro Kuriwaki and inspired by Blitzstein and Morris]"  />
<p class="caption">
Figure 5.1: Probablity as a Measure<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>
</p>
</div>
<div id="probability-definitions-formal-and-informal" class="section level3 unnumbered">
<h3>Probability Definitions: Formal and Informal</h3>
<p>Many things in the world are uncertain. In everyday speech, we say that we are <em>uncertain</em> about the outcome of random events. Probability is a formal model of uncertainty which provides a measure of uncertainty governed by a particular set of rules (Figure <a href="probability-theory.html#fig:prob-image">5.1</a>). A different model of uncertainty would, of course, have a set of rules different from anything we discuss here. Our focus on probability is justified because it has proven to be a particularly useful model of uncertainty.</p>
<p><strong>Probability Distribution Function</strong>: a mapping of each event in the sample space <span class="math inline">\(S\)</span> to the real numbers that satisfy the following three axioms (also called Kolmogorov’s Axioms).</p>
<p>Formally,</p>

<div class="definition">
<p><span id="def:unnamed-chunk-66" class="definition"><strong>Definition 5.1  (Probability)  </strong></span> Probability is a function that maps events to a real number, obeying the axioms of probability.</p>
</div>

<p>The axioms of probability make sure that the separate events add up in terms of probability, and – for standardization purposes – that they add up to 1.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-67" class="definition"><strong>Definition 5.2  (Axioms of Probability)  </strong></span></p>
<ol style="list-style-type: decimal">
<li>For any event <span class="math inline">\(A\)</span>, <span class="math inline">\(P(A)\ge 0\)</span>.</li>
<li><span class="math inline">\(P(S)=1\)</span></li>
<li>The Countable Additivity Axiom: For any sequence of <em>disjoint</em> (mutually exclusive) events <span class="math inline">\(A_1,A_2,\ldots\)</span> (of which there may be infinitely many), <span class="math display">\[P\left( \bigcup\limits_{i=1}^k
A_i\right)=\sum\limits_{i=1}^k P(A_i)\]</span></li>
</ol>
<p>The last axiom is an extension of a union to infinite sets. When there are only two events in the space, it boils down to:</p>
<span class="math display">\[\begin{align*}
P(A_1 \cup A_2) = P(A_1) + P(A_2) \quad\text{for disjoint } A_1, A_2
\end{align*}\]</span>
</div>

</div>
<div id="probability-operations" class="section level3 unnumbered">
<h3>Probability Operations</h3>
<p>Using these three axioms, we can define all of the common rules of probability.</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(\emptyset)=0\)</span></li>
<li>For any event <span class="math inline">\(A\)</span>, <span class="math inline">\(0\le P(A) \le 1\)</span>.</li>
<li><span class="math inline">\(P({A}^C)=1-P(A)\)</span></li>
<li>If <span class="math inline">\(A\subset B\)</span> (<span class="math inline">\(A\)</span> is a subset of <span class="math inline">\(B\)</span>), then <span class="math inline">\(P(A)\le P(B)\)</span>.</li>
<li>For <em>any</em> two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, <span class="math inline">\(P(A\cup B)=P(A)+P(B)-P(A\cap B)\)</span></li>
<li>Boole’s Inequality: For any sequence of <span class="math inline">\(n\)</span> events (which need not be disjoint) <span class="math inline">\(A_1,A_2,\ldots,A_n\)</span>, then <span class="math inline">\(P\left( \bigcup\limits_{i=1}^n A_i\right) \leq \sum\limits_{i=1}^n P(A_i)\)</span>.</li>
</ol>

<div class="example">
<p><span id="exm:prob" class="example"><strong>Example 5.3  (Probability)  </strong></span> Assume we have an evenly-balanced, six-sided die.</p>
<p>Then,</p>
<ol style="list-style-type: decimal">
<li>Sample space S =</li>
<li><span class="math inline">\(P(1)=\cdots=P(6)=\)</span></li>
<li><span class="math inline">\(P(\emptyset)=P(7)=\)</span></li>
<li><span class="math inline">\(P\left( \{ 1, 3, 5 \} \right)=\)</span></li>
<li><span class="math inline">\(P\left( \{ 1, 2 \}^C \right)= P\left( \{ 3, 4, 5, 6 \}\right)=\)</span></li>
<li>Let <span class="math inline">\(A=\{ 1,2,3,4,5 \}\subset S\)</span>. Then <span class="math inline">\(P(A)=5/6&lt;P(S)=\)</span></li>
<li>Let <span class="math inline">\(A=\{ 1, 2, 3 \}\)</span> and <span class="math inline">\(B=\{ 2, 4, 6 \}\)</span>. Then <span class="math inline">\(A\cup B\)</span>? <span class="math inline">\(A\cap B\)</span>? <span class="math inline">\(P(A \cup B)\)</span>?</li>
</ol>
</div>


<div class="exercise">
<p><span id="exr:prob1" class="exercise"><strong>Exercise 5.3  (Probability)  </strong></span> Suppose you had a pair of four-sided dice. You sum the results from a single toss. Let us call this sum, or the outcome, X.</p>
<ol style="list-style-type: decimal">
<li><p>What is <span class="math inline">\(P(X = 5)\)</span>, <span class="math inline">\(P(X = 3)\)</span>, <span class="math inline">\(P(X = 6)\)</span>?</p></li>
<li><p>What is <span class="math inline">\(P(X=5 \cup X = 3)^C\)</span>?</p></li>
</ol>
</div>

</div>
</div>
<div id="conditional-probability-and-bayes-rule" class="section level2">
<h2><span class="header-section-number">5.4</span> Conditional Probability and Bayes Rule</h2>
<p><strong>Conditional Probability</strong>: The conditional probability <span class="math inline">\(P(A|B)\)</span> of an event <span class="math inline">\(A\)</span> is the probability of <span class="math inline">\(A\)</span>, given that another event <span class="math inline">\(B\)</span> has occurred. Conditional probability allows for the inclusion of other information into the calculation of the probability of an event. It is calculated as</p>
<p><span class="math display">\[P(A|B)=\frac{P(A\cap B)}{P(B)}\]</span></p>
<p>Note that conditional probabilities are probabilities and must also follow the Kolmagorov axioms of probability.</p>

<div class="example">
<p><span id="exm:condprobexm1" class="example"><strong>Example 5.4  (Conditional Probability 1)  </strong></span> Assume <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> occur with the following frequencies: <span class="math inline">\(\quad\)</span></p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center"><span class="math inline">\(A\)</span></th>
<th align="center"><span class="math inline">\(A^c\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(n_{ab}\)</span></td>
<td align="center"><span class="math inline">\(n_{a^cb}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(B^C\)</span></td>
<td align="center"><span class="math inline">\(n_{ab^c}\)</span></td>
<td align="center"><span class="math inline">\(n_{(ab)^c}\)</span></td>
</tr>
</tbody>
</table>
<p>and let <span class="math inline">\(n_{ab}+n_{a^Cb}+n_{ab^C}+n_{(ab)^C}=N\)</span>. Then</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(A)=\)</span></li>
<li><span class="math inline">\(P(B)=\)</span></li>
<li><span class="math inline">\(P(A\cap B)=\)</span></li>
<li><span class="math inline">\(P(A|B)= \frac{P(A\cap B)}{P(B)}=\)</span></li>
<li><span class="math inline">\(P(B|A)= \frac{P(A\cap B)}{P(A)}=\)</span></li>
</ol>
</div>


<div class="example">
<span id="exm:condprobexm2" class="example"><strong>Example 5.5  (Conditional Probability 2)  </strong></span> A six-sided die is rolled. What is the probability of a 1, given the outcome is an odd number?
</div>

<p>You could rearrange the fraction to highlight how a joint probability could be expressed as the product of a conditional probability.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-68" class="definition"><strong>Definition 5.3  (Multiplicative Law of Probability)  </strong></span> The probability of the intersection of two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> is <span class="math inline">\(P(A\cap B)=P(A)P(B|A)=P(B)P(A|B)\)</span> which follows directly from the definition of conditional probability. More generally,</p>
<p><span class="math display">\[P(A_1\cap \cdots\cap A_k) = P(A_k| A_{k-1}\cap \cdots \cap A_1)\times P(A_{k-1}|A_{k-2}\cap \cdots A_1) \times \ldots \times P(A_2|A_1)\times P(A_1)\]</span></p>
<p>Sometimes it is easier to calculate these conditional probabilities and sum them than it is to calculate <span class="math inline">\(P(A)\)</span> directly.</p>
</div>


<div class="definition">
<p><span id="def:unnamed-chunk-69" class="definition"><strong>Definition 5.4  (Law of Total Probability)  </strong></span>Let <span class="math inline">\(S\)</span> be the sample space of some experiment and let the disjoint <span class="math inline">\(k\)</span> events <span class="math inline">\(B_1,\ldots,B_k\)</span> partition <span class="math inline">\(S\)</span>, such that <span class="math inline">\(P(B_1\cup ... \cup B_k) = P(S) = 1\)</span>. If <span class="math inline">\(A\)</span> is some other event in <span class="math inline">\(S\)</span>, then the events <span class="math inline">\(A\cap B_1, A\cap B_2, \ldots, A\cap B_k\)</span> will form a partition of <span class="math inline">\(A\)</span> and we can write <span class="math inline">\(A\)</span> as <span class="math display">\[A=(A\cap B_1)\cup\cdots\cup (A\cap B_k)\]</span>.</p>
<p>Since the <span class="math inline">\(k\)</span> events are disjoint,</p>
<span class="math display">\[\begin{eqnarray*}
P(A)&amp;=&amp;\sum\limits_{i=1}^k P(A \cap B_i)\\
      &amp;=&amp;\sum\limits_{i=1}^k P(B_i)P(A|B_i)
\end{eqnarray*}\]</span>
</div>

<p><strong>Bayes Rule</strong>: Assume that events <span class="math inline">\(B_1,\ldots,B_k\)</span> form a partition of the space <span class="math inline">\(S\)</span>. Then by the Law of Total Probability</p>
<p><span class="math display">\[P(B_j|A)= \frac{P(A \cap B_j)} {P(A)} = \frac{P(B_j) P(A|B_j)}{\sum\limits_{i=1}^k P(B_i)P(A|B_i)}\]</span></p>
<p>If there are only two states of <span class="math inline">\(B\)</span>, then this is just <span class="math display">\[P(B_1|A)=\frac{P(B_1)P(A|B_1)} {P(B_1)P(A|B_1)+P(B_2)P(A|B_2)}\]</span></p>
<p>Bayes’ rule determines the posterior probability of a state <span class="math inline">\(P(B_j|A)\)</span> by calculating the probability <span class="math inline">\(P(A \cap B_j)\)</span> that both the event <span class="math inline">\(A\)</span> and the state <span class="math inline">\(B_j\)</span> will occur and dividing it by the probability that the event will occur regardless of the state (by summing across all <span class="math inline">\(B_i\)</span>). The states could be something like Normal/Defective, Healthy/Diseased, Republican/Democrat/Independent, etc. The event on which one conditions could be something like a sampling from a batch of components, a test for a disease, or a question about a policy position.</p>
<p><strong>Prior and Posterior Probabilities</strong>: Above, <span class="math inline">\(P(B_1)\)</span> is often called the prior probability, since it’s the probability of <span class="math inline">\(B_1\)</span> before anything else is known. <span class="math inline">\(P(B_1|A)\)</span> is called the posterior probability, since it’s the probability after other information is taken into account.</p>

<div class="example">
<p><span id="exm:bayesrule" class="example"><strong>Example 5.6  (Bayes’ Rule)  </strong></span> In a given town, 40% of the voters are Democrat and 60% are Republican. The president’s budget is supported by 50% of the Democrats and 90% of the Republicans. If a randomly (equally likely) selected voter is found to support the president’s budget, what is the probability that they are a Democrat?</p>
</div>


<div class="exercise">
<p><span id="exr:condprobexr" class="exercise"><strong>Exercise 5.4  (Conditional Probability)  </strong></span></p>
<p>Assume that 2% of the population of the U.S. are members of some extremist militia group. We develop a survey that positively classifies someone as being a member of a militia group given that they are a member 95% of the time and negatively classifies someone as not being a member of a militia group given that they are not a member 97% of the time. What is the probability that someone positively classified as being a member of a militia group is actually a militia member?</p>
</div>

</div>
<div id="independence" class="section level2">
<h2><span class="header-section-number">5.5</span> Independence</h2>

<div class="definition">
<p><span id="def:unnamed-chunk-70" class="definition"><strong>Definition 5.5  (Independence)  </strong></span> If the occurrence or nonoccurrence of either events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> have no effect on the occurrence or nonoccurrence of the other, then <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent.</p>
</div>

<p>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent, then</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(A|B)=P(A)\)</span></li>
<li><span class="math inline">\(P(B|A)=P(B)\)</span></li>
<li><span class="math inline">\(P(A\cap B)=P(A)P(B)\)</span></li>
<li>More generally than the above, <span class="math inline">\(P(\bigcap_{i=1}^k A_i) = \prod_{i = 1}^K P(A_i)\)</span></li>
</ol>
<p>Are mutually exclusive events independent of each other?</p>
<p>No. If A and B are mutually exclusive, then they cannot happen simultaneously. If we know that A occurred, then we know that B couldn’t have occurred. Because of this, A and B aren’t independent.</p>
<p><strong>Pairwise Independence</strong>: A set of more than two events <span class="math inline">\(A_1, A_2, \dots, A_k\)</span> is pairwise independent if <span class="math inline">\(P(A_i\cap A_j)=P(A_i)P(A_j)\)</span>, <span class="math inline">\(\forall i\neq j\)</span>. Note that this does <strong>not</strong> necessarily imply joint independence.</p>
<p><strong>Conditional Independence</strong>: If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent once you know the occurrence of a third event <span class="math inline">\(C\)</span>, then <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are conditionally independent (conditional on <span class="math inline">\(C\)</span>):</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(A|B \cap C)=P(A|C)\)</span></li>
<li><span class="math inline">\(P(B|A \cap C)=P(B|C)\)</span></li>
<li><span class="math inline">\(P(A\cap B|C)=P(A|C)P(B|C)\)</span></li>
</ol>
<p>Just because two events are conditionally independent does not mean that they are independent. Actually it is hard to think of real-world things that are “unconditionally” independent. That’s why it’s always important to ask about a finding: What was it conditioned on? For example, suppose that a graduate school admission decisions are done by only one professor, who picks a group of 50 bright students and flips a coin for each student to generate a class of about 25 students. Then the the probability that two students get accepted are conditionally independent, because they are determined by two separate coin tosses. However, this does not mean that their admittance is not completely independent. Knowing that student <span class="math inline">\(A\)</span> got in gives us information about whether student <span class="math inline">\(B\)</span> got in, if we think that the professor originally picked her pool of 50 students by merit.</p>
<p>Perhaps more counter-intuitively: If two events are already independent, then it might seem that no amount of “conditioning” will make them dependent. But this is not always so. For example<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>, suppose I only get a call from two people, Alice and Bob. Let <span class="math inline">\(A\)</span> be the event that Alice calls, and <span class="math inline">\(B\)</span> be the event that Bob calls. Alice and Bob do not communicate, so <span class="math inline">\(P(A \mid B) = P(A).\)</span> But now let <span class="math inline">\(C\)</span> be the event that your phone rings. For conditional independence to hold here, then <span class="math inline">\(P(A \mid C)\)</span> must be equal to <span class="math inline">\(P(A \mid B \cap C).\)</span> But this is not true – <span class="math inline">\(A \mid C\)</span> may or may not be true, but <span class="math inline">\(P(A \mid B \cap C)\)</span> certainly is true.</p>
</div>
<div id="random-variables" class="section level2">
<h2><span class="header-section-number">5.6</span> Random Variables</h2>
<p>Most questions in the social sciences involve events, rather than numbers per se. To analyze and reason about events quantitatively, we need a way of mapping events to numbers. A random variable does exactly that.</p>
<div class="figure"><span id="fig:rv-image"></span>
<img src="images/rv.png" alt="The Random Variable as a Real-Valued Function"  />
<p class="caption">
Figure 5.2: The Random Variable as a Real-Valued Function
</p>
</div>

<div class="definition">
<p><span id="def:unnamed-chunk-71" class="definition"><strong>Definition 5.6  (Random Variable)  </strong></span> A random variable is a measurable function <span class="math inline">\(X\)</span> that maps from the sample space <span class="math inline">\(S\)</span> to the set of real numbers <span class="math inline">\(R.\)</span> It assigns a real number to every outcome <span class="math inline">\(s \in S\)</span>.</p>
</div>

<p>Figure <a href="probability-theory.html#fig:rv-image">5.2</a> shows a image of the function. It might seem strange to define a random variable as a function – which is neither random nor variable. The randomness comes from the realization of an event from the sample space <span class="math inline">\(s\)</span>.</p>
<p><strong>Randomness</strong> means that the outcome of some experiment is not deterministic, i.e. there is some probability (<span class="math inline">\(0 &lt; P(A) &lt; 1\)</span>) that the event will occur.</p>
<p>The support of a random variable is all values for which there is a positive probability of occurrence.</p>
<p>Example: Flip a fair coin two times. What is the sample space?</p>
<p>A random variable must map events to the real line. For example, let a random variable <span class="math inline">\(X\)</span> be the number of heads. The event <span class="math inline">\((H, H)\)</span> gets mapped to 2 <span class="math inline">\(X(s) = 2\)</span>, and the events <span class="math inline">\(\{(H, T), (T, H)\}\)</span> gets mapped to 1 <span class="math inline">\((X(s) = 1)\)</span>, the event <span class="math inline">\((T, T)\)</span> gets mapped to 0 <span class="math inline">\((X(s) = 0)\)</span>.</p>
<p>What are other possible random variables?</p>
</div>
<div id="distributions" class="section level2">
<h2><span class="header-section-number">5.7</span> Distributions</h2>
<p>We now have two main concepts in this section – probability and random variables. Given a sample space <span class="math inline">\(S\)</span> and the same experiment, both probability and random variables take events as their inputs. But they output different things (probabilities measure the “size” of events, random variables give a number in a way that the analyst chose to define the random variable). How do the two concepts relate?</p>
<p>The concept of distributions is the natural bridge between these two concepts.</p>

<div class="definition">
<span id="def:unnamed-chunk-72" class="definition"><strong>Definition 5.7  (Distribution of a random variable)  </strong></span>A distribution of a random variable is a function that specifies the probabilities of all events associated with that random variable. There are several types of distributions: A probability mass function for a discrete random variable and probability density function for a continuous random variable.
</div>

<p>Notice how the definition of distributions combines two ideas of random variables and probabilities of events. First, the distribution considers a random variable, call it <span class="math inline">\(X\)</span>. <span class="math inline">\(X\)</span> can take a number of possible numeric values.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-73" class="example"><strong>Example 5.7  (Total Number of Occurrences)  </strong></span> Consider three binary outcomes, one for each patient recovering from a disease: <span class="math inline">\(R_i\)</span> denotes the event in which patient <span class="math inline">\(i\)</span> (<span class="math inline">\(i = 1, 2, 3\)</span>) recovers from a disease. <span class="math inline">\(R_1\)</span>, <span class="math inline">\(R_2\)</span>, and <span class="math inline">\(R_3\)</span>. How would we represent the total number of people who end up recovering from the disease?</p>
</div>


<div class="solution">
<p> <span class="solution"><em>Solution. </em></span> Define the random variable <span class="math inline">\(X\)</span> be the total number of people (out of three) who recover from the disease. Random variables are functions, that take as an input a set of events (in the sample space <span class="math inline">\(S\)</span>) and deterministically assigns them to a number of the analyst’s choice.</p>
</div>

<p>Recall that with each of these numerical values there is a class of <em>events</em>. In the previous example, for <span class="math inline">\(X = 3\)</span> there is one outcome (<span class="math inline">\(R_1, R_2, R_3\)</span>) and for <span class="math inline">\(X = 1\)</span> there are multiple (<span class="math inline">\(\{(R_1, R_2^c, R_3^c), (R_1^c, R_2, R_3^c), (R_1^c, R_2^c, R_3), \}\)</span>). Now, the thing to notice here is that each of these events naturally come with a probability associated with them. That is, <span class="math inline">\(P(R_1, R_2, R_3)\)</span> is a number from 0 to 1, as is <span class="math inline">\(P(R_1, R_2^c, R_3^c)\)</span>. These all have probabilities because they are in the sample space <span class="math inline">\(S\)</span>. The function that tells us these probabilities that are associated with a numerical value of a random variable is called a distribution.</p>
<p>In other words, a random variable <span class="math inline">\(X\)</span> <em>induces a probability distribution</em> <span class="math inline">\(P\)</span> (sometimes written <span class="math inline">\(P_X\)</span> to emphasize that the probability density is about the r.v. <span class="math inline">\(X\)</span>)</p>
<div id="discrete-random-variables" class="section level3 unnumbered">
<h3>Discrete Random Variables</h3>
<p>The formal definition of a random variable is easier to given by separating out two cases: discrete random variables when the numeric summaries of the events are discrete, and continuous random variables when they are continuous.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-75" class="definition"><strong>Definition 5.8  (Discrete Random Variable)  </strong></span><span class="math inline">\(X\)</span> is a discrete random variable if it can assume only a finite or countably infinite number of distinct values. Examples: number of wars per year, heads or tails.</p>
</div>

<p>The distribution of a discrete r.v. is a PMF:</p>

<div class="definition">
<p><span id="def:unnamed-chunk-76" class="definition"><strong>Definition 5.9  (Probability Mass Function)  </strong></span> For a discrete random variable <span class="math inline">\(X\)</span>, the probability mass function (Also referred to simply as the “probability distribution.”) (PMF), <span class="math inline">\(p(x)=P(X=x)\)</span>, assigns probabilities to a countable number of distinct <span class="math inline">\(x\)</span> values such that</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(0\le p(x)\le 1\)</span></li>
<li><span class="math inline">\(\sum\limits_y p(x)=1\)</span></li>
</ol>
</div>

<p>Example: For a fair six-sided die, there is an equal probability of rolling any number. Since there are six sides, the probability mass function is then <span class="math inline">\(p(y)=1/6\)</span> for <span class="math inline">\(y=1,\ldots,6\)</span>, 0 otherwise.}</p>

<p>In a discrete random variable, <strong>cumulative density function</strong> (Also referred to simply as the “cumulative distribution” or previously as the “density function”), <span class="math inline">\(F(x)\)</span> or <span class="math inline">\(P(X\le x)\)</span>, is the probability that <span class="math inline">\(X\)</span> is less than or equal to some value <span class="math inline">\(x\)</span>, or <span class="math display">\[P(X\le x)=\sum\limits_{i\le x} p(i)\]</span></p>
<p>Properties a CDF must satisfy:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(F(x)\)</span> is non-decreasing in <span class="math inline">\(x\)</span>.</li>
<li><span class="math inline">\(\lim\limits_{x \to -\infty} F(x) = 0\)</span> and <span class="math inline">\(\lim\limits_{x \to \infty} F(x) = 1\)</span></li>
<li><span class="math inline">\(F(x)\)</span> is right-continuous.</li>
</ol>
<p>Note that <span class="math inline">\(P(X &gt; x) = 1 - P(X \le x)\)</span>.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-77" class="example"><strong>Example 5.8  </strong></span>For a fair die with its value as <span class="math inline">\(Y\)</span>, What are the following?</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(Y\le 1)\)</span></li>
<li><span class="math inline">\(P(Y\le 3)\)</span></li>
<li><span class="math inline">\(P(Y\le 6)\)</span></li>
</ol>
</div>

</div>
<div id="continuous-random-variables" class="section level3 unnumbered">
<h3>Continuous Random Variables</h3>
<p>We also have a similar definition for <em>continuous</em> random variables.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-78" class="definition"><strong>Definition 5.10  (Continuous Random Variable)  </strong></span> <span class="math inline">\(X\)</span> is a continuous random variable if there exists a nonnegative function <span class="math inline">\(f(x)\)</span> defined for all real <span class="math inline">\(x\in (-\infty,\infty)\)</span>, such that for any interval <span class="math inline">\(A\)</span>, <span class="math inline">\(P(X\in A)=\int\limits_A f(x)dx\)</span>. Examples: age, income, GNP, temperature.</p>
</div>


<div class="definition">
<p><span id="def:unnamed-chunk-79" class="definition"><strong>Definition 5.11  (Probability Density Function)  </strong></span> The function <span class="math inline">\(f\)</span> above is called the probability density function (pdf) of <span class="math inline">\(X\)</span> and must satisfy <span class="math display">\[f(x)\ge 0\]</span> <span class="math display">\[\int\limits_{-\infty}^\infty f(x)dx=1\]</span></p>
Note also that <span class="math inline">\(P(X = x)=0\)</span> — i.e., the probability of any point <span class="math inline">\(y\)</span> is zero.
</div>


<p>For both discrete and continuous random variables, we have a unifying concept of another measure: the cumulative distribution:</p>

<div class="definition">
<p><span id="def:unnamed-chunk-80" class="definition"><strong>Definition 5.12  (Cumulative Density Function)  </strong></span>Because the probability that a continuous random variable will assume any particular value is zero, we can only make statements about the probability of a continuous random variable being within an interval. The cumulative distribution gives the probability that <span class="math inline">\(Y\)</span> lies on the interval <span class="math inline">\((-\infty,y)\)</span> and is defined as <span class="math display">\[F(x)=P(X\le x)=\int\limits_{-\infty}^x f(s)ds\]</span> Note that <span class="math inline">\(F(x)\)</span> has similar properties with continuous distributions as it does with discrete - non-decreasing, continuous (not just right-continuous), and <span class="math inline">\(\lim\limits_{x \to -\infty} F(x) = 0\)</span> and <span class="math inline">\(\lim\limits_{x \to \infty} F(x) = 1\)</span>.</p>
</div>

<p>We can also make statements about the probability of <span class="math inline">\(Y\)</span> falling in an interval <span class="math inline">\(a\le y\le b\)</span>. <span class="math display">\[P(a\le x\le b)=\int\limits_a^b f(x)dx\]</span></p>
<p>The PDF and CDF are linked by the integral: The CDF of the integral of the PDF: <span class="math display">\[f(x) = F&#39;(x)=\frac{dF(x)}{dx}\]</span></p>

<div class="example">
<p><span id="exm:unnamed-chunk-81" class="example"><strong>Example 5.9  </strong></span> For <span class="math inline">\(f(y)=1, \quad 0&lt;y&lt;1\)</span>, find: (1) The CDF <span class="math inline">\(F(y)\)</span> and (2) The probability <span class="math inline">\(P(0.5&lt;y&lt;0.75)\)</span>.</p>
</div>

</div>
</div>
<div id="joint-distributions" class="section level2">
<h2><span class="header-section-number">5.8</span> Joint Distributions</h2>
<p>Often, we are interested in two or more random variables defined on the same sample space. The distribution of these variables is called a joint distribution. Joint distributions can be made up of any combination of discrete and continuous random variables.</p>
<p><strong>Joint Probability Distribution</strong>: If both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are random variable, their joint probability mass/density function assigns probabilities to each pair of outcomes</p>
<p>Discrete:</p>
<p><span class="math display">\[p(x, y) = P(X = x, Y = y)\]</span></p>
<p>such that <span class="math inline">\(p(x,y) \in [0,1]\)</span> and <span class="math display">\[\sum\sum p(x,y) = 1\]</span></p>
<p>Continuous:</p>
<p><span class="math display">\[f(x,y);P((X,Y) \in A) = \int\!\!\!\int_A f(x,y)dx dy \]</span></p>
<p>s.t. <span class="math inline">\(f(x,y)\ge 0\)</span> and</p>
<p><span class="math display">\[\int_{-\infty}^\infty\int_{-\infty}^\infty f(x,y)dxdy = 1\]</span></p>
<p>If X and Y are independent, then <span class="math inline">\(P(X=x,Y=y) = P(X=x)P(Y=y)\)</span> and <span class="math inline">\(f(x,y) = f(x)f(y)\)</span></p>
<p><strong>Marginal Probability Distribution</strong>: probability distribution of only one of the two variables (ignoring information about the other variable), we can obtain the marginal distribution by summing/integrating across the variable that we don’t care about:</p>
<ul>
<li>Discrete: <span class="math inline">\(p_X(x) = \sum_i p(x, y_i)\)</span></li>
<li>Continuous: <span class="math inline">\(f_X(x) = \int_{-\infty}^\infty f(x,y)dy\)</span></li>
</ul>
<p><strong>Conditional Probability Distribution</strong>: probability distribution for one variable, holding the other variable fixed. Recalling from the previous lecture that <span class="math inline">\(P(A|B)=\frac{P(A\cap B)}{P(B)}\)</span>, we can write the conditional distribution as</p>
<ul>
<li>Discrete: <span class="math inline">\(p_{Y|X}(y|x) = \frac{p(x,y)}{p_X(x)}, \quad p_X(x) &gt; 0\)</span></li>
<li>Continuous: <span class="math inline">\(f_{Y|X}(y|x) = \frac{f(x,y)}{f_X(x)},\quad f_X(x) &gt; 0\)</span></li>
</ul>

<div class="exercise">
<p><span id="exr:unnamed-chunk-82" class="exercise"><strong>Exercise 5.5  (Discrete Outcomes)  </strong></span>Suppose we are interested in the outcomes of flipping a coin and rolling a 6-sided die at the same time. The sample space for this process contains 12 elements: <span class="math display">\[\{(H, 1), (H, 2), (H, 3), (H, 4), (H, 5), (H, 6), (T, 1), (T, 2), (T, 3), (T, 4), (T, 5), (T, 6)\}\]</span> We can define two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> such that <span class="math inline">\(X = 1\)</span> if heads and <span class="math inline">\(X = 0\)</span> if tails, while <span class="math inline">\(Y\)</span> equals the number on the die.</p>
<p>We can then make statements about the joint distribution of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. What are the following?</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(X=x)\)</span></li>
<li><span class="math inline">\(P(Y=y)\)</span></li>
<li><span class="math inline">\(P(X=x, Y=y)\)</span></li>
<li><span class="math inline">\(P(X=x|Y=y)\)</span></li>
<li>Are X and Y independent?</li>
</ol>
</div>

</div>
<div id="expectation" class="section level2">
<h2><span class="header-section-number">5.9</span> Expectation</h2>
<p>We often want to summarize some characteristics of the distribution of a random variable. The most important summary is the expectation (or expected value, or mean), in which the possible values of a random variable are weighted by their probabilities.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-83" class="definition"><strong>Definition 5.13  (Expectation of a Discrete Random Variable)  </strong></span>The expected value of a discrete random variable <span class="math inline">\(Y\)</span> is <span class="math display">\[E(Y)=\sum\limits_{y} y P(Y=y)= \sum\limits_{y} y p(y)\]</span><br />
In words, it is the weighted average of all possible values of <span class="math inline">\(Y\)</span>, weighted by the probability that <span class="math inline">\(y\)</span> occurs. It is not necessarily the number we would expect <span class="math inline">\(Y\)</span> to take on, but the average value of <span class="math inline">\(Y\)</span> after a large number of repetitions of an experiment.</p>
</div>


<div class="example">
<p><span id="exm:expectdiscrete" class="example"><strong>Example 5.10  (Expectation of a Discrete Random Variable)  </strong></span></p>
<p>What is the expectation of a fair, six-sided die?</p>
</div>

<p><strong>Expectation of a Continuous Random Variable</strong>: The expected value of a continuous random variable is similar in concept to that of the discrete random variable, except that instead of summing using probabilities as weights, we integrate using the density to weight. Hence, the expected value of the continuous variable <span class="math inline">\(Y\)</span> is defined by <span class="math display">\[E(Y)=\int\limits_{y} y f(y) dy\]</span></p>

<div class="example">
<p><span id="exm:expectconti" class="example"><strong>Example 5.11  (Expectation of a Continuous Random Variable)  </strong></span></p>
<p>Find <span class="math inline">\(E(Y)\)</span> for <span class="math inline">\(f(y)=\frac{1}{1.5}, \quad 0&lt;y&lt;1.5\)</span>.</p>
</div>

<div id="expected-value-of-a-function" class="section level3 unnumbered">
<h3>Expected Value of a Function</h3>
<p>Remember: An Expected Value is a type of weighted average. We can extend this to composite functions. For random variable <span class="math inline">\(Y\)</span>,</p>
<p>If <span class="math inline">\(Y\)</span> is Discrete with PMF <span class="math inline">\(p(y)\)</span>,</p>
<p><span class="math display">\[E[g(Y)]=\sum\limits_y g(y)p(y)\]</span></p>
<p>If <span class="math inline">\(Y\)</span> is Continuous with PDF <span class="math inline">\(f(y)\)</span>,</p>
<p><span class="math display">\[E[g(Y)]=\int\limits_{-\infty}^\infty g(y)f(y)dy\]</span></p>
</div>
<div id="properties-of-expected-values" class="section level3 unnumbered">
<h3>Properties of Expected Values</h3>
<p>Dealing with Expectations is easier when the thing inside is a sum. The intuition behind this that Expectation is an integral, which is a type of sum.</p>
<ol style="list-style-type: decimal">
<li>Expectation of a constant is a constant <span class="math display">\[E(c)=c\]</span></li>
<li>Constants come out <span class="math display">\[E(c g(Y))= c E(g(Y))\]</span></li>
<li>Expectation is Linear <span class="math display">\[E(g(Y_1) + \cdots + g(Y_n))=E(g(Y_1)) +\cdots+E(g(Y_n)),\]</span> regardless of independence</li>
<li>Expected Value of Expected Values: <span class="math display">\[E(E(Y)) = E(Y)\]</span> (because the expected value of a random variable is a constant)</li>
</ol>
<p>Finally, if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent, even products are easy:</p>
<p><span class="math display">\[E(XY) = E(X)E(Y)\]</span></p>
<p><strong>Conditional Expectation</strong>: With joint distributions, we are often interested in the expected value of a variable <span class="math inline">\(Y\)</span> if we could hold the other variable <span class="math inline">\(X\)</span> fixed. This is the conditional expectation of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X = x\)</span>:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(Y\)</span> discrete: <span class="math inline">\(E(Y|X = x) = \sum_y yp_{Y|X}(y|x)\)</span></li>
<li><span class="math inline">\(Y\)</span> continuous: <span class="math inline">\(E(Y|X = x) = \int_y yf_{Y|X}(y|x)dy\)</span></li>
</ol>
<p>The conditional expectation is often used for prediction when one knows the value of <span class="math inline">\(X\)</span> but not <span class="math inline">\(Y\)</span></p>
</div>
</div>
<div id="variance-and-covariance" class="section level2">
<h2><span class="header-section-number">5.10</span> Variance and Covariance</h2>
<p>We can also look at other summaries of the distribution, which build on the idea of taking expectations. Variance tells us about the “spread” of the distribution; it is the expected value of the squared deviations from the mean of the distribution. The standard deviation is simply the square root of the variance.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-84" class="definition"><strong>Definition 5.14  (Variance)  </strong></span>The Variance of a Random Variable <span class="math inline">\(Y\)</span> is</p>
<p><span class="math display">\[\text{Var}(Y) = E[(Y - E(Y))^2] =  E(Y^2)-[E(Y)]^2\]</span></p>
<p>The Standard Deviation is the square root of the variance : <span class="math display">\[SD(Y) = \sigma_Y= \sqrt{\text{Var}(Y)}\]</span></p>
</div>


<div class="example">
<p><span id="exm:var" class="example"><strong>Example 5.12  (Variance)  </strong></span></p>
<p>Given the following PMF: <span class="math display">\[f(x) =  \begin{cases}
              \frac{3!}{x!(3-x)!}(\frac{1}{2})^3 \quad x = 0,1,2,3\\
               0 \quad otherwise
            \end{cases}
               \]</span></p>
<p>What is <span class="math inline">\(\text{Var}(x)\)</span>?</p>
<p><strong>Hint:</strong> First calculate <span class="math inline">\(E(X)\)</span> and <span class="math inline">\(E(X^2)\)</span></p>
</div>


<div class="definition">
<p><span id="def:unnamed-chunk-85" class="definition"><strong>Definition 5.15  (Covariance and Correlation)  </strong></span> The covariance measures the degree to which two random variables vary together; if the covariance between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is positive, X tends to be larger than its mean when Y is larger than its mean.</p>
<p><span class="math display">\[\text{Cov}(X,Y) = E[(X - E(X))(Y - E(Y))] \]</span> We can also write this as</p>
<span class="math display">\[\begin{align*}
\text{Cov}(X,Y) &amp;= E\left(XY - XE(Y) - E(X)Y + E(X)E(Y)\right)\\
&amp;= E(XY) - E(X)E(Y) - E(X)E(Y) + E(X)E(Y)\\
&amp;= E(XY) - E(X)E(Y)
\end{align*}\]</span>
</div>

<p>The covariance of a variable with itself is the variance of that variable.</p>
<p>The Covariance is unfortunately hard to interpret in magnitude. The correlation is a standardized version of the covariance, and always ranges from -1 to 1.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-86" class="definition"><strong>Definition 5.16  (Correlation)  </strong></span>The correlation coefficient is the covariance divided by the standard deviations of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. It is a unitless measure and always takes on values in the interval <span class="math inline">\([-1,1]\)</span>.</p>
<p><span class="math display">\[\text{Corr}(X, Y) = \frac{\text{Cov}(X,Y)}{\sqrt{\text{Var}(X)\text{Var}(Y)}} = \frac{\text{Cov}(X,Y)}{SD(X)SD(Y)}\]</span></p>
</div>

<p><strong><em>Properties of Variance and Covariance:</em></strong></p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\text{Var}(c) = 0\)</span></li>
<li><span class="math inline">\(\text{Var}(cY) = c^2 \text{Var}(Y)\)</span></li>
<li><span class="math inline">\(\text{Cov}(Y,Y) = \text{Var}(Y)\)</span></li>
<li><span class="math inline">\(\text{Cov}(X,Y) = \text{Cov}(Y,X)\)</span></li>
<li><span class="math inline">\(\text{Cov}(aX,bY) = ab \text{Cov}(X,Y)\)</span></li>
<li><span class="math inline">\(\text{Cov}(X+a,Y) = \text{Cov}(X,Y)\)</span></li>
<li><span class="math inline">\(\text{Cov}(X+Z,Y+W) = \text{Cov}(X,Y) + \text{Cov}(X,W) + \text{Cov}(Z,Y) + \text{Cov}(Z,W)\)</span></li>
<li><span class="math inline">\(\text{Var}(X+Y) = \text{Var}(X) + \text{Var}(Y) + 2\text{Cov}(X,Y)\)</span></li>
</ol>

<div class="exercise">
<span id="exr:expvar" class="exercise"><strong>Exercise 5.6  (Expectation and Variance)  </strong></span> Suppose we have a PMF with the following characteristics:
<span class="math display">\[\begin{eqnarray*}
  P(X = -2) = \frac{1}{5}\\
  P(X = -1) = \frac{1}{6}\\
  P(X = 0) = \frac{1}{5}\\
  P(X = 1) = \frac{1}{15}\\
  P(X = 2) = \frac{11}{30}
\end{eqnarray*}\]</span>
<ol style="list-style-type: decimal">
<li>Calculate the expected value of X</li>
</ol>
<p>Define the random variable <span class="math inline">\(Y = X^2\)</span>.</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Calculate the expected value of Y. (Hint: It would help to derive the PMF of Y first in order to calculate the expected value of Y in a straightforward way)</p></li>
<li><p>Calculate the variance of X.</p></li>
</ol>
</div>


<div class="exercise">
<p><span id="exr:expvar2" class="exercise"><strong>Exercise 5.7  (Expectation and Variance 2)  </strong></span></p>
<ol style="list-style-type: decimal">
<li>Find the expectation and variance</li>
</ol>
<p>Given the following PDF: <span class="math display">\[f(x) =  \begin{cases}
              \frac{3}{10}(3x - x^2) \quad 0 \leq x \leq 2\\
               0 \quad otherwise
            \end{cases}
               \]</span></p>
</div>


<div class="exercise">
<p><span id="exr:expvar3" class="exercise"><strong>Exercise 5.8  (Expectation and Variance 3)  </strong></span></p>
<ol style="list-style-type: decimal">
<li>Find the mean and standard deviation of random variable X. The PDF of this X is as follows:</li>
</ol>
<p><span class="math display">\[f(x) =  \begin{cases}
              \frac{1}{4}x \quad 0 \leq x \leq 2\\
               \frac{1}{4}(4 - x)  \quad 2 \leq x \leq 4\\
               0 \quad otherwise
            \end{cases}
               \]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Next, calculate <span class="math inline">\(P(X &lt; \mu - \sigma)\)</span> Remember, <span class="math inline">\(\mu\)</span> is the mean and <span class="math inline">\(\sigma\)</span> is the standard deviation</li>
</ol>
</div>

</div>
<div id="special-distributions" class="section level2">
<h2><span class="header-section-number">5.11</span> Special Distributions</h2>
<p>Two <em>discrete</em> distributions used often are:</p>

<div class="definition">
<span id="def:unnamed-chunk-87" class="definition"><strong>Definition 5.17  (Binomial Distribution)  </strong></span><span class="math inline">\(Y\)</span> is distributed binomial if it represents the number of “successes” observed in <span class="math inline">\(n\)</span> independent, identical “trials,” where the probability of success in any trial is <span class="math inline">\(p\)</span> and the probability of failure is <span class="math inline">\(q=1-p\)</span>.
</div>

<p>For any particular sequence of <span class="math inline">\(y\)</span> successes and <span class="math inline">\(n-y\)</span> failures, the probability of obtaining that sequence is <span class="math inline">\(p^y q^{n-y}\)</span> (by the multiplicative law and independence). However, there are <span class="math inline">\(\binom{n}{y}=\frac{n!}{(n-y)!y!}\)</span> ways of obtaining a sequence with <span class="math inline">\(y\)</span> successes and <span class="math inline">\(n-y\)</span> failures. So the binomial distribution is given by <span class="math display">\[p(y)=\binom{n}{y}p^y q^{n-y}, \quad y=0,1,2,\ldots,n\]</span> with mean <span class="math inline">\(\mu=E(Y)=np\)</span> and variance <span class="math inline">\(\sigma^2=\text{Var}(Y)=npq\)</span>.</p>

<div class="example">
<span id="exm:unnamed-chunk-88" class="example"><strong>Example 5.13  </strong></span>Republicans vote for Democrat-sponsored bills 2% of the time. What is the probability that out of 10 Republicans questioned, half voted for a particular Democrat-sponsored bill? What is the mean number of Republicans voting for Democrat-sponsored bills? The variance? 1. <span class="math inline">\(P(Y=5)=\)</span> 1. <span class="math inline">\(E(Y)=\)</span> 1. <span class="math inline">\(\text{Var}(Y)=6\)</span>
</div>



<div class="definition">
<p><span id="def:unnamed-chunk-89" class="definition"><strong>Definition 5.18  (Poisson Distribution)  </strong></span>A random variable <span class="math inline">\(Y\)</span> has a Poisson distribution if</p>
<p><span class="math display">\[P(Y = y)=\frac{\lambda^y}{y!}e^{-\lambda}, \quad y=0,1,2,\ldots, \quad \lambda&gt;0\]</span></p>
<p>The Poisson has the unusual feature that its expectation equals its variance: <span class="math inline">\(E(Y)=\text{Var}(Y)=\lambda\)</span>. The Poisson distribution is often used to model rare event counts: counts of the number of events that occur during some unit of time. <span class="math inline">\(\lambda\)</span> is often called the “arrival rate.”</p>
</div>


<div class="example">
<span id="exm:unnamed-chunk-90" class="example"><strong>Example 5.14  </strong></span>Border disputes occur between two countries through a Poisson Distribution, at a rate of 2 per month. What is the probability of 0, 2, and less than 5 disputes occurring in a month?
</div>


<p>Two <em>continuous</em> distributions used often are:</p>

<div class="definition">
<span id="def:unnamed-chunk-91" class="definition"><strong>Definition 5.19  (Uniform Distribution)  </strong></span>A random variable <span class="math inline">\(Y\)</span> has a continuous uniform distribution on the interval <span class="math inline">\((\alpha,\beta)\)</span> if its density is given by <span class="math display">\[f(y)=\frac{1}{\beta-\alpha}, \quad \alpha\le y\le \beta\]</span> The mean and variance of <span class="math inline">\(Y\)</span> are <span class="math inline">\(E(Y)=\frac{\alpha+\beta}{2}\)</span> and <span class="math inline">\(\text{Var}(Y)=\frac{(\beta-\alpha)^2}{12}\)</span>.
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-92" class="example"><strong>Example 5.15  </strong></span>For <span class="math inline">\(Y\)</span> uniformly distributed over <span class="math inline">\((1,3)\)</span>, what are the following probabilities?</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(Y=2)\)</span></li>
<li>Its density evaluated at 2, or <span class="math inline">\(f(2)\)</span></li>
<li><span class="math inline">\(P(Y \le 2)\)</span></li>
<li><span class="math inline">\(P(Y &gt; 2)\)</span></li>
</ol>
</div>



<div class="definition">
<p><span id="def:unnamed-chunk-93" class="definition"><strong>Definition 5.20  (Normal Distribution)  </strong></span> A random variable <span class="math inline">\(Y\)</span> is normally distributed with mean <span class="math inline">\(E(Y)=\mu\)</span> and variance <span class="math inline">\(\text{Var}(Y)=\sigma^2\)</span> if its density is</p>
<p><span class="math display">\[f(y)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(y-\mu)^2}{2\sigma^2}}\]</span></p>
</div>

<p>See Figure <a href="probability-theory.html#fig:normaldens">5.3</a> are various Normal Distributions with the same <span class="math inline">\(\mu = 1\)</span> and two versions of the variance.</p>
<div class="figure"><span id="fig:normaldens"></span>
<img src="prefresher_files/figure-html/normaldens-1.png" alt="Normal Distribution Density" width="672" />
<p class="caption">
Figure 5.3: Normal Distribution Density
</p>
</div>
</div>
<div id="summarizing-observed-events-data" class="section level2">
<h2><span class="header-section-number">5.12</span> Summarizing Observed Events (Data)</h2>
<p>So far, we’ve talked about distributions in a theoretical sense, looking at different properties of random variables. We don’t observe random variables; we observe realizations of the random variable. These realizations of events are roughly equivalent to what we mean by “data”.</p>
<p><strong>Sample mean</strong>: This is the most common measure of central tendency, calculated by summing across the observations and dividing by the number of observations. <span class="math display">\[\bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_i\]</span> The sample mean is an <em>estimate</em> of the expected value of a distribution.</p>

<p><strong>Dispersion</strong>: We also typically want to know how spread out the data are relative to the center of the observed distribution. There are several ways to measure dispersion.</p>
<p><strong>Sample variance</strong>: The sample variance is the sum of the squared deviations from the sample mean, divided by the number of observations minus 1. <span class="math display">\[ \hat{\text{Var}}(X) = \frac{1}{n-1}\sum_{i = 1}^n (x_i - \bar{x})^2\]</span></p>
<p>Again, this is an <em>estimate</em> of the variance of a random variable; we divide by <span class="math inline">\(n - 1\)</span> instead of <span class="math inline">\(n\)</span> in order to get an unbiased estimate.</p>
<p><strong>Standard deviation</strong>: The sample standard deviation is the square root of the sample variance. <span class="math display">\[ \hat{SD}(X) = \sqrt{\hat{\text{Var}}(X)} = \sqrt{\frac{1}{n-1}\sum_{i = 1}^n (x_i - \bar{x})^2}\]</span></p>

<p><strong>Covariance and Correlation</strong>: Both of these quantities measure the degree to which two variables vary together, and are estimates of the covariance and correlation of two random variables as defined above.</p>
<ol style="list-style-type: decimal">
<li><strong>Sample covariance</strong>: <span class="math inline">\(\hat{\text{Cov}}(X,Y) = \frac{1}{n-1}\sum_{i = 1}^n(x_i - \bar{x})(y_i - \bar{y})\)</span></li>
<li><strong>Sample correlation</strong>: <span class="math inline">\(\hat{\text{Corr}} = \frac{\hat{\text{Cov}}(X,Y)}{\sqrt{\hat{\text{Var}}(X)\hat{\text{Var}}(Y)}}\)</span></li>
</ol>

<div class="example">
<p><span id="exm:unnamed-chunk-94" class="example"><strong>Example 5.16  </strong></span>Example: Using the above table, calculate the sample versions of:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\text{Cov}(X,Y)\)</span></li>
<li><span class="math inline">\(\text{Corr}(X, Y)\)</span></li>
</ol>
</div>

</div>
<div id="asymptotic-theory" class="section level2">
<h2><span class="header-section-number">5.13</span> Asymptotic Theory</h2>
<p>In theoretical and applied research, asymptotic arguments are often made. In this section we briefly introduce some of this material.</p>
<p>What are asymptotics? In probability theory, asymptotic analysis is the study of limiting behavior. By limiting behavior, we mean the behavior of some random process as the number of observations gets larger and larger.</p>
<p>Why is this important? We rarely know the true process governing the events we see in the social world. It is helpful to understand how such unknown processes theoretically must behave and asymptotic theory helps us do this.</p>
<div id="clt-and-lln" class="section level3">
<h3><span class="header-section-number">5.13.1</span> CLT and LLN</h3>
<p>We are now finally ready to revisit, with a bit more precise terms, the two pillars of statistical theory we motivated Section <a href="limits-precalc.html#limitsfun">2.3</a> with.</p>

<div class="theorem">
<p><span id="thm:clt" class="theorem"><strong>Theorem 5.1  (Central Limit Theorem (i.i.d. case))  </strong></span>Let <span class="math inline">\(\{X_n\} = \{X_1, X_2, \ldots\}\)</span> be a sequence of i.i.d. random variables with finite mean (<span class="math inline">\(\mu\)</span>) and variance (<span class="math inline">\(\sigma^2\)</span>). Then, the sample mean <span class="math inline">\(\bar{X}_n = \frac{X_1 + X_2 + \cdots + X_n}{n}\)</span> increasingly converges into a Normal distribution.</p>
<p><span class="math display">\[\frac{\bar{X}_n - \mu}{\sigma / \sqrt{n}} \xrightarrow{d} \text{Normal}(0, 1),\]</span></p>
<p>Another way to write this as a probability statement is that for all real numbers <span class="math inline">\(a\)</span>,</p>
<p><span class="math display">\[P\left(\frac{\bar{X}_n - \mu}{\sigma/\sqrt{n}} \le a\right) \rightarrow \Phi(a)\]</span> as <span class="math inline">\(n\to \infty\)</span>, where <span class="math display">\[\Phi(x) = \int_{-\infty}^x \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}} \, dx\]</span> is the CDF of a Normal distribution with mean 0 and variance 1.</p>
<p>This result means that, as <span class="math inline">\(n\)</span> grows, the distribution of the sample mean <span class="math inline">\(\bar X_n = \frac{1}{n} (X_1 + X_2 + \cdots + X_n)\)</span> is approximately normal with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\frac{\sigma}{\sqrt n}\)</span>, i.e., <span class="math display">\[\bar{X}_n \approx \mathcal{N}\bigg(\mu, \frac{\sigma^2}{n}\bigg).\]</span> The standard deviation of <span class="math inline">\(\bar X_n\)</span> (which is roughly a measure of the precision of <span class="math inline">\(\bar X_n\)</span> as an estimator of <span class="math inline">\(\mu\)</span>) decreases at the rate <span class="math inline">\(1/\sqrt{n}\)</span>, so, for example, to increase its precision by <span class="math inline">\(10\)</span> (i.e., to get one more digit right), one needs to collect <span class="math inline">\(10^2=100\)</span> times more units of data.</p>
<p>Intuitively, this result also justifies that whenever a lot of small, independent processes somehow combine together to form the realized observations, practitioners often feel comfortable assuming Normality.</p>
</div>
 
<div class="theorem">
<p><span id="thm:lln" class="theorem"><strong>Theorem 5.2  (Law of Large Numbers (LLN))  </strong></span>For any draw of independent random variables with the same mean <span class="math inline">\(\mu\)</span>, the sample average after <span class="math inline">\(n\)</span> draws, <span class="math inline">\(\bar{X}_n = \frac{1}{n}(X_1 + X_2 + \ldots + X_n)\)</span>, converges in probability to the expected value of <span class="math inline">\(X\)</span>, <span class="math inline">\(\mu\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>:</p>
<p><span class="math display">\[\lim\limits_{n\to \infty} P(|\bar{X}_n - \mu | &gt; \varepsilon) = 0\]</span></p>
A shorthand of which is <span class="math inline">\(\bar{X}_n \xrightarrow{p} \mu\)</span>, where the arrow is read as “converges in probability to”.
</div>

<p>as <span class="math inline">\(n\to \infty\)</span>. In other words, <span class="math inline">\(P( \lim_{n\to\infty}\bar{X}_n = \mu) = 1\)</span>. This is an important motivation for the widespread use of the sample mean, as well as the intuition link between averages and expected values.</p>
<p>More precisely this version of the LLN is called the <em>weak</em> law of large numbers because it leaves open the possibility that <span class="math inline">\(|\bar{X}_n - \mu | &gt; \varepsilon\)</span> occurs many times. The <em>strong</em> law of large numbers states that, under a few more conditions, the probability that the limit of the sample average is the true mean is 1 (and other possibilities occur with probability 0), but the difference is rarely consequential in practice.</p>
<p>The Strong Law of Large Numbers holds so long as the expected value exists; no other assumptions are needed. However, the rate of convergence will differ greatly depending on the distribution underlying the observed data. When extreme observations occur often (i.e. kurtosis is large), the rate of convergence is much slower. Cf. The distribution of financial returns.</p>
</div>
<div id="big-mathcalo-notation" class="section level3">
<h3><span class="header-section-number">5.13.2</span> Big <span class="math inline">\(\mathcal{O}\)</span> Notation</h3>
<p>Some of you may encounter “big-OH’’-notation. If <span class="math inline">\(f, g\)</span> are two functions, we say that <span class="math inline">\(f = \mathcal{O}(g)\)</span> if there exists some constant, <span class="math inline">\(c\)</span>, such that <span class="math inline">\(f(n) \leq c \times g(n)\)</span> for large enough <span class="math inline">\(n\)</span>. This notation is useful for simplifying complex problems in game theory, computer science, and statistics.</p>
<p>Example.</p>
<p>What is <span class="math inline">\(\mathcal{O}( 5\exp(0.5 n) + n^2 + n / 2)\)</span>? Answer: <span class="math inline">\(\exp(n)\)</span>. Why? Because, for large <span class="math inline">\(n\)</span>, <span class="math display">\[
\frac{ 5\exp(0.5 n) + n^2 + n / 2 }{ \exp(n)} \leq \frac{ c \exp(n) }{ \exp(n)} = c. 
\]</span> whenever <span class="math inline">\(n &gt; 4\)</span> and where <span class="math inline">\(c = 1\)</span>.</p>

</div>
</div>
<div id="answers-to-examples-and-exercises-2" class="section level2 unnumbered">
<h2>Answers to Examples and Exercises</h2>
<p>Answer to Example <a href="probability-theory.html#exm:counting">5.1</a>:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(5 \times 5 \times 5 = 125\)</span></p></li>
<li><p><span class="math inline">\(5 \times 4 \times 3 = 60\)</span></p></li>
<li><p><span class="math inline">\(\binom{5}{3} = \frac{5!}{(5-3)!3!} = \frac{5 \times 4}{2 \times 1} = 10\)</span></p></li>
</ol>
<p>Answer to Exercise <a href="probability-theory.html#exr:counting1">5.1</a>:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\binom{52}{4} = \frac{52!}{(52-4)!4!} = 270725\)</span></li>
</ol>
<p>Answer to Example <a href="probability-theory.html#exm:sets">5.2</a>:</p>
<ol style="list-style-type: decimal">
<li>{1, 2, 3, 4, 5, 6}</li>
<li>{5, 6}</li>
<li>{1, 2, 7, 8, 9, 10}</li>
<li>{3, 4}</li>
</ol>
<p>Answer to Exercise <a href="probability-theory.html#exr:sets1">5.2</a>:</p>
<p>Sample Space: {2, 3, 4, 5, 6, 7, 8}</p>
<ol style="list-style-type: decimal">
<li>{3, 4, 5, 6, 7}</li>
<li>{4, 5, 6}</li>
</ol>
<p>Answer to Example <a href="probability-theory.html#exm:prob">5.3</a>:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\({1, 2, 3, 4, 5, 6}\)</span></p></li>
<li><p><span class="math inline">\(\frac{1}{6}\)</span></p></li>
<li><p><span class="math inline">\(0\)</span></p></li>
<li><p><span class="math inline">\(\frac{1}{2}\)</span></p></li>
<li><p><span class="math inline">\(\frac{4}{6} = \frac{2}{3}\)</span></p></li>
<li><p><span class="math inline">\(1\)</span></p></li>
<li><p><span class="math inline">\(A\cup B=\{1, 2, 3, 4, 6\}\)</span>, <span class="math inline">\(A\cap B=\{2\}\)</span>, <span class="math inline">\(\frac{5}{6}\)</span></p></li>
</ol>
<p>Answer to Exercise <a href="probability-theory.html#exr:prob1">5.3</a>:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(P(X = 5) = \frac{4}{16}\)</span>, <span class="math inline">\(P(X = 3) = \frac{2}{16}\)</span>, <span class="math inline">\(P(X = 6) = \frac{3}{16}\)</span></p></li>
<li><p>What is <span class="math inline">\(P(X=5 \cup X = 3)^C = \frac{10}{16}\)</span>?</p></li>
</ol>
<p>Answer to Example <a href="probability-theory.html#exm:condprobexm1">5.4</a>:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\frac{n_{ab} + n_{ab^c}}{N}\)</span></p></li>
<li><p><span class="math inline">\(\frac{n_{ab} + n_{a^cb}}{N}\)</span></p></li>
<li><p><span class="math inline">\(\frac{n_{ab}}{N}\)</span></p></li>
<li><p><span class="math inline">\(\frac{\frac{n_{ab}}{N}}{\frac{n_{ab} + n_{a^cb}}{N}} = \frac{n_{ab}}{n_{ab} + n_{a^cb}}\)</span></p></li>
<li><p><span class="math inline">\(\frac{\frac{n_{ab}}{N}}{\frac{n_{ab} + n_{ab^c}}{N}} = \frac{n_{ab}}{n_{ab} + n_{ab^c}}\)</span></p></li>
</ol>
<p>Answer to Example <a href="probability-theory.html#exm:condprobexm2">5.5</a>:</p>
<p><span class="math inline">\(P(1|Odd) = \frac{P(1 \cap Odd)}{P(Odd)} = \frac{\frac{1}{6}}{\frac{1}{2}} = \frac{1}{3}\)</span></p>
<p>Answer to Example <a href="probability-theory.html#exm:bayesrule">5.6</a>:</p>
<p>We are given that <span class="math display">\[P(D) = .4, P(D^c) = .6, P(S|D) = .5, P(S|D^c) = .9\]</span> Using this, Bayes’ Law and the Law of Total Probability, we know:</p>
<p><span class="math display">\[P(D|S) = \frac{P(D)P(S|D)}{P(D)P(S|D) + P(D^c)P(S|D^c)}\]</span> <span class="math display">\[P(D|S) = \frac{.4 \times .5}{.4 \times .5 + .6 \times .9 } = .27\]</span></p>
<p>Answer to Exercise <a href="probability-theory.html#exr:condprobexr">5.4</a>:</p>
<p>We are given that</p>
<p><span class="math display">\[P(M) = .02, P(C|M) = .95, P(C^c|M^c) = .97\]</span></p>
<p><span class="math display">\[P(M|C) = \frac{P(C|M)P(M)}{P(C)}\]</span></p>
<p><span class="math display">\[= \frac{P(C|M)P(M)}{P(C|M)P(M) + P(C|M^c)P(M^c)}\]</span></p>
<p><span class="math display">\[= \frac{P(C|M)P(M)}{P(C|M)P(M) + [1-P(C^c|M^c)]P(M^c)}\]</span> <span class="math display">\[ = \frac{.95 \times .02}{.95 \times .02 + .03 \times .98} = .38\]</span></p>
<p>Answer to Example <a href="probability-theory.html#exm:expectdiscrete">5.10</a>:</p>
<p><span class="math inline">\(E(Y)=7/2\)</span></p>
<p>We would never expect the result of a rolled die to be <span class="math inline">\(7/2\)</span>, but that would be the average over a large number of rolls of the die.</p>
<p>Answer to Example <a href="probability-theory.html#exm:expectconti">5.11</a></p>
<p>0.75</p>
<p>Answer to Example <a href="probability-theory.html#exm:var">5.12</a>:</p>
<p><span class="math inline">\(E(X) = 0 \times \frac{1}{8} + 1 \times \frac{3}{8} + 2 \times \frac{3}{8} + 3 \times \frac{1}{8} = \frac{3}{2}\)</span></p>
<p>Since there is a 1 to 1 mapping from <span class="math inline">\(X\)</span> to <span class="math inline">\(X^2:\)</span> <span class="math inline">\(E(X^2) = 0 \times \frac{1}{8} + 1 \times \frac{3}{8} + 4 \times \frac{3}{8} + 9 \times \frac{1}{8} = \frac{24}{8} = 3\)</span></p>
<span class="math display">\[\begin{align*}
\text{Var}(x) &amp;= E(X^2) - E(x)^2\\
&amp;= 3 - (\frac{3}{2})^2\\
&amp;= \frac{3}{4}
\end{align*}\]</span>
<p>Answer to Exercise <a href="probability-theory.html#exr:expvar">5.6</a>:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(E(X) = -2(\frac{1}{5}) + -1(\frac{1}{6}) + 0(\frac{1}{5}) + 1(\frac{1}{15}) + 2(\frac{11}{30}) = \frac{7}{30}\)</span></p></li>
<li><p><span class="math inline">\(E(Y) = 0(\frac{1}{5}) + 1(\frac{7}{30}) + 4(\frac{17}{30}) = \frac{5}{2}\)</span></p></li>
<li></li>
</ol>
<span class="math display">\[\begin{align*}
\text{Var}(X) &amp;= E[X^2] - E[X]^2\\
&amp;= E(Y) - E(X)^2\\
&amp;= \frac{5}{2} - \frac{7}{30}^2 \approx 2.45
\end{align*}\]</span>
<p>Answer to Exercise <a href="probability-theory.html#exr:expvar2">5.7</a>:</p>
<ol style="list-style-type: decimal">
<li>expectation = <span class="math inline">\(\frac{6}{5}\)</span>, variance = <span class="math inline">\(\frac{6}{25}\)</span></li>
</ol>
<p>Answer to Exercise <a href="probability-theory.html#exr:expvar3">5.8</a>:</p>
<ol style="list-style-type: decimal">
<li><p>mean = 2, standard deviation = <span class="math inline">\(\sqrt(\frac{2}{3})\)</span></p></li>
<li><p><span class="math inline">\(\frac{1}{8}(2 - \sqrt(\frac{2}{3}))^2\)</span></p></li>
</ol>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>Images of Probability and Random Variables drawn by Shiro Kuriwaki and inspired by Blitzstein and Morris<a href="probability-theory.html#fnref3">↩</a></p></li>
<li id="fn4"><p>Example taken from Blitzstein and Hwang, Example 2.5.10<a href="probability-theory.html#fnref4">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="optim.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linearalgebra.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/IQSS/prefresher/edit/master/06_probability.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["prefresher.pdf", "prefresher.epub"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
