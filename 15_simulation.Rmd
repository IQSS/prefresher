# Programming 5: Simulation


Module originally written by Connor Jerzak

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```



```{r libraries, message=FALSE,warning=FALSE}
library(readr)
library(scales)
library(forcats)
library(ggplot2)
```

## Where are we? Where are we headed?

Up till now, you should have covered:

* `R` basics
* Wrangling with real data
* Visualization

In this module, we will start to work with generating data within R, from thin air, as it were. This branch of statistics is grouped as "simulation", and it is becoming increasing relevant and useful for empirical social sciece researchers, not just statisticians.


## Preview!

Check if you have an idea of how you might code the following tasks:

* Simulate 100 rolls of a die
* Simulate one random ordering of 25 numbers
* Simulate 100 valus of white noise (uniform random variables)
* Generate a "bootstrap" sample of an existing dataset

We're going to learn about this today!

## Motivation
An increasing amount of political science contributions now include a simulation. 

* [Axelrod (1977)](http://www-personal.umich.edu/~axe/research/Dissemination.pdf) demonstrated via simulation how atomized individuals evolve to be grouped in similar clusters or countries, a model of culture^[[Axelrod, Robert. 1997. "The Dissemination of Culture." _Journal of Conflict Resolution_ 41(2): 203â€“26.](http://www-personal.umich.edu/~axe/research/Dissemination.pdf)].
* [Chen and Rodden (2013)](http://www-personal.umich.edu/~jowei/florida.pdf) argued in a 2013 article that the vote-seat inequality in U.S. elections that is often attributed to intentional partisan gerrymandering can actually attributed to simply the reality of "human geography" -- Democratic voters tend to be concentrated in smaller area. Put another way, no feasible form of gerrymandering could spread out Democratic voters in such a way to equalize their vote-seat translation effectiveness. After demonstraing the empirical pattern of human geography, they advance their key claim by simulating thousands of redistricting plans and record the vote-seat ratio^[[Chen, Jowei, and Jonathan Rodden.  "Unintentional Gerrymandering: Political Geography and Electoral Bias in Legislatures. _Quarterly Journal of Political Science_, 8:239-269"](http://www-personal.umich.edu/~jowei/florida.pdf)]. 
* [Gary King, James Honaker, and multiple other authors](https://gking.harvard.edu/files/abs/evil-abs.shtml) propose a way to analyze missing data with a method of multiple imputation, which uses a lot of simulation from a researcher's observed dataset^[[King, Gary, et al. "Analyzing Incomplete Political Science Data: An Alternative Algorithm for Multiple Imputation". _American Political Science Review_, 95: 49-69.](https://gking.harvard.edu/files/abs/evil-abs.shtml)]  (Software: Amelia^[[James Honaker, Gary King, Matthew Blackwell (2011). Amelia II: A Program for Missing Data. Journal of
  Statistical Software, 45(7), 1-47.](http://www.jstatsoft.org/v45/i07/)]). 

Statistical methods also incorporate simulation: 
  
      1. The bootstrap: a statistical method for estimating uncertainty around some parameter by re-sampling observations. 
      2. Bagging: a method for improving machine learning predictions by re-sampling observations, storing the estimate across many re-samples, and averaging these estimates to form the final estimate. A variance reduction technique. 
      3. Statistical reasoning: if you are trying to understand a quantitative problem, a wonderful first-step to understand the problem better is to simulate it! The analytical solution is often very hard (or impossible), but the simulation is often much easier :-) 

## Key functions
The core functions for coding up stochastic data revolves around several key functions, so we will simply review them here.  

## `sample()`
Suppose you have a vector of values `x` and from it you want to randomly sample a sample of length `size`. For this, use the `sample` function
```{r}
sample(x = 1:10, size = 5)
```

There are two subtypes of sampling -- with and without replacement.
```{r}
help(sample)
```

Sampling without replacement (`replace = FALSE`) means once an element of `x` is chosen, it will not be considered again:
```{r}
sample(x = 1:10, size = 10, replace = FALSE) ## no number appears more than once
```

Sampling with repalcement (`replace = TRUE`) means that even if an element of `x` is chosen, it is put back in the pool and may be chosen again. 
```{r}
sample(x = 1:10, size = 10, replace = TRUE) ## any number can appear more than once
```

It follows than that you cannot sample without replacement a sample that is larger than the pool.
```{r, error = TRUE}
sample(x = 1:10, size = 100, replace = FALSE)
```


So far, every element in `x` has had an equal probability of being chosen. In some application, we want a sampling scheme where some elements are more likely to be chosen than others. The argument `prob` handles this.

For example, this simulates 20 fair coin tosses (each outcome is equally likely to happen)
```{r}
sample(c("Head", "Tail"), size = 20, prob = c(0.5, 0.5), replace = TRUE)
```


But this simulates 20 biased coin tosses, where say the probability of Tails is 4 times more likely than the number of Heads
```{r}
sample(c("Head", "Tail"), size = 20, prob = c(0.2, 0.8), replace = TRUE)
```


## `rbinom()`
`rbinom` builds upon `sample` as a tool to help you answer the question -- what is the _total number of successes_ I would get if I ran sampled a binary (bernoulli) result from a pool of size `size`, with a event-wise probability of `prob`, with `n` number of trials?

For example, I want to know how many Heads I would get if I flipped a fair coin 100 times. 
```{r}
rbinom(n = 1, size = 100, prob = 0.5)
```

Now imagine this I wanted to do this experiment 10 times, which would require I flip the coin 10 x 100 = 1000 times! Helpfully, we can do this in one line
```{r}
rbinom(n = 10, size = 100, prob = 0.5)
```

## `runif()`
`runif` also simulates a stochastic scheme where each event has equal probability of getting chosen like `sample`, but is a continuous rather than discrete system.  We will cover this more in the next math module.

The intuition to emphasize here is that one can generate potentially infinite amounts (size `n`) of noise that is a essentially random


```{r}
runif(n = 5)
```


## `rnorm()`
`rnorm` is also a continous distribution, but draws from a Normal distribution -- perhaps the most important distribution in statistics. It runs the same way as `runif`

```{r}
rnorm(n = 5)
```

To better visualize the difference between the output of `runif` and `rnorm`, let's generate lots of each and plot a histogram.

```{r}
from_runif <- runif(n = 1000)
from_rnorm <- rnorm(n = 1000)

par(mfrow = c(1, 2)) ## two plots at once
hist(from_runif)
hist(from_rnorm)
```




## `set.seed()`
`R` doesn't have the ability to generate truly random numbers! Random numbers are actually very hard to generate. (Think: flipping a coin --> can be perfectly predicted if I know windspeed, the angle the coin is flipped, etc.). Some people use random noise in the atmosphere or random behavior in quantuum systems to generate "truly" (?) random numbers. Convserely, R uses deterministic algorithms which take as an input a "seed" and which then perform a series of operations to generate a sequence of random-seeming numbers (that is, numbers whose sequence is sufficiently hard to predict).

Let's think about this another way. Sampling is a stochastic process, so every time you run `sample()` or `runif()` you are bound to get a different output (because different random seeds are used). This is intenional in some cases but you might want to avoid it in others. For example, you might want to diagnose a coding discrepancy by setting the random number generator to give the same number each time. To do this, use the function `set.seed()`.

In the function goes any number. When you run a sample function in the same command as a preceding `set.seed()`, the sampling function will always give you the same sequence of numbers. In a sense, the sampler is no longer random (in the sense of unpredictable to use; remember: it never was "truly" random in the first place)

```{r}
set.seed(02138)
runif(n = 5)
## exact same output long as you preced the function by the same seed, 
set.seed(02138)
runif(n = 5)
```

A true random number generator would give you the exact same sequence of output with probability 0!
```{r}
runif(n = 5)
```

## Anything else? Specific questions? General questions? 
:-) 

## Exercises

### The Birthday problem
Write code that will answer the well-known birthday probelm via simulation^[This exercise draws from Imai (2017)]. 

The problem is fairly simple: Suppose $k$ people gather together in a room. What is the probability at least two people share the same birthday?

To simplify reality a bit, assume that (1) there are no leap years, and so there are always 365 days in a year, and (2) a given individual's birthday is randomly assigned and independent from each other. 


_Step 1_: Set `k` to a concrete number. Pick a number from 1 to 365 randomly, `k` times to simulate birthdays (would this be with replacement or without?).
```{r}
# Your code
```


_Step 2_: Write a line (or two) of code  that gives a `TRUE` or `FALSE` statement of whether or not at least two people share the same birthdate.
```{r}
# Your code
```


_Step 3_: The above steps will generate a `TRUE` or `FALSE` answer for your event of interest, but only for one realization of an event in the sample space. In order to estimate the _probability_ of your event happening, we need a "stochastic", as opposed to "deterministic", method. To do this, write a loop that does Steps 1 and 2 repeatedly for many times, call that number of times `sims`. For each of `sims` iteration, your code should give you a `TRUE` or `FALSE` answer. Code up a way to store these estimates.
```{r}
# Your code
```


_Step 4_: Finally, generalize the function further by letting `k` be a user-defined number. You have now created a _Monte Carlo simulation_! 
```{r}
# Your code
```


_Step 5_: Generate a table or plot that shows how the probability of sharing a birthday changes by `k` (fixing `sims` at a large number like `1000`). Also generate a similar plot that shows how the probability of sharing a birthday changes by `sims` (fixing `k` at some arbitrary number like `10`). 
```{r}
# Your code
```


_Extra credit_: Give an "analtyical" answer to this problem, that is an answer through deriving the mathematical expressions of the probability.
```{r}
# Your equations
```


### The Monty Hall problem
The Monty Hall problem is a counterintuitive example demonstrating the importance of conditional probability that also shows up in most probability textbooks. 

The original formulation of the problem appeared on a magazine column in 1990

> "Suppose you're on a game show, and you're given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what's behind the doors, opens another door, say No. 3, which has a goat. He then says to you, 'Do you want to pick door No. 2?' Is it to your advantage to switch your choice?"
> `r tufte::quote_footer('[https://en.wikipedia.org/wiki/Monty_Hall_problem](https://en.wikipedia.org/wiki/Monty_Hall_problem)')`

Give an answer to this question by a  Monte Carlo simulation. As in the previous expample, set a number `sims` for the number of simulations you will run.

The key difference in this problem is to record the outcome (whether you won or lost) for _two counterfactuals_ at any given simulation. That is, record the result for two cases: when you switched given the host's advice or did not switch. 

Comparing the average success rates of each of the two choices will provide a simulation-based answer to the Monty Hall problem. 

```{r}
# Your code
```

A model answer (there are many correct answers) is given in Imai (2017), p.265^[with a slight robustness addition [here](https://github.com/kosukeimai/qss/blob/master/errata/QSSerrata.pdf)]
